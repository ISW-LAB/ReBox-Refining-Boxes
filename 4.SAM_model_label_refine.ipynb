{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975c5906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[DISCOVERY] Found 13 unique dataset roots under: /home/ISW/project/datasets\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] SKU-110K\n",
      " - root        : /home/ISW/project/datasets/SKU-110K\n",
      " - split_mode  : sku_virtual_8_2\n",
      " - train_dir   : /home/ISW/project/datasets/SKU-110K/images | tag=virtual_8_2 | n_train=9394\n",
      " - val_dir     : /home/ISW/project/datasets/SKU-110K/images | tag=virtual_8_2 | n_val=2349\n",
      " - train_labels_dir : /home/ISW/project/datasets/SKU-110K/labels\n",
      " - val_labels_dir   : /home/ISW/project/datasets/SKU-110K/labels\n",
      " - train label files/boxes/groups_est : 11743 / 1730996 / 1730996\n",
      " - val   label files/boxes           : 11743 / 1730996\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=1, names=['class_0']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] kitti\n",
      " - root        : /home/ISW/project/datasets/kitti\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/kitti/images/train | tag=train | n_train=5985\n",
      " - val_dir     : /home/ISW/project/datasets/kitti/images/val | tag=val | n_val=1496\n",
      " - train_labels_dir : /home/ISW/project/datasets/kitti/labels/train\n",
      " - val_labels_dir   : /home/ISW/project/datasets/kitti/labels/val\n",
      " - train label files/boxes/groups_est : 5985 / 32442 / 32442\n",
      " - val   label files/boxes           : 1496 / 8128\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=8, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] homeobjects-3K\n",
      " - root        : /home/ISW/project/datasets/homeobjects-3K\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/homeobjects-3K/images/train | tag=train | n_train=2285\n",
      " - val_dir     : /home/ISW/project/datasets/homeobjects-3K/images/val | tag=val | n_val=404\n",
      " - train_labels_dir : /home/ISW/project/datasets/homeobjects-3K/labels/train\n",
      " - val_labels_dir   : /home/ISW/project/datasets/homeobjects-3K/labels/val\n",
      " - train label files/boxes/groups_est : 2285 / 18822 / 18822\n",
      " - val   label files/boxes           : 404 / 3470\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=12, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] african-wildlife\n",
      " - root        : /home/ISW/project/datasets/african-wildlife\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/african-wildlife/images/train | tag=train | n_train=1052\n",
      " - val_dir     : /home/ISW/project/datasets/african-wildlife/images/val | tag=val | n_val=225\n",
      " - test_dir    : /home/ISW/project/datasets/african-wildlife/images/test | n_test=227\n",
      " - train_labels_dir : /home/ISW/project/datasets/african-wildlife/labels/train\n",
      " - val_labels_dir   : /home/ISW/project/datasets/african-wildlife/labels/val\n",
      " - train label files/boxes/groups_est : 1052 / 1931 / 1931\n",
      " - val   label files/boxes           : 225 / 379\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=4, names=['class_0', 'class_1', 'class_2', 'class_3']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] construction-ppe\n",
      " - root        : /home/ISW/project/datasets/construction-ppe\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/construction-ppe/images/train | tag=train | n_train=1132\n",
      " - val_dir     : /home/ISW/project/datasets/construction-ppe/images/val | tag=val | n_val=143\n",
      " - test_dir    : /home/ISW/project/datasets/construction-ppe/images/test | n_test=141\n",
      " - train_labels_dir : /home/ISW/project/datasets/construction-ppe/labels/train\n",
      " - val_labels_dir   : /home/ISW/project/datasets/construction-ppe/labels/val\n",
      " - train label files/boxes/groups_est : 1142 / 9191 / 9191\n",
      " - val   label files/boxes           : 143 / 1172\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=11, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] Custom_Blood\n",
      " - root        : /home/ISW/project/datasets/Custom_Blood\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/Custom_Blood/images/train | tag=train | n_train=1105\n",
      " - val_dir     : /home/ISW/project/datasets/Custom_Blood/images/val | tag=val | n_val=122\n",
      " - train_labels_dir : /home/ISW/project/datasets/Custom_Blood/labels/train\n",
      " - val_labels_dir   : /home/ISW/project/datasets/Custom_Blood/labels/val\n",
      " - train label files/boxes/groups_est : 1105 / 46487 / 46487\n",
      " - val   label files/boxes           : 122 / 6317\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=13, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] brain-tumor\n",
      " - root        : /home/ISW/project/datasets/brain-tumor\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/brain-tumor/images/train | tag=train | n_train=893\n",
      " - val_dir     : /home/ISW/project/datasets/brain-tumor/images/val | tag=val | n_val=223\n",
      " - train_labels_dir : /home/ISW/project/datasets/brain-tumor/labels/train\n",
      " - val_labels_dir   : /home/ISW/project/datasets/brain-tumor/labels/val\n",
      " - train label files/boxes/groups_est : 878 / 925 / 925\n",
      " - val   label files/boxes           : 223 / 241\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=2, names=['class_0', 'class_1']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] BCCD\n",
      " - root        : /home/ISW/project/datasets/BCCD\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/BCCD/images/train | tag=train | n_train=310\n",
      " - val_dir     : /home/ISW/project/datasets/BCCD/images/val | tag=val | n_val=54\n",
      " - train_labels_dir : /home/ISW/project/datasets/BCCD/labels/train\n",
      " - val_labels_dir   : /home/ISW/project/datasets/BCCD/labels/val\n",
      " - train label files/boxes/groups_est : 310 / 4153 / 4153\n",
      " - val   label files/boxes           : 54 / 735\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=3, names=['class_0', 'class_1', 'class_2']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] signature\n",
      " - root        : /home/ISW/project/datasets/signature\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/signature/images/train | tag=train | n_train=143\n",
      " - val_dir     : /home/ISW/project/datasets/signature/images/val | tag=val | n_val=35\n",
      " - train_labels_dir : /home/ISW/project/datasets/signature/labels/train\n",
      " - val_labels_dir   : /home/ISW/project/datasets/signature/labels/val\n",
      " - train label files/boxes/groups_est : 143 / 143 / 143\n",
      " - val   label files/boxes           : 35 / 35\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=1, names=['class_0']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] medical-pills\n",
      " - root        : /home/ISW/project/datasets/medical-pills\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/medical-pills/images/train | tag=train | n_train=92\n",
      " - val_dir     : /home/ISW/project/datasets/medical-pills/images/val | tag=val | n_val=23\n",
      " - train_labels_dir : /home/ISW/project/datasets/medical-pills/labels/train\n",
      " - val_labels_dir   : /home/ISW/project/datasets/medical-pills/labels/val\n",
      " - train label files/boxes/groups_est : 92 / 1623 / 1623\n",
      " - val   label files/boxes           : 23 / 399\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=1, names=['class_0']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] coco\n",
      " - root        : /home/ISW/project/datasets/coco\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/coco/images/train2017 | tag=train2017 | n_train=118287\n",
      " - val_dir     : /home/ISW/project/datasets/coco/images/val2017 | tag=val2017 | n_val=5000\n",
      " - test_dir    : /home/ISW/project/datasets/coco/images/test2017 | n_test=40670\n",
      " - train_labels_dir : /home/ISW/project/datasets/coco/labels/train2017\n",
      " - val_labels_dir   : /home/ISW/project/datasets/coco/labels/val2017\n",
      " - train label files/boxes/groups_est : 117266 / 849942 / 849942\n",
      " - val   label files/boxes           : 4952 / 36335\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=80, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', 'class_16', 'class_17', 'class_18', 'class_19', 'class_20', 'class_21', 'class_22', 'class_23', 'class_24', 'class_25', 'class_26', 'class_27', 'class_28', 'class_29', 'class_30', 'class_31', 'class_32', 'class_33', 'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39', 'class_40', 'class_41', 'class_42', 'class_43', 'class_44', 'class_45', 'class_46', 'class_47', 'class_48', 'class_49', 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55', 'class_56', 'class_57', 'class_58', 'class_59', 'class_60', 'class_61', 'class_62', 'class_63', 'class_64', 'class_65', 'class_66', 'class_67', 'class_68', 'class_69', 'class_70', 'class_71', 'class_72', 'class_73', 'class_74', 'class_75', 'class_76', 'class_77', 'class_78', 'class_79']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] lvis\n",
      " - root        : /home/ISW/project/datasets/lvis\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/lvis/images/train2017 | tag=train2017 | n_train=118287\n",
      " - val_dir     : /home/ISW/project/datasets/lvis/images/val2017 | tag=val2017 | n_val=5000\n",
      " - test_dir    : /home/ISW/project/datasets/lvis/images/test2017 | n_test=40670\n",
      " - train_labels_dir : /home/ISW/project/datasets/lvis/labels/train2017\n",
      " - val_labels_dir   : /home/ISW/project/datasets/lvis/labels/val2017\n",
      " - train label files/boxes/groups_est : 114262 / 1464174 / 1464174\n",
      " - val   label files/boxes           : 4752 / 50672\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=1202, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', 'class_16', 'class_17', 'class_18', 'class_19', 'class_20', 'class_21', 'class_22', 'class_23', 'class_24', 'class_25', 'class_26', 'class_27', 'class_28', 'class_29', 'class_30', 'class_31', 'class_32', 'class_33', 'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39', 'class_40', 'class_41', 'class_42', 'class_43', 'class_44', 'class_45', 'class_46', 'class_47', 'class_48', 'class_49', 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55', 'class_56', 'class_57', 'class_58', 'class_59', 'class_60', 'class_61', 'class_62', 'class_63', 'class_64', 'class_65', 'class_66', 'class_67', 'class_68', 'class_69', 'class_70', 'class_71', 'class_72', 'class_73', 'class_74', 'class_75', 'class_76', 'class_77', 'class_78', 'class_79', 'class_80', 'class_81', 'class_82', 'class_83', 'class_84', 'class_85', 'class_86', 'class_87', 'class_88', 'class_89', 'class_90', 'class_91', 'class_92', 'class_93', 'class_94', 'class_95', 'class_96', 'class_97', 'class_98', 'class_99', 'class_100', 'class_101', 'class_102', 'class_103', 'class_104', 'class_105', 'class_106', 'class_107', 'class_108', 'class_109', 'class_110', 'class_111', 'class_112', 'class_113', 'class_114', 'class_115', 'class_116', 'class_117', 'class_118', 'class_119', 'class_120', 'class_121', 'class_122', 'class_123', 'class_124', 'class_125', 'class_126', 'class_127', 'class_128', 'class_129', 'class_130', 'class_131', 'class_132', 'class_133', 'class_134', 'class_135', 'class_136', 'class_137', 'class_138', 'class_139', 'class_140', 'class_141', 'class_142', 'class_143', 'class_144', 'class_145', 'class_146', 'class_147', 'class_148', 'class_149', 'class_150', 'class_151', 'class_152', 'class_153', 'class_154', 'class_155', 'class_156', 'class_157', 'class_158', 'class_159', 'class_160', 'class_161', 'class_162', 'class_163', 'class_164', 'class_165', 'class_166', 'class_167', 'class_168', 'class_169', 'class_170', 'class_171', 'class_172', 'class_173', 'class_174', 'class_175', 'class_176', 'class_177', 'class_178', 'class_179', 'class_180', 'class_181', 'class_182', 'class_183', 'class_184', 'class_185', 'class_186', 'class_187', 'class_188', 'class_189', 'class_190', 'class_191', 'class_192', 'class_193', 'class_194', 'class_195', 'class_196', 'class_197', 'class_198', 'class_199', 'class_200', 'class_201', 'class_202', 'class_203', 'class_204', 'class_205', 'class_206', 'class_207', 'class_208', 'class_209', 'class_210', 'class_211', 'class_212', 'class_213', 'class_214', 'class_215', 'class_216', 'class_217', 'class_218', 'class_219', 'class_220', 'class_221', 'class_222', 'class_223', 'class_224', 'class_225', 'class_226', 'class_227', 'class_228', 'class_229', 'class_230', 'class_231', 'class_232', 'class_233', 'class_234', 'class_235', 'class_236', 'class_237', 'class_238', 'class_239', 'class_240', 'class_241', 'class_242', 'class_243', 'class_244', 'class_245', 'class_246', 'class_247', 'class_248', 'class_249', 'class_250', 'class_251', 'class_252', 'class_253', 'class_254', 'class_255', 'class_256', 'class_257', 'class_258', 'class_259', 'class_260', 'class_261', 'class_262', 'class_263', 'class_264', 'class_265', 'class_266', 'class_267', 'class_268', 'class_269', 'class_270', 'class_271', 'class_272', 'class_273', 'class_274', 'class_275', 'class_276', 'class_277', 'class_278', 'class_279', 'class_280', 'class_281', 'class_282', 'class_283', 'class_284', 'class_285', 'class_286', 'class_287', 'class_288', 'class_289', 'class_290', 'class_291', 'class_292', 'class_293', 'class_294', 'class_295', 'class_296', 'class_297', 'class_298', 'class_299', 'class_300', 'class_301', 'class_302', 'class_303', 'class_304', 'class_305', 'class_306', 'class_307', 'class_308', 'class_309', 'class_310', 'class_311', 'class_312', 'class_313', 'class_314', 'class_315', 'class_316', 'class_317', 'class_318', 'class_319', 'class_320', 'class_321', 'class_322', 'class_323', 'class_324', 'class_325', 'class_326', 'class_327', 'class_328', 'class_329', 'class_330', 'class_331', 'class_332', 'class_333', 'class_334', 'class_335', 'class_336', 'class_337', 'class_338', 'class_339', 'class_340', 'class_341', 'class_342', 'class_343', 'class_344', 'class_345', 'class_346', 'class_347', 'class_348', 'class_349', 'class_350', 'class_351', 'class_352', 'class_353', 'class_354', 'class_355', 'class_356', 'class_357', 'class_358', 'class_359', 'class_360', 'class_361', 'class_362', 'class_363', 'class_364', 'class_365', 'class_366', 'class_367', 'class_368', 'class_369', 'class_370', 'class_371', 'class_372', 'class_373', 'class_374', 'class_375', 'class_376', 'class_377', 'class_378', 'class_379', 'class_380', 'class_381', 'class_382', 'class_383', 'class_384', 'class_385', 'class_386', 'class_387', 'class_388', 'class_389', 'class_390', 'class_391', 'class_392', 'class_393', 'class_394', 'class_395', 'class_396', 'class_397', 'class_398', 'class_399', 'class_400', 'class_401', 'class_402', 'class_403', 'class_404', 'class_405', 'class_406', 'class_407', 'class_408', 'class_409', 'class_410', 'class_411', 'class_412', 'class_413', 'class_414', 'class_415', 'class_416', 'class_417', 'class_418', 'class_419', 'class_420', 'class_421', 'class_422', 'class_423', 'class_424', 'class_425', 'class_426', 'class_427', 'class_428', 'class_429', 'class_430', 'class_431', 'class_432', 'class_433', 'class_434', 'class_435', 'class_436', 'class_437', 'class_438', 'class_439', 'class_440', 'class_441', 'class_442', 'class_443', 'class_444', 'class_445', 'class_446', 'class_447', 'class_448', 'class_449', 'class_450', 'class_451', 'class_452', 'class_453', 'class_454', 'class_455', 'class_456', 'class_457', 'class_458', 'class_459', 'class_460', 'class_461', 'class_462', 'class_463', 'class_464', 'class_465', 'class_466', 'class_467', 'class_468', 'class_469', 'class_470', 'class_471', 'class_472', 'class_473', 'class_474', 'class_475', 'class_476', 'class_477', 'class_478', 'class_479', 'class_480', 'class_481', 'class_482', 'class_483', 'class_484', 'class_485', 'class_486', 'class_487', 'class_488', 'class_489', 'class_490', 'class_491', 'class_492', 'class_493', 'class_494', 'class_495', 'class_496', 'class_497', 'class_498', 'class_499', 'class_500', 'class_501', 'class_502', 'class_503', 'class_504', 'class_505', 'class_506', 'class_507', 'class_508', 'class_509', 'class_510', 'class_511', 'class_512', 'class_513', 'class_514', 'class_515', 'class_516', 'class_517', 'class_518', 'class_519', 'class_520', 'class_521', 'class_522', 'class_523', 'class_524', 'class_525', 'class_526', 'class_527', 'class_528', 'class_529', 'class_530', 'class_531', 'class_532', 'class_533', 'class_534', 'class_535', 'class_536', 'class_537', 'class_538', 'class_539', 'class_540', 'class_541', 'class_542', 'class_543', 'class_544', 'class_545', 'class_546', 'class_547', 'class_548', 'class_549', 'class_550', 'class_551', 'class_552', 'class_553', 'class_554', 'class_555', 'class_556', 'class_557', 'class_558', 'class_559', 'class_560', 'class_561', 'class_562', 'class_563', 'class_564', 'class_565', 'class_566', 'class_567', 'class_568', 'class_569', 'class_570', 'class_571', 'class_572', 'class_573', 'class_574', 'class_575', 'class_576', 'class_577', 'class_578', 'class_579', 'class_580', 'class_581', 'class_582', 'class_583', 'class_584', 'class_585', 'class_586', 'class_587', 'class_588', 'class_589', 'class_590', 'class_591', 'class_592', 'class_593', 'class_594', 'class_595', 'class_596', 'class_597', 'class_598', 'class_599', 'class_600', 'class_601', 'class_602', 'class_603', 'class_604', 'class_605', 'class_606', 'class_607', 'class_608', 'class_609', 'class_610', 'class_611', 'class_612', 'class_613', 'class_614', 'class_615', 'class_616', 'class_617', 'class_618', 'class_619', 'class_620', 'class_621', 'class_622', 'class_623', 'class_624', 'class_625', 'class_626', 'class_627', 'class_628', 'class_629', 'class_630', 'class_631', 'class_632', 'class_633', 'class_634', 'class_635', 'class_636', 'class_637', 'class_638', 'class_639', 'class_640', 'class_641', 'class_642', 'class_643', 'class_644', 'class_645', 'class_646', 'class_647', 'class_648', 'class_649', 'class_650', 'class_651', 'class_652', 'class_653', 'class_654', 'class_655', 'class_656', 'class_657', 'class_658', 'class_659', 'class_660', 'class_661', 'class_662', 'class_663', 'class_664', 'class_665', 'class_666', 'class_667', 'class_668', 'class_669', 'class_670', 'class_671', 'class_672', 'class_673', 'class_674', 'class_675', 'class_676', 'class_677', 'class_678', 'class_679', 'class_680', 'class_681', 'class_682', 'class_683', 'class_684', 'class_685', 'class_686', 'class_687', 'class_688', 'class_689', 'class_690', 'class_691', 'class_692', 'class_693', 'class_694', 'class_695', 'class_696', 'class_697', 'class_698', 'class_699', 'class_700', 'class_701', 'class_702', 'class_703', 'class_704', 'class_705', 'class_706', 'class_707', 'class_708', 'class_709', 'class_710', 'class_711', 'class_712', 'class_713', 'class_714', 'class_715', 'class_716', 'class_717', 'class_718', 'class_719', 'class_720', 'class_721', 'class_722', 'class_723', 'class_724', 'class_725', 'class_726', 'class_727', 'class_728', 'class_729', 'class_730', 'class_731', 'class_732', 'class_733', 'class_734', 'class_735', 'class_736', 'class_737', 'class_738', 'class_739', 'class_740', 'class_741', 'class_742', 'class_743', 'class_744', 'class_745', 'class_746', 'class_747', 'class_748', 'class_749', 'class_750', 'class_751', 'class_752', 'class_753', 'class_754', 'class_755', 'class_756', 'class_757', 'class_758', 'class_759', 'class_760', 'class_761', 'class_762', 'class_763', 'class_764', 'class_765', 'class_766', 'class_767', 'class_768', 'class_769', 'class_770', 'class_771', 'class_772', 'class_773', 'class_774', 'class_775', 'class_776', 'class_777', 'class_778', 'class_779', 'class_780', 'class_781', 'class_782', 'class_783', 'class_784', 'class_785', 'class_786', 'class_787', 'class_788', 'class_789', 'class_790', 'class_791', 'class_792', 'class_793', 'class_794', 'class_795', 'class_796', 'class_797', 'class_798', 'class_799', 'class_800', 'class_801', 'class_802', 'class_803', 'class_804', 'class_805', 'class_806', 'class_807', 'class_808', 'class_809', 'class_810', 'class_811', 'class_812', 'class_813', 'class_814', 'class_815', 'class_816', 'class_817', 'class_818', 'class_819', 'class_820', 'class_821', 'class_822', 'class_823', 'class_824', 'class_825', 'class_826', 'class_827', 'class_828', 'class_829', 'class_830', 'class_831', 'class_832', 'class_833', 'class_834', 'class_835', 'class_836', 'class_837', 'class_838', 'class_839', 'class_840', 'class_841', 'class_842', 'class_843', 'class_844', 'class_845', 'class_846', 'class_847', 'class_848', 'class_849', 'class_850', 'class_851', 'class_852', 'class_853', 'class_854', 'class_855', 'class_856', 'class_857', 'class_858', 'class_859', 'class_860', 'class_861', 'class_862', 'class_863', 'class_864', 'class_865', 'class_866', 'class_867', 'class_868', 'class_869', 'class_870', 'class_871', 'class_872', 'class_873', 'class_874', 'class_875', 'class_876', 'class_877', 'class_878', 'class_879', 'class_880', 'class_881', 'class_882', 'class_883', 'class_884', 'class_885', 'class_886', 'class_887', 'class_888', 'class_889', 'class_890', 'class_891', 'class_892', 'class_893', 'class_894', 'class_895', 'class_896', 'class_897', 'class_898', 'class_899', 'class_900', 'class_901', 'class_902', 'class_903', 'class_904', 'class_905', 'class_906', 'class_907', 'class_908', 'class_909', 'class_910', 'class_911', 'class_912', 'class_913', 'class_914', 'class_915', 'class_916', 'class_917', 'class_918', 'class_919', 'class_920', 'class_921', 'class_922', 'class_923', 'class_924', 'class_925', 'class_926', 'class_927', 'class_928', 'class_929', 'class_930', 'class_931', 'class_932', 'class_933', 'class_934', 'class_935', 'class_936', 'class_937', 'class_938', 'class_939', 'class_940', 'class_941', 'class_942', 'class_943', 'class_944', 'class_945', 'class_946', 'class_947', 'class_948', 'class_949', 'class_950', 'class_951', 'class_952', 'class_953', 'class_954', 'class_955', 'class_956', 'class_957', 'class_958', 'class_959', 'class_960', 'class_961', 'class_962', 'class_963', 'class_964', 'class_965', 'class_966', 'class_967', 'class_968', 'class_969', 'class_970', 'class_971', 'class_972', 'class_973', 'class_974', 'class_975', 'class_976', 'class_977', 'class_978', 'class_979', 'class_980', 'class_981', 'class_982', 'class_983', 'class_984', 'class_985', 'class_986', 'class_987', 'class_988', 'class_989', 'class_990', 'class_991', 'class_992', 'class_993', 'class_994', 'class_995', 'class_996', 'class_997', 'class_998', 'class_999', 'class_1000', 'class_1001', 'class_1002', 'class_1003', 'class_1004', 'class_1005', 'class_1006', 'class_1007', 'class_1008', 'class_1009', 'class_1010', 'class_1011', 'class_1012', 'class_1013', 'class_1014', 'class_1015', 'class_1016', 'class_1017', 'class_1018', 'class_1019', 'class_1020', 'class_1021', 'class_1022', 'class_1023', 'class_1024', 'class_1025', 'class_1026', 'class_1027', 'class_1028', 'class_1029', 'class_1030', 'class_1031', 'class_1032', 'class_1033', 'class_1034', 'class_1035', 'class_1036', 'class_1037', 'class_1038', 'class_1039', 'class_1040', 'class_1041', 'class_1042', 'class_1043', 'class_1044', 'class_1045', 'class_1046', 'class_1047', 'class_1048', 'class_1049', 'class_1050', 'class_1051', 'class_1052', 'class_1053', 'class_1054', 'class_1055', 'class_1056', 'class_1057', 'class_1058', 'class_1059', 'class_1060', 'class_1061', 'class_1062', 'class_1063', 'class_1064', 'class_1065', 'class_1066', 'class_1067', 'class_1068', 'class_1069', 'class_1070', 'class_1071', 'class_1072', 'class_1073', 'class_1074', 'class_1075', 'class_1076', 'class_1077', 'class_1078', 'class_1079', 'class_1080', 'class_1081', 'class_1082', 'class_1083', 'class_1084', 'class_1085', 'class_1086', 'class_1087', 'class_1088', 'class_1089', 'class_1090', 'class_1091', 'class_1092', 'class_1093', 'class_1094', 'class_1095', 'class_1096', 'class_1097', 'class_1098', 'class_1099', 'class_1100', 'class_1101', 'class_1102', 'class_1103', 'class_1104', 'class_1105', 'class_1106', 'class_1107', 'class_1108', 'class_1109', 'class_1110', 'class_1111', 'class_1112', 'class_1113', 'class_1114', 'class_1115', 'class_1116', 'class_1117', 'class_1118', 'class_1119', 'class_1120', 'class_1121', 'class_1122', 'class_1123', 'class_1124', 'class_1125', 'class_1126', 'class_1127', 'class_1128', 'class_1129', 'class_1130', 'class_1131', 'class_1132', 'class_1133', 'class_1134', 'class_1135', 'class_1136', 'class_1137', 'class_1138', 'class_1139', 'class_1140', 'class_1141', 'class_1142', 'class_1143', 'class_1144', 'class_1145', 'class_1146', 'class_1147', 'class_1148', 'class_1149', 'class_1150', 'class_1151', 'class_1152', 'class_1153', 'class_1154', 'class_1155', 'class_1156', 'class_1157', 'class_1158', 'class_1159', 'class_1160', 'class_1161', 'class_1162', 'class_1163', 'class_1164', 'class_1165', 'class_1166', 'class_1167', 'class_1168', 'class_1169', 'class_1170', 'class_1171', 'class_1172', 'class_1173', 'class_1174', 'class_1175', 'class_1176', 'class_1177', 'class_1178', 'class_1179', 'class_1180', 'class_1181', 'class_1182', 'class_1183', 'class_1184', 'class_1185', 'class_1186', 'class_1187', 'class_1188', 'class_1189', 'class_1190', 'class_1191', 'class_1192', 'class_1193', 'class_1194', 'class_1195', 'class_1196', 'class_1197', 'class_1198', 'class_1199', 'class_1200', 'class_1201']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] VOC\n",
      " - root        : /home/ISW/project/datasets/VOC\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/VOC/images/train2012 | tag=train2012 | n_train=5717\n",
      " - val_dir     : /home/ISW/project/datasets/VOC/images/val2012 | tag=val2012 | n_val=5823\n",
      " - train_labels_dir : /home/ISW/project/datasets/VOC/labels/train2012\n",
      " - val_labels_dir   : /home/ISW/project/datasets/VOC/labels/val2012\n",
      " - train label files/boxes/groups_est : 5717 / 13609 / 13609\n",
      " - val   label files/boxes           : 5823 / 13841\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=20, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', 'class_16', 'class_17', 'class_18', 'class_19']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✅ Cell 1 done.\n",
      "   -> dataset_summaries length = 13\n",
      "   -> roots variable is ready for Cell 2.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 1) Detection datasets discovery & inspection (FINAL++)\n",
    "#   - How many datasets are found\n",
    "#   - train/val image count per dataset\n",
    "#   - Whether label cases (original/scale/side) exist\n",
    "#   - Output estimated class count/names (multiclass-based)\n",
    "#\n",
    "# [UPDATED++]\n",
    "#   ✅ Reflect split structure rules per dataset name\n",
    "#   ✅ For Cell 2 acceleration\n",
    "#       - Store confirmed train/val labels dir\n",
    "#       - Calculate train/val label file count, box (line) count\n",
    "#       - Store n_train_groups_est (=box count)\n",
    "# ========================================== \n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, sys, random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 0) Register PROJECT_MODULE_DIR\n",
    "# -------------------------------------------------------------------------\n",
    "PROJECT_MODULE_DIR = Path(\"/home/ISW/project/Project_Module\")\n",
    "if str(PROJECT_MODULE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_MODULE_DIR))\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1) ultra_det_loader\n",
    "# -------------------------------------------------------------------------\n",
    "from ultra_det_loader import discover_det_datasets\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2) noisy_insection (use only scale/boundary jitter case list)\n",
    "# -------------------------------------------------------------------------\n",
    "try:\n",
    "    from noisy_insection import UNIFORM_SCALING_FACTORS, JITTER_PATTERNS\n",
    "except Exception:\n",
    "    UNIFORM_SCALING_FACTORS = [0.6, 0.7, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
    "    JITTER_PATTERNS = [1, 3, 5, 7, 9]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# User config\n",
    "# -------------------------------------------------------------------------\n",
    "LOAD_DIR = \"/home/ISW/project/datasets\"\n",
    "SEED = 42\n",
    "\n",
    "# Image extensions\n",
    "_IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "\n",
    "def list_images(dir_path: Optional[Path]) -> List[Path]:\n",
    "    if dir_path is None or not Path(dir_path).exists():\n",
    "        return []\n",
    "    dir_path = Path(dir_path)\n",
    "    imgs = []\n",
    "    for p in dir_path.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in _IMG_EXTS:\n",
    "            imgs.append(p)\n",
    "    return sorted(imgs)\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    n = name.strip().lower()\n",
    "    n = n.replace(\"_\", \"-\")\n",
    "    n = n.replace(\" \", \"-\")\n",
    "    return n\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Legacy heuristic (fallback)\n",
    "# -------------------------------------------------------------------------\n",
    "def _fallback_train_dir(images_root: Path) -> Path:\n",
    "    if (images_root / \"train\").is_dir():\n",
    "        return images_root / \"train\"\n",
    "    return images_root\n",
    "\n",
    "def _fallback_val_dir(images_root: Path) -> Optional[Path]:\n",
    "    if (images_root / \"val\").is_dir():\n",
    "        return images_root / \"val\"\n",
    "    if (images_root / \"valid\").is_dir():\n",
    "        return images_root / \"valid\"\n",
    "    return None\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ✅ Dataset-specific split rules\n",
    "# -------------------------------------------------------------------------\n",
    "_SIMPLE_TRAIN_VAL = {\n",
    "    \"bccd\",\n",
    "    \"brain-tumor\",\n",
    "    \"custom-blood\",\n",
    "    \"homeobjects-3k\",\n",
    "    \"kitti\",\n",
    "    \"medical-pills\",\n",
    "    \"signature\",\n",
    "}\n",
    "\n",
    "_TRAIN_TEST_VAL = {\n",
    "    \"construction-ppe\",\n",
    "    \"african-wildlife\",\n",
    "}\n",
    "\n",
    "def detect_split_dirs(ds_root: Path) -> Dict[str, Optional[Path]]:\n",
    "    \"\"\"\n",
    "    Interpret images/labels split structure based on ds_root.\n",
    "    Returns:\n",
    "        {\n",
    "          \"train_img_dir\": Path|None,\n",
    "          \"val_img_dir\": Path|None,\n",
    "          \"test_img_dir\": Path|None,\n",
    "          \"split_mode\": str,  # \"explicit\" | \"sku_virtual_8_2\" | \"fallback\"\n",
    "          \"train_tag\": str,\n",
    "          \"val_tag\": str,\n",
    "        }\n",
    "    \"\"\"\n",
    "    ds_name = normalize_name(ds_root.name)\n",
    "    images_root = ds_root / \"images\"\n",
    "\n",
    "    # 1) VOC rule: use train2012/val2012 only\n",
    "    if ds_name == \"voc\":\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train2012\",\n",
    "            val_img_dir=images_root / \"val2012\",\n",
    "            test_img_dir=None,\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train2012\",\n",
    "            val_tag=\"val2012\",\n",
    "        )\n",
    "\n",
    "    # 2) COCO/LVIS rule\n",
    "    if ds_name == \"coco\" or \"coco\" in ds_name:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train2017\",\n",
    "            val_img_dir=images_root / \"val2017\",\n",
    "            test_img_dir=images_root / \"test2017\",\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train2017\",\n",
    "            val_tag=\"val2017\",\n",
    "        )\n",
    "\n",
    "    if ds_name == \"lvis\" or \"lvis\" in ds_name:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train2017\",\n",
    "            val_img_dir=images_root / \"val2017\",\n",
    "            test_img_dir=images_root / \"test2017\",\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train2017\",\n",
    "            val_tag=\"val2017\",\n",
    "        )\n",
    "\n",
    "    # 3) Explicit train/val structure\n",
    "    if ds_name in _SIMPLE_TRAIN_VAL:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train\",\n",
    "            val_img_dir=images_root / \"val\",\n",
    "            test_img_dir=None,\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train\",\n",
    "            val_tag=\"val\",\n",
    "        )\n",
    "\n",
    "    # 4) train/test/val structure\n",
    "    if ds_name in _TRAIN_TEST_VAL:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train\",\n",
    "            val_img_dir=images_root / \"val\",\n",
    "            test_img_dir=images_root / \"test\",\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train\",\n",
    "            val_tag=\"val\",\n",
    "        )\n",
    "\n",
    "    # 5) SKU-110K: no subfolders -> virtual split\n",
    "    if ds_name in {\"sku-110k\", \"sku110k\", \"sku_110k\"} or (\"sku\" in ds_name and \"110k\" in ds_name):\n",
    "        return dict(\n",
    "            train_img_dir=images_root,\n",
    "            val_img_dir=images_root,\n",
    "            test_img_dir=None,\n",
    "            split_mode=\"sku_virtual_8_2\",\n",
    "            train_tag=\"virtual_8_2\",\n",
    "            val_tag=\"virtual_8_2\",\n",
    "        )\n",
    "\n",
    "    # 6) fallback\n",
    "    tr = _fallback_train_dir(images_root)\n",
    "    va = _fallback_val_dir(images_root)\n",
    "    return dict(\n",
    "        train_img_dir=tr,\n",
    "        val_img_dir=va,\n",
    "        test_img_dir=None,\n",
    "        split_mode=\"fallback\",\n",
    "        train_tag=tr.name if tr else \"unknown\",\n",
    "        val_tag=va.name if va else \"missing\",\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Class name estimation\n",
    "# -------------------------------------------------------------------------\n",
    "def infer_class_names_from_labels(label_root: Path, max_files: int = 2000) -> List[str]:\n",
    "    if label_root is None or not label_root.exists():\n",
    "        return [\"class_0\"]\n",
    "\n",
    "    txts = list(label_root.rglob(\"*.txt\"))\n",
    "    if not txts:\n",
    "        return [\"class_0\"]\n",
    "\n",
    "    txts = txts[:max_files]\n",
    "    cls_ids = set()\n",
    "\n",
    "    for t in txts:\n",
    "        try:\n",
    "            with open(t, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) < 1:\n",
    "                        continue\n",
    "                    cid = int(float(parts[0]))\n",
    "                    cls_ids.add(cid)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not cls_ids:\n",
    "        return [\"class_0\"]\n",
    "\n",
    "    max_id = max(cls_ids)\n",
    "    return [f\"class_{i}\" for i in range(max_id + 1)]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Label case detection\n",
    "# -------------------------------------------------------------------------\n",
    "def list_label_cases_for_dataset(ds_root: Path) -> List[Tuple[str, str]]:\n",
    "    cases: List[Tuple[str, str]] = []\n",
    "\n",
    "    if (ds_root / \"labels\").is_dir():\n",
    "        cases.append((\"original\", \"labels\"))\n",
    "\n",
    "    for s in UNIFORM_SCALING_FACTORS:\n",
    "        d = f\"labels_uniform_scaling_{s}\"\n",
    "        if (ds_root / d).is_dir():\n",
    "            cases.append((f\"scale_{s}\", d))\n",
    "\n",
    "    for k in JITTER_PATTERNS:\n",
    "        d = f\"labels_boundary_jitter_{k}\"\n",
    "        if (ds_root / d).is_dir():\n",
    "            cases.append((f\"side_{k}\", d))\n",
    "\n",
    "    return cases\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ✅ Determine train/val labels dir (used directly by Cell 2)\n",
    "# -------------------------------------------------------------------------\n",
    "def resolve_split_label_dirs(ds_root: Path, train_tag: str, val_tag: str) -> Tuple[Path, Path]:\n",
    "    labels_root = ds_root / \"labels\"\n",
    "\n",
    "    cand_train = labels_root / train_tag\n",
    "    cand_val   = labels_root / val_tag\n",
    "\n",
    "    train_labels_dir = cand_train if cand_train.is_dir() else labels_root\n",
    "    val_labels_dir   = cand_val   if cand_val.is_dir()   else labels_root\n",
    "\n",
    "    return train_labels_dir, val_labels_dir\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ✅ Label statistics (quick group count estimation)\n",
    "# -------------------------------------------------------------------------\n",
    "def count_label_files_and_boxes(label_dir: Optional[Path]) -> Tuple[int, int]:\n",
    "    if label_dir is None or not Path(label_dir).exists():\n",
    "        return 0, 0\n",
    "    label_dir = Path(label_dir)\n",
    "    txts = sorted(label_dir.rglob(\"*.txt\"))\n",
    "    n_files = len(txts)\n",
    "    n_boxes = 0\n",
    "    for t in txts:\n",
    "        try:\n",
    "            with open(t, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        n_boxes += 1\n",
    "        except Exception:\n",
    "            continue\n",
    "    return n_files, n_boxes\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# SKU-110K virtual split count\n",
    "# -------------------------------------------------------------------------\n",
    "def compute_sku_virtual_counts(images_root: Path, seed: int = 42, ratio: float = 0.8) -> Tuple[int, int]:\n",
    "    imgs = list_images(images_root)\n",
    "    n = len(imgs)\n",
    "    if n == 0:\n",
    "        return 0, 0\n",
    "    rnd = random.Random(seed)\n",
    "    idxs = list(range(n))\n",
    "    rnd.shuffle(idxs)\n",
    "    cut = int(n * ratio)\n",
    "    n_train = cut\n",
    "    n_val = n - cut\n",
    "    return n_train, n_val\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Discover dataset roots\n",
    "# -------------------------------------------------------------------------\n",
    "set_seed(SEED)\n",
    "\n",
    "specs = discover_det_datasets(LOAD_DIR)\n",
    "roots: List[Path] = []\n",
    "for s in specs:\n",
    "    r = Path(s.root)\n",
    "    if r not in roots:\n",
    "        roots.append(r)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"[DISCOVERY] Found {len(roots)} unique dataset roots under: {Path(LOAD_DIR).resolve()}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Per-dataset summary\n",
    "# -------------------------------------------------------------------------\n",
    "dataset_summaries: List[Dict] = []\n",
    "\n",
    "for ds_root in roots:\n",
    "    ds_root = Path(ds_root)\n",
    "    images_root = ds_root / \"images\"\n",
    "    labels_root = ds_root / \"labels\"\n",
    "\n",
    "    if not images_root.is_dir() or not labels_root.is_dir():\n",
    "        print(f\"⏭️  Skip (missing images/labels): {ds_root}\")\n",
    "        continue\n",
    "\n",
    "    split_info = detect_split_dirs(ds_root)\n",
    "    train_dir = split_info[\"train_img_dir\"]\n",
    "    val_dir   = split_info[\"val_img_dir\"]\n",
    "    split_mode = split_info[\"split_mode\"]\n",
    "    train_tag  = split_info.get(\"train_tag\", \"train\")\n",
    "    val_tag    = split_info.get(\"val_tag\", \"val\")\n",
    "\n",
    "    # --- Calculate image count ---\n",
    "    if split_mode == \"sku_virtual_8_2\":\n",
    "        n_train, n_val = compute_sku_virtual_counts(images_root, seed=SEED, ratio=0.8)\n",
    "    else:\n",
    "        n_train = len(list_images(train_dir))\n",
    "        n_val   = len(list_images(val_dir)) if val_dir else 0\n",
    "\n",
    "    # --- Confirm labels split dir ---\n",
    "    train_labels_dir, val_labels_dir = resolve_split_label_dirs(ds_root, train_tag, val_tag)\n",
    "\n",
    "    # --- Label statistics ---\n",
    "    n_train_label_files, n_train_boxes = count_label_files_and_boxes(train_labels_dir)\n",
    "    n_val_label_files,   n_val_boxes   = count_label_files_and_boxes(val_labels_dir)\n",
    "\n",
    "    # group count estimate (for practical absn conversion)\n",
    "    n_train_groups_est = n_train_boxes\n",
    "\n",
    "    cases = list_label_cases_for_dataset(ds_root)\n",
    "    class_names = infer_class_names_from_labels(labels_root)\n",
    "    nc = len(class_names)\n",
    "\n",
    "    info = {\n",
    "        \"dataset\": ds_root.name,\n",
    "        \"root\": str(ds_root),\n",
    "        \"images_root\": str(images_root),\n",
    "        \"labels_root\": str(labels_root),\n",
    "\n",
    "        \"train_dir\": str(train_dir) if train_dir else None,\n",
    "        \"val_dir\": str(val_dir) if val_dir else None,\n",
    "\n",
    "        # ✅ Used directly by Cell 2\n",
    "        \"train_labels_dir\": str(train_labels_dir) if train_labels_dir else None,\n",
    "        \"val_labels_dir\": str(val_labels_dir) if val_labels_dir else None,\n",
    "\n",
    "        \"n_train\": n_train,\n",
    "        \"n_val\": n_val,\n",
    "\n",
    "        # ✅ Label statistics\n",
    "        \"n_train_label_files\": n_train_label_files,\n",
    "        \"n_val_label_files\": n_val_label_files,\n",
    "        \"n_train_boxes\": n_train_boxes,\n",
    "        \"n_val_boxes\": n_val_boxes,\n",
    "        \"n_train_groups_est\": n_train_groups_est,\n",
    "\n",
    "        \"split_mode\": split_mode,\n",
    "        \"train_tag\": train_tag,\n",
    "        \"val_tag\": val_tag,\n",
    "        \"label_cases\": [c[0] for c in cases],\n",
    "        \"nc_inferred\": nc,\n",
    "        \"class_names_inferred\": class_names,\n",
    "    }\n",
    "    dataset_summaries.append(info)\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(f\"[Dataset] {ds_root.name}\")\n",
    "    print(f\" - root        : {ds_root}\")\n",
    "    print(f\" - split_mode  : {split_mode}\")\n",
    "    print(f\" - train_dir   : {train_dir if train_dir else '(missing)'} | tag={train_tag} | n_train={n_train}\")\n",
    "    print(f\" - val_dir     : {val_dir if val_dir else '(missing)'} | tag={val_tag} | n_val={n_val}\")\n",
    "\n",
    "    test_dir = split_info.get(\"test_img_dir\", None)\n",
    "    if test_dir and test_dir.is_dir():\n",
    "        n_test = len(list_images(test_dir))\n",
    "        print(f\" - test_dir    : {test_dir} | n_test={n_test}\")\n",
    "\n",
    "    print(f\" - train_labels_dir : {train_labels_dir}\")\n",
    "    print(f\" - val_labels_dir   : {val_labels_dir}\")\n",
    "    print(f\" - train label files/boxes/groups_est : {n_train_label_files} / {n_train_boxes} / {n_train_groups_est}\")\n",
    "    print(f\" - val   label files/boxes           : {n_val_label_files} / {n_val_boxes}\")\n",
    "\n",
    "    print(f\" - label_cases : {[c[0] for c in cases] if cases else '(none)'}\")\n",
    "    print(f\" - inferred classes (multiclass-based): nc={nc}, names={class_names}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n✅ Cell 1 done.\")\n",
    "print(f\"   -> dataset_summaries length = {len(dataset_summaries)}\")\n",
    "print(\"   -> roots variable is ready for Cell 2.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05933360",
   "metadata": {},
   "source": [
    "# Load SAM model weights & perform refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52788f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================================================================\n",
      "[DATASET] kitti | case_id=SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8 | noise_cases=13 | splits=['train', 'val']\n",
      "          output => SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8\n",
      "==============================================================================================================\n",
      "  - refine labels_uniform_scaling_0.6 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/train\n",
      "  - refine labels_uniform_scaling_0.6 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/val\n",
      "  - refine labels_uniform_scaling_0.7 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/train\n",
      "  - refine labels_uniform_scaling_0.7 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/val\n",
      "  - refine labels_uniform_scaling_0.8 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/train\n",
      "  - refine labels_uniform_scaling_0.8 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/val\n",
      "  - refine labels_uniform_scaling_0.9 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/train\n",
      "  - refine labels_uniform_scaling_0.9 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/val\n",
      "  - refine labels_uniform_scaling_1.1 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/train\n",
      "  - refine labels_uniform_scaling_1.1 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/val\n",
      "  - refine labels_uniform_scaling_1.2 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/train\n",
      "  - refine labels_uniform_scaling_1.2 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/val\n",
      "  - refine labels_uniform_scaling_1.3 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/train\n",
      "  - refine labels_uniform_scaling_1.3 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/val\n",
      "  - refine labels_uniform_scaling_1.4 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/train\n",
      "  - refine labels_uniform_scaling_1.4 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/val\n",
      "  - refine labels_boundary_jitter_1 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/train\n",
      "  - refine labels_boundary_jitter_1 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/val\n",
      "  - refine labels_boundary_jitter_3 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/train\n",
      "  - refine labels_boundary_jitter_3 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/val\n",
      "  - refine labels_boundary_jitter_5 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/train\n",
      "  - refine labels_boundary_jitter_5 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/val\n",
      "  - refine labels_boundary_jitter_7 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/train\n",
      "  - refine labels_boundary_jitter_7 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/val\n",
      "  - refine labels_boundary_jitter_9 / train | files=5985\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/train\n",
      "  - refine labels_boundary_jitter_9 / val | files=1496\n",
      "    -> save to: SAM_refine_final/refines/kitti/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/val\n",
      "\n",
      "==============================================================================================================\n",
      "[DATASET] homeobjects-3K | case_id=SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8 | noise_cases=13 | splits=['train', 'val']\n",
      "          output => SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8\n",
      "==============================================================================================================\n",
      "  - refine labels_uniform_scaling_0.6 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/train\n",
      "  - refine labels_uniform_scaling_0.6 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/val\n",
      "  - refine labels_uniform_scaling_0.7 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/train\n",
      "  - refine labels_uniform_scaling_0.7 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/val\n",
      "  - refine labels_uniform_scaling_0.8 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/train\n",
      "  - refine labels_uniform_scaling_0.8 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/val\n",
      "  - refine labels_uniform_scaling_0.9 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/train\n",
      "  - refine labels_uniform_scaling_0.9 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/val\n",
      "  - refine labels_uniform_scaling_1.1 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/train\n",
      "  - refine labels_uniform_scaling_1.1 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/val\n",
      "  - refine labels_uniform_scaling_1.2 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/train\n",
      "  - refine labels_uniform_scaling_1.2 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/val\n",
      "  - refine labels_uniform_scaling_1.3 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/train\n",
      "  - refine labels_uniform_scaling_1.3 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/val\n",
      "  - refine labels_uniform_scaling_1.4 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/train\n",
      "  - refine labels_uniform_scaling_1.4 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/val\n",
      "  - refine labels_boundary_jitter_1 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/train\n",
      "  - refine labels_boundary_jitter_1 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/val\n",
      "  - refine labels_boundary_jitter_3 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/train\n",
      "  - refine labels_boundary_jitter_3 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/val\n",
      "  - refine labels_boundary_jitter_5 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/train\n",
      "  - refine labels_boundary_jitter_5 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/val\n",
      "  - refine labels_boundary_jitter_7 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/train\n",
      "  - refine labels_boundary_jitter_7 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/val\n",
      "  - refine labels_boundary_jitter_9 / train | files=2285\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/train\n",
      "  - refine labels_boundary_jitter_9 / val | files=404\n",
      "    -> save to: SAM_refine_final/refines/homeobjects-3K/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/val\n",
      "\n",
      "==============================================================================================================\n",
      "[DATASET] african-wildlife | case_id=SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8 | noise_cases=13 | splits=['train', 'val']\n",
      "          output => SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8\n",
      "==============================================================================================================\n",
      "  - refine labels_uniform_scaling_0.6 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/train\n",
      "  - refine labels_uniform_scaling_0.6 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/val\n",
      "  - refine labels_uniform_scaling_0.7 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/train\n",
      "  - refine labels_uniform_scaling_0.7 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/val\n",
      "  - refine labels_uniform_scaling_0.8 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/train\n",
      "  - refine labels_uniform_scaling_0.8 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/val\n",
      "  - refine labels_uniform_scaling_0.9 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/train\n",
      "  - refine labels_uniform_scaling_0.9 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/val\n",
      "  - refine labels_uniform_scaling_1.1 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/train\n",
      "  - refine labels_uniform_scaling_1.1 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/val\n",
      "  - refine labels_uniform_scaling_1.2 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/train\n",
      "  - refine labels_uniform_scaling_1.2 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/val\n",
      "  - refine labels_uniform_scaling_1.3 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/train\n",
      "  - refine labels_uniform_scaling_1.3 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/val\n",
      "  - refine labels_uniform_scaling_1.4 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/train\n",
      "  - refine labels_uniform_scaling_1.4 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/val\n",
      "  - refine labels_boundary_jitter_1 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/train\n",
      "  - refine labels_boundary_jitter_1 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/val\n",
      "  - refine labels_boundary_jitter_3 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/train\n",
      "  - refine labels_boundary_jitter_3 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/val\n",
      "  - refine labels_boundary_jitter_5 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/train\n",
      "  - refine labels_boundary_jitter_5 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/val\n",
      "  - refine labels_boundary_jitter_7 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/train\n",
      "  - refine labels_boundary_jitter_7 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/val\n",
      "  - refine labels_boundary_jitter_9 / train | files=1052\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/train\n",
      "  - refine labels_boundary_jitter_9 / val | files=225\n",
      "    -> save to: SAM_refine_final/refines/african-wildlife/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/val\n",
      "\n",
      "==============================================================================================================\n",
      "[DATASET] construction-ppe | case_id=SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8 | noise_cases=13 | splits=['train', 'val']\n",
      "          output => SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8\n",
      "==============================================================================================================\n",
      "  - refine labels_uniform_scaling_0.6 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/train\n",
      "  - refine labels_uniform_scaling_0.6 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/val\n",
      "  - refine labels_uniform_scaling_0.7 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/train\n",
      "  - refine labels_uniform_scaling_0.7 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/val\n",
      "  - refine labels_uniform_scaling_0.8 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/train\n",
      "  - refine labels_uniform_scaling_0.8 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/val\n",
      "  - refine labels_uniform_scaling_0.9 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/train\n",
      "  - refine labels_uniform_scaling_0.9 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/val\n",
      "  - refine labels_uniform_scaling_1.1 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/train\n",
      "  - refine labels_uniform_scaling_1.1 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/val\n",
      "  - refine labels_uniform_scaling_1.2 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/train\n",
      "  - refine labels_uniform_scaling_1.2 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/val\n",
      "  - refine labels_uniform_scaling_1.3 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/train\n",
      "  - refine labels_uniform_scaling_1.3 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/val\n",
      "  - refine labels_uniform_scaling_1.4 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/train\n",
      "  - refine labels_uniform_scaling_1.4 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/val\n",
      "  - refine labels_boundary_jitter_1 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/train\n",
      "  - refine labels_boundary_jitter_1 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/val\n",
      "  - refine labels_boundary_jitter_3 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/train\n",
      "  - refine labels_boundary_jitter_3 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/val\n",
      "  - refine labels_boundary_jitter_5 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/train\n",
      "  - refine labels_boundary_jitter_5 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/val\n",
      "  - refine labels_boundary_jitter_7 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/train\n",
      "  - refine labels_boundary_jitter_7 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/val\n",
      "  - refine labels_boundary_jitter_9 / train | files=1142\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/train\n",
      "  - refine labels_boundary_jitter_9 / val | files=143\n",
      "    -> save to: SAM_refine_final/refines/construction-ppe/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/val\n",
      "\n",
      "==============================================================================================================\n",
      "[DATASET] brain-tumor | case_id=SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8 | noise_cases=13 | splits=['train', 'val']\n",
      "          output => SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8\n",
      "==============================================================================================================\n",
      "  - refine labels_uniform_scaling_0.6 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/train\n",
      "  - refine labels_uniform_scaling_0.6 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/val\n",
      "  - refine labels_uniform_scaling_0.7 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/train\n",
      "  - refine labels_uniform_scaling_0.7 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/val\n",
      "  - refine labels_uniform_scaling_0.8 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/train\n",
      "  - refine labels_uniform_scaling_0.8 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/val\n",
      "  - refine labels_uniform_scaling_0.9 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/train\n",
      "  - refine labels_uniform_scaling_0.9 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/val\n",
      "  - refine labels_uniform_scaling_1.1 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/train\n",
      "  - refine labels_uniform_scaling_1.1 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/val\n",
      "  - refine labels_uniform_scaling_1.2 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/train\n",
      "  - refine labels_uniform_scaling_1.2 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/val\n",
      "  - refine labels_uniform_scaling_1.3 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/train\n",
      "  - refine labels_uniform_scaling_1.3 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/val\n",
      "  - refine labels_uniform_scaling_1.4 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/train\n",
      "  - refine labels_uniform_scaling_1.4 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/val\n",
      "  - refine labels_boundary_jitter_1 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/train\n",
      "  - refine labels_boundary_jitter_1 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/val\n",
      "  - refine labels_boundary_jitter_3 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/train\n",
      "  - refine labels_boundary_jitter_3 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/val\n",
      "  - refine labels_boundary_jitter_5 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/train\n",
      "  - refine labels_boundary_jitter_5 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/val\n",
      "  - refine labels_boundary_jitter_7 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/train\n",
      "  - refine labels_boundary_jitter_7 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/val\n",
      "  - refine labels_boundary_jitter_9 / train | files=878\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/train\n",
      "  - refine labels_boundary_jitter_9 / val | files=223\n",
      "    -> save to: SAM_refine_final/refines/brain-tumor/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/val\n",
      "\n",
      "==============================================================================================================\n",
      "[DATASET] BCCD | case_id=SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8 | noise_cases=13 | splits=['train', 'val']\n",
      "          output => SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8\n",
      "==============================================================================================================\n",
      "  - refine labels_uniform_scaling_0.6 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/train\n",
      "  - refine labels_uniform_scaling_0.6 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/val\n",
      "  - refine labels_uniform_scaling_0.7 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/train\n",
      "  - refine labels_uniform_scaling_0.7 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/val\n",
      "  - refine labels_uniform_scaling_0.8 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/train\n",
      "  - refine labels_uniform_scaling_0.8 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/val\n",
      "  - refine labels_uniform_scaling_0.9 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/train\n",
      "  - refine labels_uniform_scaling_0.9 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/val\n",
      "  - refine labels_uniform_scaling_1.1 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/train\n",
      "  - refine labels_uniform_scaling_1.1 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/val\n",
      "  - refine labels_uniform_scaling_1.2 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/train\n",
      "  - refine labels_uniform_scaling_1.2 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/val\n",
      "  - refine labels_uniform_scaling_1.3 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/train\n",
      "  - refine labels_uniform_scaling_1.3 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/val\n",
      "  - refine labels_uniform_scaling_1.4 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/train\n",
      "  - refine labels_uniform_scaling_1.4 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/val\n",
      "  - refine labels_boundary_jitter_1 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/train\n",
      "  - refine labels_boundary_jitter_1 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/val\n",
      "  - refine labels_boundary_jitter_3 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/train\n",
      "  - refine labels_boundary_jitter_3 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/val\n",
      "  - refine labels_boundary_jitter_5 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/train\n",
      "  - refine labels_boundary_jitter_5 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/val\n",
      "  - refine labels_boundary_jitter_7 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/train\n",
      "  - refine labels_boundary_jitter_7 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/val\n",
      "  - refine labels_boundary_jitter_9 / train | files=310\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/train\n",
      "  - refine labels_boundary_jitter_9 / val | files=54\n",
      "    -> save to: SAM_refine_final/refines/BCCD/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/val\n",
      "\n",
      "==============================================================================================================\n",
      "[DATASET] signature | case_id=SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8 | noise_cases=13 | splits=['train', 'val']\n",
      "          output => SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8\n",
      "==============================================================================================================\n",
      "  - refine labels_uniform_scaling_0.6 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/train\n",
      "  - refine labels_uniform_scaling_0.6 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/val\n",
      "  - refine labels_uniform_scaling_0.7 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/train\n",
      "  - refine labels_uniform_scaling_0.7 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/val\n",
      "  - refine labels_uniform_scaling_0.8 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/train\n",
      "  - refine labels_uniform_scaling_0.8 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/val\n",
      "  - refine labels_uniform_scaling_0.9 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/train\n",
      "  - refine labels_uniform_scaling_0.9 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/val\n",
      "  - refine labels_uniform_scaling_1.1 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/train\n",
      "  - refine labels_uniform_scaling_1.1 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/val\n",
      "  - refine labels_uniform_scaling_1.2 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/train\n",
      "  - refine labels_uniform_scaling_1.2 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/val\n",
      "  - refine labels_uniform_scaling_1.3 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/train\n",
      "  - refine labels_uniform_scaling_1.3 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/val\n",
      "  - refine labels_uniform_scaling_1.4 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/train\n",
      "  - refine labels_uniform_scaling_1.4 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/val\n",
      "  - refine labels_boundary_jitter_1 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/train\n",
      "  - refine labels_boundary_jitter_1 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/val\n",
      "  - refine labels_boundary_jitter_3 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/train\n",
      "  - refine labels_boundary_jitter_3 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/val\n",
      "  - refine labels_boundary_jitter_5 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/train\n",
      "  - refine labels_boundary_jitter_5 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/val\n",
      "  - refine labels_boundary_jitter_7 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/train\n",
      "  - refine labels_boundary_jitter_7 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/val\n",
      "  - refine labels_boundary_jitter_9 / train | files=143\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/train\n",
      "  - refine labels_boundary_jitter_9 / val | files=35\n",
      "    -> save to: SAM_refine_final/refines/signature/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/val\n",
      "\n",
      "==============================================================================================================\n",
      "[DATASET] medical-pills | case_id=SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8 | noise_cases=13 | splits=['train', 'val']\n",
      "          output => SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8\n",
      "==============================================================================================================\n",
      "  - refine labels_uniform_scaling_0.6 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/train\n",
      "  - refine labels_uniform_scaling_0.6 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/val\n",
      "  - refine labels_uniform_scaling_0.7 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/train\n",
      "  - refine labels_uniform_scaling_0.7 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/val\n",
      "  - refine labels_uniform_scaling_0.8 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/train\n",
      "  - refine labels_uniform_scaling_0.8 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/val\n",
      "  - refine labels_uniform_scaling_0.9 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/train\n",
      "  - refine labels_uniform_scaling_0.9 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/val\n",
      "  - refine labels_uniform_scaling_1.1 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/train\n",
      "  - refine labels_uniform_scaling_1.1 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/val\n",
      "  - refine labels_uniform_scaling_1.2 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/train\n",
      "  - refine labels_uniform_scaling_1.2 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/val\n",
      "  - refine labels_uniform_scaling_1.3 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/train\n",
      "  - refine labels_uniform_scaling_1.3 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/val\n",
      "  - refine labels_uniform_scaling_1.4 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/train\n",
      "  - refine labels_uniform_scaling_1.4 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/val\n",
      "  - refine labels_boundary_jitter_1 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/train\n",
      "  - refine labels_boundary_jitter_1 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/val\n",
      "  - refine labels_boundary_jitter_3 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/train\n",
      "  - refine labels_boundary_jitter_3 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/val\n",
      "  - refine labels_boundary_jitter_5 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/train\n",
      "  - refine labels_boundary_jitter_5 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/val\n",
      "  - refine labels_boundary_jitter_7 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/train\n",
      "  - refine labels_boundary_jitter_7 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/val\n",
      "  - refine labels_boundary_jitter_9 / train | files=92\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/train\n",
      "  - refine labels_boundary_jitter_9 / val | files=23\n",
      "    -> save to: SAM_refine_final/refines/medical-pills/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/val\n",
      "\n",
      "==============================================================================================================\n",
      "[DATASET] VOC | case_id=SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8 | noise_cases=13 | splits=['train2007', 'train2012', 'val2007', 'val2012']\n",
      "          output => SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8\n",
      "==============================================================================================================\n",
      "  - refine labels_uniform_scaling_0.6 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/train2007\n",
      "  - refine labels_uniform_scaling_0.6 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/train2012\n",
      "  - refine labels_uniform_scaling_0.6 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/val2007\n",
      "  - refine labels_uniform_scaling_0.6 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.6/val2012\n",
      "  - refine labels_uniform_scaling_0.7 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/train2007\n",
      "  - refine labels_uniform_scaling_0.7 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/train2012\n",
      "  - refine labels_uniform_scaling_0.7 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/val2007\n",
      "  - refine labels_uniform_scaling_0.7 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.7/val2012\n",
      "  - refine labels_uniform_scaling_0.8 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/train2007\n",
      "  - refine labels_uniform_scaling_0.8 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/train2012\n",
      "  - refine labels_uniform_scaling_0.8 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/val2007\n",
      "  - refine labels_uniform_scaling_0.8 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.8/val2012\n",
      "  - refine labels_uniform_scaling_0.9 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/train2007\n",
      "  - refine labels_uniform_scaling_0.9 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/train2012\n",
      "  - refine labels_uniform_scaling_0.9 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/val2007\n",
      "  - refine labels_uniform_scaling_0.9 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_0.9/val2012\n",
      "  - refine labels_uniform_scaling_1.1 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/train2007\n",
      "  - refine labels_uniform_scaling_1.1 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/train2012\n",
      "  - refine labels_uniform_scaling_1.1 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/val2007\n",
      "  - refine labels_uniform_scaling_1.1 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.1/val2012\n",
      "  - refine labels_uniform_scaling_1.2 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/train2007\n",
      "  - refine labels_uniform_scaling_1.2 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/train2012\n",
      "  - refine labels_uniform_scaling_1.2 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/val2007\n",
      "  - refine labels_uniform_scaling_1.2 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.2/val2012\n",
      "  - refine labels_uniform_scaling_1.3 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/train2007\n",
      "  - refine labels_uniform_scaling_1.3 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/train2012\n",
      "  - refine labels_uniform_scaling_1.3 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/val2007\n",
      "  - refine labels_uniform_scaling_1.3 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.3/val2012\n",
      "  - refine labels_uniform_scaling_1.4 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/train2007\n",
      "  - refine labels_uniform_scaling_1.4 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/train2012\n",
      "  - refine labels_uniform_scaling_1.4 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/val2007\n",
      "  - refine labels_uniform_scaling_1.4 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_uniform_scaling_1.4/val2012\n",
      "  - refine labels_boundary_jitter_1 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/train2007\n",
      "  - refine labels_boundary_jitter_1 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/train2012\n",
      "  - refine labels_boundary_jitter_1 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/val2007\n",
      "  - refine labels_boundary_jitter_1 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_1/val2012\n",
      "  - refine labels_boundary_jitter_3 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/train2007\n",
      "  - refine labels_boundary_jitter_3 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/train2012\n",
      "  - refine labels_boundary_jitter_3 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/val2007\n",
      "  - refine labels_boundary_jitter_3 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_3/val2012\n",
      "  - refine labels_boundary_jitter_5 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/train2007\n",
      "  - refine labels_boundary_jitter_5 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/train2012\n",
      "  - refine labels_boundary_jitter_5 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/val2007\n",
      "  - refine labels_boundary_jitter_5 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_5/val2012\n",
      "  - refine labels_boundary_jitter_7 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/train2007\n",
      "  - refine labels_boundary_jitter_7 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/train2012\n",
      "  - refine labels_boundary_jitter_7 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/val2007\n",
      "  - refine labels_boundary_jitter_7 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_7/val2012\n",
      "  - refine labels_boundary_jitter_9 / train2007 | files=2501\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/train2007\n",
      "  - refine labels_boundary_jitter_9 / train2012 | files=5717\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/train2012\n",
      "  - refine labels_boundary_jitter_9 / val2007 | files=2510\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/val2007\n",
      "  - refine labels_boundary_jitter_9 / val2012 | files=5823\n",
      "    -> save to: SAM_refine_final/refines/VOC/SAM_vit_h__bexp0__mm1__pickscore__a195a0a8e8/labels_boundary_jitter_9/val2012\n",
      "\n",
      "✅ Metrics are appended incrementally: SAM_refine_final/_refine_summary_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "###### Not modifying all data with SAM / Sampling to verify refinement works for each noise ######\n",
    "\n",
    "# ==========================================\n",
    "# Cell 2) SAM-based Refinement Runner — FINAL (RESUME + PROGRESS + INCREMENTAL METRICS)\n",
    "#  - Refine YOLO boxes using SAM segmentation (box prompt)\n",
    "#  - ONLY covers label_cases: labels_uniform_scaling_* + labels_boundary_jitter_*  (original labels/ is OFF by default)\n",
    "#  - Save refined labels UNDER OUT_ROOT/refines/<dataset>/<case_id>/<noise_name>/<split>/.../*.txt\n",
    "#  - Evaluate IoU vs ORIGINAL clean labels (/datasets/<ds>/labels/...) for files/boxes that exist\n",
    "#  - Do NOT create empty labels for missing files (skip if missing)\n",
    "#\n",
    "# [NEW: RESUME SAFE]\n",
    "#  - If out_lbl_dir has _DONE.json and it's complete => skip that noise/split\n",
    "#  - If interrupted mid-way (no _DONE.json) => resume by skipping existing out txt files\n",
    "#  - Write _PROGRESS.json every N files to track where it stopped\n",
    "#  - Metrics CSV is appended per split (survives crashes), with duplicate-key guard\n",
    "# ==========================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, re, json, gc, hashlib, sys, zipfile, shutil, time, csv\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------------\n",
    "# USER CONFIG\n",
    "# -------------------------\n",
    "DATASETS_ROOT = Path(\"/home/ISW/project/datasets\")\n",
    "\n",
    "OUT_ROOT = Path(\"./SAM_refine_final\")  # Desired experiment root (refines/ save location)\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = \"cuda:1\"\n",
    "\n",
    "TARGET_DATASETS: Optional[List[str]] = [\n",
    "    \"kitti\",\n",
    "    \"homeobjects-3K\",\n",
    "    \"african-wildlife\",\n",
    "    \"construction-ppe\",\n",
    "    # \"Custom_Blood\",\n",
    "    \"brain-tumor\",\n",
    "    \"BCCD\",\n",
    "    \"signature\",\n",
    "    \"medical-pills\",\n",
    "    \"VOC\",\n",
    "]\n",
    "\n",
    "# Target noise label folders for refinement\n",
    "UNIFORM_SCALING_FACTORS   = [0.6, 0.7, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
    "JITTER_PATTERNS  = [1, 3, 5, 7, 9]\n",
    "\n",
    "# Set True to refine original labels/ as well\n",
    "INCLUDE_ORIGINAL_LABELS = False\n",
    "\n",
    "# split selection (includes val2012/valid2012)\n",
    "REFINE_SPLITS = [\"train\", \"val\", \"valid\"]   # includes train/val/valid prefix\n",
    "MAX_FILES_PER_SPLIT: Optional[int] = None   # None=all (recommend limiting for large datasets)\n",
    "OVERWRITE_EXISTING = False\n",
    "WRITE_METRICS_CSV = True\n",
    "\n",
    "# -------------------------\n",
    "# RESUME / PROGRESS (NEW)\n",
    "# -------------------------\n",
    "RESUME_MODE = True                 # If True, skip files when out_lbl_path exists (resume execution)\n",
    "VERIFY_EXISTING_OUT_LABELS = False # If True, regenerate even if out_lbl_path exists but YOLO parsing fails/corrupt\n",
    "PROGRESS_EVERY = 50                # Update _PROGRESS.json every N files processed\n",
    "WRITE_METRICS_INCREMENTAL = True   # Append to metrics CSV per split completion (records remain even on mid-termination)\n",
    "METRICS_CSV_PATH = OUT_ROOT / \"_refine_summary_metrics.csv\"\n",
    "METRICS_KEY_COLS = (\"dataset\", \"case_id\", \"noise_name\", \"split\")  # Key for preventing duplicates\n",
    "\n",
    "# SAM config\n",
    "SAM_MODEL_TYPE = \"vit_h\"  # \"vit_h\" | \"vit_l\" | \"vit_b\"\n",
    "SAM_CKPT_PATH  = \"/home/ISW/project/checkpoints/sam_vit_h_4b8939.pth\"  # <-- Modify to your own path\n",
    "\n",
    "# refinement knobs\n",
    "BOX_EXPAND_RATIO = 0.0     # Slightly expand SAM box prompt (include boundaries)\n",
    "MIN_BOX_WH_PIX   = 2       # Skip/fallback too small boxes\n",
    "MASK_TO_BOX_PAD  = 0       # Padding pixels for mask->bbox conversion (recommend 0)\n",
    "USE_MULTIMASK    = True    # SAM multimask_output=True\n",
    "PICK_BY          = \"score\" # \"score\" | \"area\" (multimask selection criterion)\n",
    "\n",
    "REFINES_OUT_ROOT = OUT_ROOT / \"refines\"\n",
    "REFINES_OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_EXTS = [\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\"]\n",
    "YOLO_RE = re.compile(r\"^\\s*(\\d+)\\s+([\\d\\.eE+-]+)\\s+([\\d\\.eE+-]+)\\s+([\\d\\.eE+-]+)\\s+([\\d\\.eE+-]+)\")\n",
    "\n",
    "# -------------------------\n",
    "# EASY SAM LIB LOADER (NO GIT REQUIRED)\n",
    "# -------------------------\n",
    "SAM_DEPS_DIR = OUT_ROOT / \"_deps\"\n",
    "SAM_DEPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOCAL_SAM_ZIP_CANDIDATES = [\n",
    "    Path(\"segment-anything-main.zip\"),\n",
    "    Path(\"segment-anything.zip\"),\n",
    "]\n",
    "\n",
    "LOCAL_SAM_DIR_CANDIDATES = [\n",
    "    Path(\"segment-anything-main\"),\n",
    "    Path(\"segment-anything\"),\n",
    "    SAM_DEPS_DIR / \"segment-anything-main\",\n",
    "]\n",
    "\n",
    "AUTO_DOWNLOAD_SAM_ZIP = True\n",
    "SAM_GITHUB_ZIP_URL = \"https://github.com/facebookresearch/segment-anything/archive/refs/heads/main.zip\"\n",
    "\n",
    "def _add_syspath(p: Path):\n",
    "    p = p.resolve()\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "\n",
    "def _extract_zip(zip_path: Path, out_dir: Path) -> Path:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "        zf.extractall(out_dir)\n",
    "\n",
    "    cand = []\n",
    "    for p in out_dir.rglob(\"segment_anything\"):\n",
    "        if p.is_dir():\n",
    "            cand.append(p.parent)\n",
    "    if not cand:\n",
    "        raise RuntimeError(f\"Zip extracted but cannot find 'segment_anything/' inside: {zip_path}\")\n",
    "\n",
    "    repo_root = sorted(cand, key=lambda x: len(str(x)))[0]\n",
    "    return repo_root\n",
    "\n",
    "def ensure_segment_anything_importable() -> None:\n",
    "    try:\n",
    "        import segment_anything  # noqa\n",
    "        return\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    for d in LOCAL_SAM_DIR_CANDIDATES:\n",
    "        if d.is_dir() and (d / \"segment_anything\").is_dir():\n",
    "            _add_syspath(d)\n",
    "            try:\n",
    "                import segment_anything  # noqa\n",
    "                print(f\"[SAM] using local repo dir: {d}\")\n",
    "                return\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    for z in LOCAL_SAM_ZIP_CANDIDATES:\n",
    "        if z.is_file():\n",
    "            try:\n",
    "                repo_root = _extract_zip(z, SAM_DEPS_DIR)\n",
    "                _add_syspath(repo_root)\n",
    "                import segment_anything  # noqa\n",
    "                print(f\"[SAM] extracted from local zip: {z} -> {repo_root}\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"[SAM] found local zip but failed to use it: {z}\\nReason: {e}\")\n",
    "\n",
    "    if AUTO_DOWNLOAD_SAM_ZIP:\n",
    "        try:\n",
    "            import urllib.request\n",
    "            zip_path = SAM_DEPS_DIR / \"segment-anything-main.zip\"\n",
    "            if not zip_path.exists():\n",
    "                print(f\"[SAM] downloading zip: {SAM_GITHUB_ZIP_URL}\")\n",
    "                urllib.request.urlretrieve(SAM_GITHUB_ZIP_URL, str(zip_path))\n",
    "                print(f\"[SAM] downloaded: {zip_path}\")\n",
    "\n",
    "            repo_root = _extract_zip(zip_path, SAM_DEPS_DIR)\n",
    "            _add_syspath(repo_root)\n",
    "            import segment_anything  # noqa\n",
    "            print(f\"[SAM] extracted from downloaded zip -> {repo_root}\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                \"[SAM] segment_anything import failed + auto download/install also failed.\\n\"\n",
    "                \"Alternatives:\\n\"\n",
    "                \"  (A) Download segment-anything-main.zip directly in internet-enabled environment and place in current folder\\n\"\n",
    "                \"  (B) Extract zip and place segment-anything-main/ folder in current folder\\n\"\n",
    "                \"  (C) Or request git installation from administrator\\n\"\n",
    "                f\"Cause: {e}\"\n",
    "            )\n",
    "\n",
    "    raise RuntimeError(\n",
    "        \"[SAM] segment_anything import failed.\\n\"\n",
    "        \"Solution:\\n\"\n",
    "        \"  - Place segment-anything-main/ folder (containing segment_anything/) in current directory, or\\n\"\n",
    "        \"  - Place segment-anything-main.zip in current directory and run again.\\n\"\n",
    "        \"  - Or set AUTO_DOWNLOAD_SAM_ZIP=True.\"\n",
    "    )\n",
    "\n",
    "ensure_segment_anything_importable()\n",
    "from segment_anything import sam_model_registry, SamPredictor  # noqa: E402\n",
    "\n",
    "# -------------------------\n",
    "# Utils: dataset layout (robust)\n",
    "# -------------------------\n",
    "def resolve_dataset_root(dataset_name: str) -> Optional[Path]:\n",
    "    cand = DATASETS_ROOT / dataset_name\n",
    "    if cand.exists():\n",
    "        return cand\n",
    "    lname = dataset_name.lower()\n",
    "    for d in DATASETS_ROOT.iterdir():\n",
    "        if d.is_dir() and d.name.lower() == lname:\n",
    "            return d\n",
    "    alt = dataset_name.replace(\"3K\", \"3k\").replace(\"3k\", \"3K\")\n",
    "    cand2 = DATASETS_ROOT / alt\n",
    "    if cand2.exists():\n",
    "        return cand2\n",
    "    for d in DATASETS_ROOT.iterdir():\n",
    "        if d.is_dir() and d.name.lower() == alt.lower():\n",
    "            return d\n",
    "    return None\n",
    "\n",
    "def list_existing_splits(images_root: Path) -> List[str]:\n",
    "    if not images_root.exists():\n",
    "        return [\"__flat__\"]\n",
    "    subs = sorted([p.name for p in images_root.iterdir() if p.is_dir()])\n",
    "    return subs if subs else [\"__flat__\"]\n",
    "\n",
    "def _split_selected(split: str) -> bool:\n",
    "    if split == \"__flat__\":\n",
    "        return True\n",
    "    if not REFINE_SPLITS:\n",
    "        return True\n",
    "    s = split.lower()\n",
    "    for t in REFINE_SPLITS:\n",
    "        tl = str(t).lower()\n",
    "        if s == tl or s.startswith(tl):\n",
    "            return True\n",
    "    if s.startswith(\"val\") and any(str(t).lower()==\"val\" for t in REFINE_SPLITS):\n",
    "        return True\n",
    "    if s.startswith(\"valid\") and any(str(t).lower()==\"valid\" for t in REFINE_SPLITS):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def resolve_split_dir(base: Path, split: str) -> Path:\n",
    "    return base if split == \"__flat__\" else (base / split)\n",
    "\n",
    "def find_image_for_label(images_dir: Path, rel_lbl_path: Path) -> Optional[Path]:\n",
    "    stem = rel_lbl_path.with_suffix(\"\").as_posix()\n",
    "    for ext in IMG_EXTS:\n",
    "        cand = images_dir / f\"{stem}{ext}\"\n",
    "        if cand.exists():\n",
    "            return cand\n",
    "    return None\n",
    "\n",
    "def read_yolo_txt(p: Optional[Path]) -> List[Tuple[int,float,float,float,float]]:\n",
    "    rows=[]\n",
    "    if p is None or (not p.exists()):\n",
    "        return rows\n",
    "    for ln in p.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines():\n",
    "        m = YOLO_RE.match(ln)\n",
    "        if not m:\n",
    "            continue\n",
    "        cls = int(float(m.group(1)))\n",
    "        cx,cy,w,h = map(float, m.groups()[1:])\n",
    "        rows.append((cls,cx,cy,w,h))\n",
    "    return rows\n",
    "\n",
    "def write_yolo_txt(p: Path, rows: List[Tuple[int,float,float,float,float]]):\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(p, \"w\", encoding=\"utf-8\") as f:\n",
    "        for cls,cx,cy,w,h in rows:\n",
    "            cx = min(max(cx, 0.0), 1.0)\n",
    "            cy = min(max(cy, 0.0), 1.0)\n",
    "            w  = min(max(w,  0.0), 1.0)\n",
    "            h  = min(max(h,  0.0), 1.0)\n",
    "            f.write(f\"{cls} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "def is_valid_yolo_file(p: Path) -> bool:\n",
    "    try:\n",
    "        if not p.exists():\n",
    "            return False\n",
    "        txt = p.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
    "        if txt == \"\":\n",
    "            return True  # empty allowed\n",
    "        for ln in txt.splitlines():\n",
    "            ln = ln.strip()\n",
    "            if ln == \"\":\n",
    "                continue\n",
    "            if YOLO_RE.match(ln) is None:\n",
    "                return False\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# -------------------------\n",
    "# Metrics: IoU (normalized cxcywh)\n",
    "# -------------------------\n",
    "def _to_xyxy(cx, cy, w, h):\n",
    "    return cx - w/2, cy - h/2, cx + w/2, cy + h/2\n",
    "\n",
    "def box_iou(a, b, eps=1e-9) -> float:\n",
    "    ax1, ay1, ax2, ay2 = _to_xyxy(*a)\n",
    "    bx1, by1, bx2, by2 = _to_xyxy(*b)\n",
    "    inter_x1 = max(ax1, bx1); inter_y1 = max(ay1, by1)\n",
    "    inter_x2 = min(ax2, bx2); inter_y2 = min(ay2, by2)\n",
    "    iw = max(0.0, inter_x2 - inter_x1); ih = max(0.0, inter_y2 - inter_y1)\n",
    "    inter = iw * ih\n",
    "    area_a = max(0.0, ax2-ax1) * max(0.0, ay2-ay1)\n",
    "    area_b = max(0.0, bx2-bx1) * max(0.0, by2-by1)\n",
    "    union = area_a + area_b - inter\n",
    "    return float(inter / (union + eps))\n",
    "\n",
    "# -------------------------\n",
    "# label cases: labels_uniform_scaling_* + labels_boundary_jitter_* (and optionally labels/)\n",
    "# -------------------------\n",
    "def iter_label_case_dirs(dataset_root: Path) -> List[Tuple[str, Path]]:\n",
    "    out: List[Tuple[str, Path]] = []\n",
    "\n",
    "    if INCLUDE_ORIGINAL_LABELS and (dataset_root / \"labels\").is_dir():\n",
    "        out.append((\"labels\", dataset_root / \"labels\"))\n",
    "\n",
    "    for s in UNIFORM_SCALING_FACTORS:\n",
    "        name = f\"labels_uniform_scaling_{s:g}\"\n",
    "        p = dataset_root / name\n",
    "        if p.is_dir():\n",
    "            out.append((name, p))\n",
    "\n",
    "    for k in JITTER_PATTERNS:\n",
    "        name = f\"labels_boundary_jitter_{int(k)}\"\n",
    "        p = dataset_root / name\n",
    "        if p.is_dir():\n",
    "            out.append((name, p))\n",
    "\n",
    "    return out\n",
    "\n",
    "# -------------------------\n",
    "# case_id for SAM run (no best.pt)\n",
    "# -------------------------\n",
    "def make_sam_case_id() -> str:\n",
    "    cfg = {\n",
    "        \"sam_type\": SAM_MODEL_TYPE,\n",
    "        \"box_expand\": BOX_EXPAND_RATIO,\n",
    "        \"multimask\": bool(USE_MULTIMASK),\n",
    "        \"pick_by\": PICK_BY,\n",
    "        \"mask_to_box_pad\": MASK_TO_BOX_PAD,\n",
    "        \"min_box_wh_pix\": MIN_BOX_WH_PIX,\n",
    "    }\n",
    "    h = hashlib.md5(json.dumps(cfg, sort_keys=True).encode(\"utf-8\")).hexdigest()[:10]\n",
    "    return f\"SAM_{SAM_MODEL_TYPE}__bexp{BOX_EXPAND_RATIO:g}__mm{int(USE_MULTIMASK)}__pick{PICK_BY}__{h}\"\n",
    "\n",
    "# -------------------------\n",
    "# SAM helper: yolo->pixel, expand, mask->box\n",
    "# -------------------------\n",
    "def yolo_to_xyxy_pix(cx, cy, w, h, W, H) -> Tuple[int,int,int,int]:\n",
    "    x1 = int(round((cx - w/2) * W))\n",
    "    x2 = int(round((cx + w/2) * W))\n",
    "    y1 = int(round((cy - h/2) * H))\n",
    "    y2 = int(round((cy + h/2) * H))\n",
    "    x1 = max(0, min(W-1, x1))\n",
    "    y1 = max(0, min(H-1, y1))\n",
    "    x2 = max(1, min(W, x2))\n",
    "    y2 = max(1, min(H, y2))\n",
    "    return x1,y1,x2,y2\n",
    "\n",
    "def expand_xyxy(x1,y1,x2,y2,W,H, ratio: float) -> Tuple[int,int,int,int]:\n",
    "    if ratio <= 0:\n",
    "        return x1,y1,x2,y2\n",
    "    bw = x2 - x1\n",
    "    bh = y2 - y1\n",
    "    ex = int(round(bw * ratio))\n",
    "    ey = int(round(bh * ratio))\n",
    "    nx1 = max(0, x1 - ex)\n",
    "    ny1 = max(0, y1 - ey)\n",
    "    nx2 = min(W, x2 + ex)\n",
    "    ny2 = min(H, y2 + ey)\n",
    "    nx2 = max(nx2, nx1+1)\n",
    "    ny2 = max(ny2, ny1+1)\n",
    "    return nx1,ny1,nx2,ny2\n",
    "\n",
    "def xyxy_pix_to_yolo(x1,y1,x2,y2,W,H) -> Tuple[float,float,float,float]:\n",
    "    x1 = max(0, min(W-1, x1))\n",
    "    y1 = max(0, min(H-1, y1))\n",
    "    x2 = max(1, min(W, x2))\n",
    "    y2 = max(1, min(H, y2))\n",
    "    cx = ((x1 + x2) / 2.0) / float(W)\n",
    "    cy = ((y1 + y2) / 2.0) / float(H)\n",
    "    w  = (x2 - x1) / float(W)\n",
    "    h  = (y2 - y1) / float(H)\n",
    "    return float(cx), float(cy), float(w), float(h)\n",
    "\n",
    "def mask_to_xyxy(mask: np.ndarray, pad: int = 0) -> Optional[Tuple[int,int,int,int]]:\n",
    "    ys, xs = np.where(mask.astype(bool))\n",
    "    if xs.size == 0 or ys.size == 0:\n",
    "        return None\n",
    "    x1 = int(xs.min()) - pad\n",
    "    x2 = int(xs.max()) + 1 + pad\n",
    "    y1 = int(ys.min()) - pad\n",
    "    y2 = int(ys.max()) + 1 + pad\n",
    "    return x1,y1,x2,y2\n",
    "\n",
    "# -------------------------\n",
    "# Resume helpers (NEW)\n",
    "# -------------------------\n",
    "def _safe_read_json(p: Path) -> Optional[Dict[str, Any]]:\n",
    "    try:\n",
    "        if p.exists():\n",
    "            return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def _done_marker_seems_complete(done_payload: Optional[Dict[str, Any]]) -> bool:\n",
    "    if not done_payload:\n",
    "        return False\n",
    "    ft = int(done_payload.get(\"files_total\", 0) or 0)\n",
    "    fd = int(done_payload.get(\"files_done\", 0) or 0)\n",
    "    fs = int(done_payload.get(\"files_skipped\", 0) or 0)\n",
    "    # At minimum, if total exists and done+skipped >= total, consider complete\n",
    "    return (ft > 0) and ((fd + fs) >= ft)\n",
    "\n",
    "def load_existing_metric_keys(csv_path: Path) -> set:\n",
    "    keys = set()\n",
    "    if not csv_path.exists():\n",
    "        return keys\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        dfk = pd.read_csv(csv_path, usecols=list(METRICS_KEY_COLS))\n",
    "        for r in dfk.itertuples(index=False):\n",
    "            keys.add(tuple(r))\n",
    "    except Exception:\n",
    "        # If CSV is corrupt: give up key check for append safety (duplicates possible) -> execution still works\n",
    "        return set()\n",
    "    return keys\n",
    "\n",
    "def append_metrics_row_csv(csv_path: Path, row: Dict[str, Any]):\n",
    "    csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    exists = csv_path.exists()\n",
    "    fieldnames = list(row.keys())\n",
    "    with open(csv_path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if not exists:\n",
    "            w.writeheader()\n",
    "        w.writerow(row)\n",
    "\n",
    "# -------------------------\n",
    "# SAM build\n",
    "# -------------------------\n",
    "def build_sam_predictor(device: torch.device) -> SamPredictor:\n",
    "    ckpt = Path(SAM_CKPT_PATH)\n",
    "    if not ckpt.exists():\n",
    "        raise FileNotFoundError(f\"SAM checkpoint not found: {ckpt}\")\n",
    "\n",
    "    sam = sam_model_registry[SAM_MODEL_TYPE](checkpoint=str(ckpt))\n",
    "    sam.to(device=device)\n",
    "    sam.eval()\n",
    "    predictor = SamPredictor(sam)\n",
    "    return predictor\n",
    "\n",
    "def free_cuda():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# -------------------------\n",
    "# Core: refine one file using SAM\n",
    "# -------------------------\n",
    "@torch.inference_mode()\n",
    "def refine_one_label_file_sam(\n",
    "    predictor: SamPredictor,\n",
    "    img_path: Path,\n",
    "    noisy_lbl_path: Path,\n",
    "    clean_lbl_path: Optional[Path],\n",
    "    out_lbl_path: Path,\n",
    ") -> Dict[str, float]:\n",
    "    noisy_rows = read_yolo_txt(noisy_lbl_path)\n",
    "    if len(noisy_rows) == 0:\n",
    "        # noisy label file exists but empty => saving refined empty is OK\n",
    "        if OVERWRITE_EXISTING or (not out_lbl_path.exists()):\n",
    "            write_yolo_txt(out_lbl_path, [])\n",
    "        return {\"n_boxes_eval\": 0.0, \"sum_iou_noisy\": 0.0, \"sum_iou_refined\": 0.0}\n",
    "\n",
    "    clean_rows = read_yolo_txt(clean_lbl_path) if (WRITE_METRICS_CSV and clean_lbl_path is not None and clean_lbl_path.exists()) else None\n",
    "\n",
    "    with Image.open(img_path).convert(\"RGB\") as im:\n",
    "        img_np = np.array(im)\n",
    "        H, W = img_np.shape[0], img_np.shape[1]\n",
    "\n",
    "    predictor.set_image(img_np)\n",
    "\n",
    "    refined_rows: List[Tuple[int,float,float,float,float]] = []\n",
    "    sum_iou_noisy = 0.0\n",
    "    sum_iou_ref   = 0.0\n",
    "    n_boxes_eval = 0\n",
    "\n",
    "    for i, (cls, cx, cy, w, h) in enumerate(noisy_rows):\n",
    "        x1,y1,x2,y2 = yolo_to_xyxy_pix(cx,cy,w,h,W,H)\n",
    "        bw, bh = (x2-x1), (y2-y1)\n",
    "\n",
    "        if bw < MIN_BOX_WH_PIX or bh < MIN_BOX_WH_PIX:\n",
    "            refined_rows.append((cls, cx,cy,w,h))\n",
    "            if clean_rows is not None and i < len(clean_rows):\n",
    "                _, ccx, ccy, cw, ch = clean_rows[i]\n",
    "                clean_box = (ccx, ccy, cw, ch)\n",
    "                noisy_box = (cx, cy, w, h)\n",
    "                sum_iou_noisy += box_iou(noisy_box, clean_box)\n",
    "                sum_iou_ref   += box_iou(noisy_box, clean_box)\n",
    "                n_boxes_eval += 1\n",
    "            continue\n",
    "\n",
    "        x1e,y1e,x2e,y2e = expand_xyxy(x1,y1,x2,y2,W,H, BOX_EXPAND_RATIO)\n",
    "        box = np.array([x1e, y1e, x2e, y2e], dtype=np.float32)\n",
    "\n",
    "        masks, scores, _ = predictor.predict(\n",
    "            box=box,\n",
    "            multimask_output=bool(USE_MULTIMASK),\n",
    "        )\n",
    "\n",
    "        if masks is None or len(masks) == 0:\n",
    "            refined_rows.append((cls, cx,cy,w,h))\n",
    "            if clean_rows is not None and i < len(clean_rows):\n",
    "                _, ccx, ccy, cw, ch = clean_rows[i]\n",
    "                clean_box = (ccx, ccy, cw, ch)\n",
    "                noisy_box = (cx, cy, w, h)\n",
    "                sum_iou_noisy += box_iou(noisy_box, clean_box)\n",
    "                sum_iou_ref   += box_iou(noisy_box, clean_box)\n",
    "                n_boxes_eval += 1\n",
    "            continue\n",
    "\n",
    "        if PICK_BY == \"area\":\n",
    "            areas = [float(m.sum()) for m in masks]\n",
    "            j = int(np.argmax(areas))\n",
    "        else:\n",
    "            j = int(np.argmax(scores)) if scores is not None else 0\n",
    "\n",
    "        best_mask = masks[j]\n",
    "        xyxy = mask_to_xyxy(best_mask, pad=int(MASK_TO_BOX_PAD))\n",
    "\n",
    "        if xyxy is None:\n",
    "            refined_rows.append((cls, cx,cy,w,h))\n",
    "            if clean_rows is not None and i < len(clean_rows):\n",
    "                _, ccx, ccy, cw, ch = clean_rows[i]\n",
    "                clean_box = (ccx, ccy, cw, ch)\n",
    "                noisy_box = (cx, cy, w, h)\n",
    "                sum_iou_noisy += box_iou(noisy_box, clean_box)\n",
    "                sum_iou_ref   += box_iou(noisy_box, clean_box)\n",
    "                n_boxes_eval += 1\n",
    "            continue\n",
    "\n",
    "        mx1,my1,mx2,my2 = xyxy\n",
    "        mx1 = max(0, min(W-1, mx1))\n",
    "        my1 = max(0, min(H-1, my1))\n",
    "        mx2 = max(1, min(W, mx2))\n",
    "        my2 = max(1, min(H, my2))\n",
    "\n",
    "        if (mx2-mx1) < MIN_BOX_WH_PIX or (my2-my1) < MIN_BOX_WH_PIX:\n",
    "            refined_rows.append((cls, cx,cy,w,h))\n",
    "            if clean_rows is not None and i < len(clean_rows):\n",
    "                _, ccx, ccy, cw, ch = clean_rows[i]\n",
    "                clean_box = (ccx, ccy, cw, ch)\n",
    "                noisy_box = (cx, cy, w, h)\n",
    "                sum_iou_noisy += box_iou(noisy_box, clean_box)\n",
    "                sum_iou_ref   += box_iou(noisy_box, clean_box)\n",
    "                n_boxes_eval += 1\n",
    "            continue\n",
    "\n",
    "        rcx, rcy, rw, rh = xyxy_pix_to_yolo(mx1,my1,mx2,my2,W,H)\n",
    "        refined_rows.append((cls, rcx, rcy, rw, rh))\n",
    "\n",
    "        if clean_rows is not None and i < len(clean_rows):\n",
    "            _, ccx, ccy, cw, ch = clean_rows[i]\n",
    "            clean_box = (ccx, ccy, cw, ch)\n",
    "            noisy_box = (cx, cy, w, h)\n",
    "            refined_box = (rcx, rcy, rw, rh)\n",
    "            sum_iou_noisy += box_iou(noisy_box, clean_box)\n",
    "            sum_iou_ref   += box_iou(refined_box, clean_box)\n",
    "            n_boxes_eval += 1\n",
    "\n",
    "    if OVERWRITE_EXISTING or (not out_lbl_path.exists()):\n",
    "        write_yolo_txt(out_lbl_path, refined_rows)\n",
    "\n",
    "    return {\n",
    "        \"n_boxes_eval\": float(n_boxes_eval),\n",
    "        \"sum_iou_noisy\": float(sum_iou_noisy),\n",
    "        \"sum_iou_refined\": float(sum_iou_ref),\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# MAIN\n",
    "# -------------------------\n",
    "device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "predictor = build_sam_predictor(device=device)\n",
    "\n",
    "case_id = make_sam_case_id()\n",
    "all_metrics_rows: List[Dict[str, Any]] = []\n",
    "\n",
    "# (NEW) Load existing metrics keys (prevent duplicate append)\n",
    "existing_metric_keys = load_existing_metric_keys(METRICS_CSV_PATH) if (WRITE_METRICS_CSV and WRITE_METRICS_INCREMENTAL) else set()\n",
    "\n",
    "for dataset in (TARGET_DATASETS or []):\n",
    "    ds_root = resolve_dataset_root(dataset)\n",
    "    if ds_root is None or (not ds_root.exists()):\n",
    "        print(f\"⚠️ Skip missing dataset root: {DATASETS_ROOT/dataset}\")\n",
    "        continue\n",
    "\n",
    "    images_root = ds_root / \"images\"\n",
    "    labels_root = ds_root / \"labels\"  # clean labels (metric reference)\n",
    "    if not images_root.exists() or not labels_root.exists():\n",
    "        print(f\"⚠️ Skip (missing images/labels): {ds_root.name}\")\n",
    "        continue\n",
    "\n",
    "    splits_all = list_existing_splits(images_root)\n",
    "    splits = [s for s in splits_all if _split_selected(s)]\n",
    "    if not splits:\n",
    "        splits = [\"__flat__\"]\n",
    "\n",
    "    label_case_dirs = iter_label_case_dirs(ds_root)\n",
    "    if not label_case_dirs:\n",
    "        print(f\"⚠️ No noise label dirs in {ds_root} (labels_uniform_scaling_* / labels_boundary_jitter_*). Skip.\")\n",
    "        continue\n",
    "\n",
    "    refine_root = REFINES_OUT_ROOT / ds_root.name / case_id\n",
    "    refine_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*110)\n",
    "    print(f\"[DATASET] {ds_root.name} | case_id={case_id} | noise_cases={len(label_case_dirs)} | splits={splits}\")\n",
    "    print(f\"          output => {refine_root}\")\n",
    "    print(\"=\"*110)\n",
    "\n",
    "    for noise_name, noise_dir in label_case_dirs:\n",
    "        for split in splits:\n",
    "            img_dir = resolve_split_dir(images_root, split)\n",
    "            clean_lbl_dir = resolve_split_dir(labels_root, split)\n",
    "            noisy_lbl_dir = resolve_split_dir(noise_dir, split)\n",
    "\n",
    "            # Requirement: if no data, skip instead of creating empty label\n",
    "            if (not img_dir.exists()) or (not noisy_lbl_dir.exists()) or (not clean_lbl_dir.exists()):\n",
    "                continue\n",
    "\n",
    "            out_lbl_dir = refine_root / noise_name / (split if split != \"__flat__\" else \"\")\n",
    "            done_marker = out_lbl_dir / \"_DONE.json\"\n",
    "            progress_marker = out_lbl_dir / \"_PROGRESS.json\"\n",
    "\n",
    "            # (A) Skip if already complete (but supplement with _DONE.json if metrics missing)\n",
    "            if done_marker.exists() and (not OVERWRITE_EXISTING):\n",
    "                dm = _safe_read_json(done_marker)\n",
    "                if _done_marker_seems_complete(dm):\n",
    "                    if WRITE_METRICS_CSV and WRITE_METRICS_INCREMENTAL and dm is not None:\n",
    "                        key = tuple(dm.get(k) for k in METRICS_KEY_COLS)\n",
    "                        if (None not in key) and (key not in existing_metric_keys):\n",
    "                            # Supplement n_boxes compatible column\n",
    "                            if \"n_boxes\" not in dm and \"n_boxes_eval\" in dm:\n",
    "                                dm[\"n_boxes\"] = dm[\"n_boxes_eval\"]\n",
    "                            append_metrics_row_csv(METRICS_CSV_PATH, dm)\n",
    "                            existing_metric_keys.add(key)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  ⚠️ found {done_marker} but seems incomplete -> resume {noise_name}/{split}\")\n",
    "\n",
    "            lbl_files = sorted([p for p in noisy_lbl_dir.rglob(\"*.txt\") if p.is_file()])\n",
    "            if MAX_FILES_PER_SPLIT is not None:\n",
    "                lbl_files = lbl_files[:int(MAX_FILES_PER_SPLIT)]\n",
    "            if not lbl_files:\n",
    "                continue\n",
    "\n",
    "            out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            print(f\"  - refine {noise_name} / {split} | files={len(lbl_files)}\")\n",
    "            print(f\"    -> save to: {out_lbl_dir}\")\n",
    "\n",
    "            sum_iou_noisy = 0.0\n",
    "            sum_iou_ref = 0.0\n",
    "            n_boxes_eval = 0\n",
    "            n_files_done = 0\n",
    "            n_files_skipped = 0\n",
    "            n_files_noimg = 0\n",
    "            n_files_noclean = 0\n",
    "\n",
    "            # (B) Resume core: skip file if out_lf already exists\n",
    "            for idx, lf in enumerate(lbl_files, start=1):\n",
    "                rel = lf.relative_to(noisy_lbl_dir)\n",
    "                out_lf = out_lbl_dir / rel\n",
    "\n",
    "                should_skip = False\n",
    "                if RESUME_MODE and out_lf.exists() and (not OVERWRITE_EXISTING):\n",
    "                    if (not VERIFY_EXISTING_OUT_LABELS) or is_valid_yolo_file(out_lf):\n",
    "                        should_skip = True\n",
    "\n",
    "                if should_skip:\n",
    "                    n_files_skipped += 1\n",
    "                else:\n",
    "                    img_path = find_image_for_label(img_dir, rel)\n",
    "                    if img_path is None:\n",
    "                        n_files_noimg += 1\n",
    "                        continue\n",
    "\n",
    "                    clean_lf = clean_lbl_dir / rel\n",
    "                    clean_arg = clean_lf if clean_lf.exists() else None\n",
    "                    if clean_arg is None:\n",
    "                        n_files_noclean += 1\n",
    "\n",
    "                    m = refine_one_label_file_sam(\n",
    "                        predictor=predictor,\n",
    "                        img_path=img_path,\n",
    "                        noisy_lbl_path=lf,\n",
    "                        clean_lbl_path=clean_arg,\n",
    "                        out_lbl_path=out_lf,\n",
    "                    )\n",
    "                    n_files_done += 1\n",
    "                    sum_iou_noisy += m[\"sum_iou_noisy\"]\n",
    "                    sum_iou_ref   += m[\"sum_iou_refined\"]\n",
    "                    n_boxes_eval  += int(m[\"n_boxes_eval\"])\n",
    "\n",
    "                # (C) Save progress state (for mid-termination)\n",
    "                if (PROGRESS_EVERY is not None) and (PROGRESS_EVERY > 0) and (idx % int(PROGRESS_EVERY) == 0):\n",
    "                    prog = {\n",
    "                        \"dataset\": ds_root.name,\n",
    "                        \"case_id\": case_id,\n",
    "                        \"noise_name\": noise_name,\n",
    "                        \"split\": split,\n",
    "                        \"files_total\": len(lbl_files),\n",
    "                        \"files_done\": n_files_done,\n",
    "                        \"files_skipped\": n_files_skipped,\n",
    "                        \"files_noimg\": n_files_noimg,\n",
    "                        \"files_noclean\": n_files_noclean,\n",
    "                        \"n_boxes_eval\": int(n_boxes_eval),\n",
    "                        \"last_rel\": rel.as_posix(),\n",
    "                        \"updated_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        \"out_dir\": str(out_lbl_dir),\n",
    "                    }\n",
    "                    progress_marker.write_text(json.dumps(prog, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "            mean_iou_noisy = None\n",
    "            mean_iou_refined = None\n",
    "            delta_iou = None\n",
    "            if WRITE_METRICS_CSV and n_boxes_eval > 0:\n",
    "                mean_iou_noisy = (sum_iou_noisy / n_boxes_eval)\n",
    "                mean_iou_refined = (sum_iou_ref / n_boxes_eval)\n",
    "                delta_iou = ((sum_iou_ref - sum_iou_noisy) / n_boxes_eval)\n",
    "\n",
    "            payload = {\n",
    "                \"dataset\": ds_root.name,\n",
    "                \"case_id\": case_id,\n",
    "                \"noise_name\": noise_name,\n",
    "                \"split\": split,\n",
    "                \"files_total\": len(lbl_files),\n",
    "                \"files_done\": n_files_done,\n",
    "                \"files_skipped\": n_files_skipped,\n",
    "                \"files_noimg\": n_files_noimg,\n",
    "                \"files_noclean\": n_files_noclean,\n",
    "                # Also record n_boxes column for compatibility\n",
    "                \"n_boxes\": int(n_boxes_eval),\n",
    "                \"n_boxes_eval\": int(n_boxes_eval),\n",
    "                \"mean_iou_noisy\": mean_iou_noisy,\n",
    "                \"mean_iou_refined\": mean_iou_refined,\n",
    "                \"delta_iou\": delta_iou,\n",
    "                \"sam_model_type\": SAM_MODEL_TYPE,\n",
    "                \"sam_ckpt\": str(SAM_CKPT_PATH),\n",
    "                \"box_expand_ratio\": float(BOX_EXPAND_RATIO),\n",
    "                \"multimask\": bool(USE_MULTIMASK),\n",
    "                \"pick_by\": str(PICK_BY),\n",
    "                \"mask_to_box_pad\": int(MASK_TO_BOX_PAD),\n",
    "                \"min_box_wh_pix\": int(MIN_BOX_WH_PIX),\n",
    "                \"out_dir\": str(out_lbl_dir),\n",
    "            }\n",
    "\n",
    "            # (D) Metrics append (for mid-termination)\n",
    "            if WRITE_METRICS_CSV:\n",
    "                if WRITE_METRICS_INCREMENTAL:\n",
    "                    key = tuple(payload.get(k) for k in METRICS_KEY_COLS)\n",
    "                    if (None not in key) and (key not in existing_metric_keys):\n",
    "                        append_metrics_row_csv(METRICS_CSV_PATH, payload)\n",
    "                        existing_metric_keys.add(key)\n",
    "                else:\n",
    "                    all_metrics_rows.append(payload)\n",
    "\n",
    "            # (E) Record completion marker (if exists, skip entire noise/split on next run)\n",
    "            done_marker.write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "            # Progress marker is deleted on completion (optional)\n",
    "            try:\n",
    "                if progress_marker.exists():\n",
    "                    progress_marker.unlink()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "free_cuda()\n",
    "\n",
    "# save global metrics (non-incremental only)\n",
    "if WRITE_METRICS_CSV:\n",
    "    if WRITE_METRICS_INCREMENTAL:\n",
    "        print(f\"\\n✅ Metrics are appended incrementally: {METRICS_CSV_PATH}\")\n",
    "    else:\n",
    "        if all_metrics_rows:\n",
    "            import pandas as pd\n",
    "            df = pd.DataFrame(all_metrics_rows)\n",
    "            save_path = OUT_ROOT / \"_refine_summary_metrics.csv\"\n",
    "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            df.to_csv(save_path, index=False)\n",
    "            print(f\"\\n✅ Saved refine metrics summary: {save_path}\")\n",
    "        else:\n",
    "            print(\"\\n✅ Done (no metrics rows).\")\n",
    "else:\n",
    "    print(\"\\n✅ Done (no metrics csv requested).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08d908",
   "metadata": {},
   "source": [
    "## Time Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d6b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAM (vit_h) on cuda:1...\n",
      "Warming up GPU...\n",
      "Warmup done.\n",
      "\n",
      "Dataset              | Img Load(s) | SAM Refine(s) | Objs/Img | Total/Img(s)\n",
      "---------------------------------------------------------------------------\n",
      "kitti                | 0.0020s      | 0.5671s       |      4.4 | 0.5691s\n",
      "homeobjects-3K       | 0.0093s      | 0.5969s       |      9.6 | 0.6062s\n",
      "african-wildlife     | 0.0020s      | 0.5634s       |      1.2 | 0.5653s\n",
      "construction-ppe     | 0.0032s      | 0.5776s       |      6.8 | 0.5808s\n",
      "brain-tumor          | 0.0007s      | 0.5621s       |      1.0 | 0.5628s\n",
      "BCCD                 | 0.0013s      | 0.5947s       |     12.6 | 0.5960s\n",
      "signature            | 0.0076s      | 0.5699s       |      1.0 | 0.5775s\n",
      "medical-pills        | 0.0075s      | 0.6218s       |     16.8 | 0.6294s\n",
      "VOC                  | 0.0019s      | 0.5693s       |      1.8 | 0.5712s\n",
      "---------------------------------------------------------------------------\n",
      "OVERALL AVERAGE      | -          | -            | -        | 0.5843s\n",
      "===========================================================================\n",
      "Note: Measured on 5 random images per dataset.\n",
      "Time includes: Image Load + SAM Encoder(set_image) + Mask Decoding(predict loop).\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 3) SAM-based Refinement Speed Benchmark\n",
    "#  - No saving logic\n",
    "#  - Random 5 samples per dataset -> speed measurement\n",
    "#  - Includes Image Encoding time + Box Prompting time\n",
    "# ==========================================\n",
    "\n",
    "import time\n",
    "import random\n",
    "import statistics\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# [Configuration] Keep same as previous cell or modify if needed\n",
    "DATASETS_ROOT = Path(\"/home/ISW/project/datasets\")\n",
    "DEVICE = \"cuda:1\"\n",
    "SAM_MODEL_TYPE = \"vit_h\"\n",
    "SAM_CKPT_PATH  = \"/home/ISW/project/checkpoints/sam_vit_h_4b8939.pth\"\n",
    "\n",
    "TARGET_DATASETS = [\n",
    "    \"kitti\",\n",
    "    \"homeobjects-3K\",\n",
    "    \"african-wildlife\",\n",
    "    \"construction-ppe\",\n",
    "    # \"Custom_Blood\",\n",
    "    \"brain-tumor\",\n",
    "    \"BCCD\",\n",
    "    \"signature\",\n",
    "    \"medical-pills\",\n",
    "    \"VOC\",\n",
    "]\n",
    "\n",
    "# Benchmark settings\n",
    "TEST_NUMBER = 50          # Number of images to test per dataset\n",
    "BOX_EXPAND_RATIO = 0.0   # Setting for benchmark\n",
    "USE_MULTIMASK = True\n",
    "IMG_EXTS = [\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\"]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Helper Functions (Reused for consistency)\n",
    "# -------------------------------------------------\n",
    "def resolve_dataset_root(dataset_name: str) -> Path:\n",
    "    cand = DATASETS_ROOT / dataset_name\n",
    "    if cand.exists(): return cand\n",
    "    # Try simple name matching\n",
    "    for d in DATASETS_ROOT.iterdir():\n",
    "        if d.is_dir() and d.name.lower() == dataset_name.lower():\n",
    "            return d\n",
    "    return cand # fallback\n",
    "\n",
    "def read_yolo_txt_fast(p: Path):\n",
    "    rows = []\n",
    "    if not p.exists(): return rows\n",
    "    with open(p, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                # cls, cx, cy, w, h\n",
    "                rows.append([float(x) for x in parts[1:5]]) # exclude class, coordinates only\n",
    "    return rows\n",
    "\n",
    "def yolo_to_xyxy_pix(cx, cy, w, h, W, H):\n",
    "    x1 = int(round((cx - w/2) * W)); x2 = int(round((cx + w/2) * W))\n",
    "    y1 = int(round((cy - h/2) * H)); y2 = int(round((cy + h/2) * H))\n",
    "    return max(0, x1), max(0, y1), min(W, x2), min(H, y2)\n",
    "\n",
    "def expand_xyxy(x1, y1, x2, y2, W, H, ratio):\n",
    "    if ratio <= 0: return x1, y1, x2, y2\n",
    "    bw, bh = x2-x1, y2-y1\n",
    "    ex, ey = int(bw*ratio), int(bh*ratio)\n",
    "    return max(0, x1-ex), max(0, y1-ey), min(W, x2+ex), min(H, y2+ey)\n",
    "\n",
    "# SAM Loader (can skip if already loaded in Cell 2, but check for safety)\n",
    "try:\n",
    "    from segment_anything import sam_model_registry, SamPredictor\n",
    "except ImportError:\n",
    "    # Add path if needed in case Cell 2 loading logic was not executed\n",
    "    import sys\n",
    "    sys.path.append(str(Path(\"./SAM_refine_final/_deps/segment-anything-main\").resolve()))\n",
    "    from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Main Benchmark Logic\n",
    "# -------------------------------------------------\n",
    "def run_benchmark():\n",
    "    # 1) Model Load\n",
    "    print(f\"Loading SAM ({SAM_MODEL_TYPE}) on {DEVICE}...\")\n",
    "    sam = sam_model_registry[SAM_MODEL_TYPE](checkpoint=SAM_CKPT_PATH)\n",
    "    sam.to(device=DEVICE)\n",
    "    sam.eval()\n",
    "    predictor = SamPredictor(sam)\n",
    "    \n",
    "    # Warmup\n",
    "    print(\"Warming up GPU...\")\n",
    "    dummy_img = np.zeros((512, 512, 3), dtype=np.uint8)\n",
    "    predictor.set_image(dummy_img)\n",
    "    predictor.predict(box=np.array([10,10,100,100]))\n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    print(\"Warmup done.\\n\")\n",
    "\n",
    "    dataset_times = {}\n",
    "    \n",
    "    print(f\"{'Dataset':<20} | {'Img Load(s)':<10} | {'SAM Refine(s)':<12} | {'Objs/Img':<8} | {'Total/Img(s)':<12}\")\n",
    "    print(\"-\" * 75)\n",
    "\n",
    "    for ds_name in TARGET_DATASETS:\n",
    "        ds_root = resolve_dataset_root(ds_name)\n",
    "        if not ds_root.exists():\n",
    "            print(f\"{ds_name:<20} | NOT FOUND\")\n",
    "            continue\n",
    "\n",
    "        # Find images and labels (prioritize Noise folder, use labels if not found)\n",
    "        images_dir = ds_root / \"images\"\n",
    "        \n",
    "        # Find label source: use noise folder like labels_uniform_scaling_0.6 if exists (simulate real scenario)\n",
    "        # Use clean labels if not found\n",
    "        label_source = ds_root / \"labels\"\n",
    "        for d in ds_root.iterdir():\n",
    "            if d.is_dir() and d.name.startswith(\"labels_uniform_scaling_\"):\n",
    "                label_source = d\n",
    "                break\n",
    "        \n",
    "        # Collect file list\n",
    "        # Find all images recursively in images folder\n",
    "        all_imgs = []\n",
    "        for ext in IMG_EXTS:\n",
    "            all_imgs.extend(list(images_dir.rglob(f\"*{ext}\")))\n",
    "            \n",
    "        if not all_imgs:\n",
    "            print(f\"{ds_name:<20} | NO IMAGES\")\n",
    "            continue\n",
    "\n",
    "        # Random sampling\n",
    "        if len(all_imgs) > TEST_NUMBER:\n",
    "            samples = random.sample(all_imgs, TEST_NUMBER)\n",
    "        else:\n",
    "            samples = all_imgs\n",
    "\n",
    "        time_records = [] # (load_time, infer_time, num_objects)\n",
    "\n",
    "        for img_path in samples:\n",
    "            # Find matching label\n",
    "            rel_path = img_path.relative_to(images_dir)\n",
    "            lbl_path = label_source / rel_path.with_suffix(\".txt\")\n",
    "            \n",
    "            # --- [Measurement Start] ---\n",
    "            # 1. Image Loading & Preprocessing Time\n",
    "            t_start_load = time.time()\n",
    "            try:\n",
    "                with Image.open(img_path).convert(\"RGB\") as im:\n",
    "                    img_np = np.array(im)\n",
    "                    H, W = img_np.shape[:2]\n",
    "                \n",
    "                # Read label (YOLO parsing)\n",
    "                boxes_yolo = read_yolo_txt_fast(lbl_path)\n",
    "            except Exception:\n",
    "                continue # Skip on file read failure\n",
    "            \n",
    "            if torch.cuda.is_available(): torch.cuda.synchronize()\n",
    "            t_end_load = time.time()\n",
    "            load_dur = t_end_load - t_start_load\n",
    "\n",
    "            # 2. SAM Inference Time (Set Image + Predict Loop)\n",
    "            #    * Note: SAM's set_image(encoding) time is quite long.\n",
    "            t_start_infer = time.time()\n",
    "            \n",
    "            predictor.set_image(img_np) # Run Encoder (Heavy)\n",
    "            \n",
    "            # Inference for all boxes\n",
    "            # (Batch inference is possible, but following existing code's Loop approach)\n",
    "            if boxes_yolo:\n",
    "                for (cx, cy, w, h) in boxes_yolo:\n",
    "                    x1, y1, x2, y2 = yolo_to_xyxy_pix(cx, cy, w, h, W, H)\n",
    "                    \n",
    "                    # Box Valid Check\n",
    "                    if (x2-x1) < 2 or (y2-y1) < 2: continue\n",
    "\n",
    "                    ex1, ey1, ex2, ey2 = expand_xyxy(x1, y1, x2, y2, W, H, BOX_EXPAND_RATIO)\n",
    "                    input_box = np.array([ex1, ey1, ex2, ey2])\n",
    "\n",
    "                    masks, _, _ = predictor.predict(\n",
    "                        box=input_box,\n",
    "                        multimask_output=USE_MULTIMASK\n",
    "                    )\n",
    "                    # (Post-processing time is minimal, so included)\n",
    "            \n",
    "            if torch.cuda.is_available(): torch.cuda.synchronize()\n",
    "            t_end_infer = time.time()\n",
    "            infer_dur = t_end_infer - t_start_infer\n",
    "            \n",
    "            time_records.append((load_dur, infer_dur, len(boxes_yolo)))\n",
    "            # --- [Measurement End] ---\n",
    "\n",
    "        if not time_records:\n",
    "            print(f\"{ds_name:<20} | SKIPPED (No valid labels)\")\n",
    "            continue\n",
    "\n",
    "        avg_load = statistics.mean([t[0] for t in time_records])\n",
    "        avg_infer = statistics.mean([t[1] for t in time_records])\n",
    "        avg_objs = statistics.mean([t[2] for t in time_records])\n",
    "        total_time_per_img = avg_load + avg_infer\n",
    "\n",
    "        dataset_times[ds_name] = total_time_per_img\n",
    "\n",
    "        print(f\"{ds_name:<20} | {avg_load:.4f}s      | {avg_infer:.4f}s       | {avg_objs:>8.1f} | {total_time_per_img:.4f}s\")\n",
    "\n",
    "    # Final Summary\n",
    "    print(\"-\" * 75)\n",
    "    if dataset_times:\n",
    "        global_avg = statistics.mean(dataset_times.values())\n",
    "        print(f\"{'OVERALL AVERAGE':<20} | {'-':<10} | {'-':<12} | {'-':<8} | {global_avg:.4f}s\")\n",
    "        print(\"=\" * 75)\n",
    "        print(f\"Note: Measured on {TEST_NUMBER} random images per dataset.\")\n",
    "        print(\"Time includes: Image Load + SAM Encoder(set_image) + Mask Decoding(predict loop).\")\n",
    "    else:\n",
    "        print(\"No datasets processed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run after memory cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    run_benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
