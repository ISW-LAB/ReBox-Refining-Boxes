{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77569d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[DISCOVERY] Found 13 unique dataset roots under: /home/ISW/project/datasets\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] SKU-110K\n",
      " - root        : /home/ISW/project/datasets/SKU-110K\n",
      " - split_mode  : sku_virtual_8_2\n",
      " - train_dir   : /home/ISW/project/datasets/SKU-110K/images | tag=virtual_8_2 | n_train=9394\n",
      " - val_dir     : /home/ISW/project/datasets/SKU-110K/images | tag=virtual_8_2 | n_val=2349\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/SKU-110K/labels\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/SKU-110K/labels\n",
      " - [BASE original] train label files/boxes/groups_est : 11743 / 1730996 / 1730996\n",
      " - [BASE original] val   label files/boxes           : 11743 / 1730996\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: (none)\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=11743, val_files=11743\n",
      "   *            scale_0.6 | train_files=11743, val_files=11743\n",
      "   *            scale_0.7 | train_files=11743, val_files=11743\n",
      "   *            scale_0.8 | train_files=11743, val_files=11743\n",
      "   *            scale_0.9 | train_files=11743, val_files=11743\n",
      "   *            scale_1.1 | train_files=11743, val_files=11743\n",
      "   *            scale_1.2 | train_files=11743, val_files=11743\n",
      "   *            scale_1.3 | train_files=11743, val_files=11743\n",
      "   *            scale_1.4 | train_files=11743, val_files=11743\n",
      "   *               side_1 | train_files=11743, val_files=11743\n",
      "   *               side_3 | train_files=11165, val_files=11165\n",
      "   *               side_5 | train_files=11743, val_files=11743\n",
      "   *               side_7 | train_files=11743, val_files=11743\n",
      "   *               side_9 | train_files=11743, val_files=11743\n",
      " - inferred classes (multiclass-based): nc=1, names=['class_0']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] kitti\n",
      " - root        : /home/ISW/project/datasets/kitti\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/kitti/images/train | tag=train | n_train=5985\n",
      " - val_dir     : /home/ISW/project/datasets/kitti/images/val | tag=val | n_val=1496\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/kitti/labels/train\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/kitti/labels/val\n",
      " - [BASE original] train label files/boxes/groups_est : 5985 / 32442 / 32442\n",
      " - [BASE original] val   label files/boxes           : 1496 / 8128\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: ['refine(10)', 'refine(100)', 'refine(50)', 'refine(sam)']\n",
      "   * refine(10) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(100) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3']\n",
      "   * refine(50) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(sam) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=5985, val_files=1496\n",
      "   *            scale_0.6 | train_files=5985, val_files=1496\n",
      "   *            scale_0.7 | train_files=5985, val_files=1496\n",
      "   *            scale_0.8 | train_files=5985, val_files=1496\n",
      "   *            scale_0.9 | train_files=5985, val_files=1496\n",
      "   *            scale_1.1 | train_files=5985, val_files=1496\n",
      "   *            scale_1.2 | train_files=5985, val_files=1496\n",
      "   *            scale_1.3 | train_files=5985, val_files=1496\n",
      "   *            scale_1.4 | train_files=5985, val_files=1496\n",
      "   *               side_1 | train_files=5985, val_files=1496\n",
      "   *               side_3 | train_files=5985, val_files=1496\n",
      "   *               side_5 | train_files=5985, val_files=1496\n",
      "   *               side_7 | train_files=5985, val_files=1496\n",
      "   *               side_9 | train_files=5985, val_files=1496\n",
      "   * refine(10)::scale_0.6 | train_files=5985, val_files=1496\n",
      "   * refine(10)::scale_0.7 | train_files=5985, val_files=1496\n",
      "   * refine(10)::scale_0.8 | train_files=5985, val_files=1496\n",
      "   * refine(10)::scale_0.9 | train_files=5985, val_files=1496\n",
      "   * refine(10)::scale_1.1 | train_files=5985, val_files=1496\n",
      "   * refine(10)::scale_1.2 | train_files=5985, val_files=1496\n",
      "   * refine(10)::scale_1.3 | train_files=5985, val_files=1496\n",
      "   * refine(10)::scale_1.4 | train_files=5985, val_files=1496\n",
      "   *   refine(10)::side_1 | train_files=5985, val_files=1496\n",
      "   *   refine(10)::side_3 | train_files=5985, val_files=1496\n",
      "   *   refine(10)::side_5 | train_files=5985, val_files=1496\n",
      "   *   refine(10)::side_7 | train_files=5985, val_files=1496\n",
      "   *   refine(10)::side_9 | train_files=5985, val_files=1496\n",
      "   * refine(100)::scale_0.6 | train_files=5985, val_files=1496\n",
      "   * refine(100)::scale_0.7 | train_files=5985, val_files=1496\n",
      "   * refine(100)::scale_0.8 | train_files=5985, val_files=1496\n",
      "   * refine(100)::scale_0.9 | train_files=5985, val_files=1496\n",
      "   * refine(100)::scale_1.1 | train_files=5985, val_files=1496\n",
      "   * refine(100)::scale_1.2 | train_files=5985, val_files=1496\n",
      "   * refine(100)::scale_1.3 | train_files=5985, val_files=782\n",
      "   * refine(50)::scale_0.6 | train_files=5985, val_files=1496\n",
      "   * refine(50)::scale_0.7 | train_files=5985, val_files=1496\n",
      "   * refine(50)::scale_0.8 | train_files=5985, val_files=1496\n",
      "   * refine(50)::scale_0.9 | train_files=5985, val_files=1496\n",
      "   * refine(50)::scale_1.1 | train_files=5985, val_files=1496\n",
      "   * refine(50)::scale_1.2 | train_files=5985, val_files=1496\n",
      "   * refine(50)::scale_1.3 | train_files=5985, val_files=1496\n",
      "   * refine(50)::scale_1.4 | train_files=5985, val_files=1496\n",
      "   *   refine(50)::side_1 | train_files=5985, val_files=1496\n",
      "   *   refine(50)::side_3 | train_files=5985, val_files=1496\n",
      "   *   refine(50)::side_5 | train_files=5985, val_files=1496\n",
      "   *   refine(50)::side_7 | train_files=5985, val_files=1496\n",
      "   *   refine(50)::side_9 | train_files=5985, val_files=1496\n",
      "   * refine(sam)::scale_0.6 | train_files=5985, val_files=1496\n",
      "   * refine(sam)::scale_0.7 | train_files=5985, val_files=1496\n",
      "   * refine(sam)::scale_0.8 | train_files=5985, val_files=1496\n",
      "   * refine(sam)::scale_0.9 | train_files=5985, val_files=1496\n",
      "   * refine(sam)::scale_1.1 | train_files=5985, val_files=1496\n",
      "   * refine(sam)::scale_1.2 | train_files=5985, val_files=1496\n",
      "   * refine(sam)::scale_1.3 | train_files=5985, val_files=1496\n",
      "   * refine(sam)::scale_1.4 | train_files=5985, val_files=1496\n",
      "   *  refine(sam)::side_1 | train_files=5985, val_files=1496\n",
      "   *  refine(sam)::side_3 | train_files=5985, val_files=1496\n",
      "   *  refine(sam)::side_5 | train_files=5985, val_files=1496\n",
      "   *  refine(sam)::side_7 | train_files=5985, val_files=1496\n",
      "   *  refine(sam)::side_9 | train_files=5985, val_files=1496\n",
      " - inferred classes (multiclass-based): nc=8, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] homeobjects-3K\n",
      " - root        : /home/ISW/project/datasets/homeobjects-3K\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/homeobjects-3K/images/train | tag=train | n_train=2285\n",
      " - val_dir     : /home/ISW/project/datasets/homeobjects-3K/images/val | tag=val | n_val=404\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/homeobjects-3K/labels/train\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/homeobjects-3K/labels/val\n",
      " - [BASE original] train label files/boxes/groups_est : 2285 / 18822 / 18822\n",
      " - [BASE original] val   label files/boxes           : 404 / 3470\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: ['refine(10)', 'refine(50)', 'refine(sam)']\n",
      "   * refine(10) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(50) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(sam) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=2285, val_files=404\n",
      "   *            scale_0.6 | train_files=2285, val_files=404\n",
      "   *            scale_0.7 | train_files=2285, val_files=404\n",
      "   *            scale_0.8 | train_files=2285, val_files=404\n",
      "   *            scale_0.9 | train_files=2285, val_files=404\n",
      "   *            scale_1.1 | train_files=2285, val_files=404\n",
      "   *            scale_1.2 | train_files=2285, val_files=404\n",
      "   *            scale_1.3 | train_files=2285, val_files=404\n",
      "   *            scale_1.4 | train_files=2285, val_files=404\n",
      "   *               side_1 | train_files=2285, val_files=404\n",
      "   *               side_3 | train_files=2285, val_files=404\n",
      "   *               side_5 | train_files=2285, val_files=404\n",
      "   *               side_7 | train_files=2285, val_files=404\n",
      "   *               side_9 | train_files=2285, val_files=404\n",
      "   * refine(10)::scale_0.6 | train_files=2285, val_files=404\n",
      "   * refine(10)::scale_0.7 | train_files=2285, val_files=404\n",
      "   * refine(10)::scale_0.8 | train_files=2285, val_files=404\n",
      "   * refine(10)::scale_0.9 | train_files=2285, val_files=404\n",
      "   * refine(10)::scale_1.1 | train_files=2285, val_files=404\n",
      "   * refine(10)::scale_1.2 | train_files=2285, val_files=404\n",
      "   * refine(10)::scale_1.3 | train_files=2285, val_files=404\n",
      "   * refine(10)::scale_1.4 | train_files=2285, val_files=404\n",
      "   *   refine(10)::side_1 | train_files=2285, val_files=404\n",
      "   *   refine(10)::side_3 | train_files=2285, val_files=404\n",
      "   *   refine(10)::side_5 | train_files=2285, val_files=404\n",
      "   *   refine(10)::side_7 | train_files=2285, val_files=404\n",
      "   *   refine(10)::side_9 | train_files=2285, val_files=404\n",
      "   * refine(50)::scale_0.6 | train_files=2285, val_files=404\n",
      "   * refine(50)::scale_0.7 | train_files=2285, val_files=404\n",
      "   * refine(50)::scale_0.8 | train_files=2285, val_files=404\n",
      "   * refine(50)::scale_0.9 | train_files=2285, val_files=404\n",
      "   * refine(50)::scale_1.1 | train_files=2285, val_files=404\n",
      "   * refine(50)::scale_1.2 | train_files=2285, val_files=404\n",
      "   * refine(50)::scale_1.3 | train_files=2285, val_files=404\n",
      "   * refine(50)::scale_1.4 | train_files=2285, val_files=404\n",
      "   *   refine(50)::side_1 | train_files=2285, val_files=404\n",
      "   *   refine(50)::side_3 | train_files=2285, val_files=404\n",
      "   *   refine(50)::side_5 | train_files=2285, val_files=404\n",
      "   *   refine(50)::side_7 | train_files=2285, val_files=404\n",
      "   *   refine(50)::side_9 | train_files=2285, val_files=404\n",
      "   * refine(sam)::scale_0.6 | train_files=2285, val_files=404\n",
      "   * refine(sam)::scale_0.7 | train_files=2285, val_files=404\n",
      "   * refine(sam)::scale_0.8 | train_files=2285, val_files=404\n",
      "   * refine(sam)::scale_0.9 | train_files=2285, val_files=404\n",
      "   * refine(sam)::scale_1.1 | train_files=2285, val_files=404\n",
      "   * refine(sam)::scale_1.2 | train_files=2285, val_files=404\n",
      "   * refine(sam)::scale_1.3 | train_files=2285, val_files=404\n",
      "   * refine(sam)::scale_1.4 | train_files=2285, val_files=404\n",
      "   *  refine(sam)::side_1 | train_files=2285, val_files=404\n",
      "   *  refine(sam)::side_3 | train_files=2285, val_files=404\n",
      "   *  refine(sam)::side_5 | train_files=2285, val_files=404\n",
      "   *  refine(sam)::side_7 | train_files=2285, val_files=404\n",
      "   *  refine(sam)::side_9 | train_files=2285, val_files=404\n",
      " - inferred classes (multiclass-based): nc=12, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] african-wildlife\n",
      " - root        : /home/ISW/project/datasets/african-wildlife\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/african-wildlife/images/train | tag=train | n_train=1052\n",
      " - val_dir     : /home/ISW/project/datasets/african-wildlife/images/val | tag=val | n_val=225\n",
      " - test_dir    : /home/ISW/project/datasets/african-wildlife/images/test | n_test=227\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/african-wildlife/labels/train\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/african-wildlife/labels/val\n",
      " - [BASE original] train label files/boxes/groups_est : 1052 / 1931 / 1931\n",
      " - [BASE original] val   label files/boxes           : 225 / 379\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: ['refine(10)', 'refine(50)', 'refine(sam)']\n",
      "   * refine(10) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(50) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(sam) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=1052, val_files=225\n",
      "   *            scale_0.6 | train_files=1052, val_files=225\n",
      "   *            scale_0.7 | train_files=1052, val_files=225\n",
      "   *            scale_0.8 | train_files=1052, val_files=225\n",
      "   *            scale_0.9 | train_files=1052, val_files=225\n",
      "   *            scale_1.1 | train_files=1052, val_files=225\n",
      "   *            scale_1.2 | train_files=1052, val_files=225\n",
      "   *            scale_1.3 | train_files=1052, val_files=225\n",
      "   *            scale_1.4 | train_files=1052, val_files=225\n",
      "   *               side_1 | train_files=1052, val_files=225\n",
      "   *               side_3 | train_files=1052, val_files=225\n",
      "   *               side_5 | train_files=1052, val_files=225\n",
      "   *               side_7 | train_files=1052, val_files=225\n",
      "   *               side_9 | train_files=1052, val_files=225\n",
      "   * refine(10)::scale_0.6 | train_files=1049, val_files=225\n",
      "   * refine(10)::scale_0.7 | train_files=1049, val_files=225\n",
      "   * refine(10)::scale_0.8 | train_files=1049, val_files=225\n",
      "   * refine(10)::scale_0.9 | train_files=1049, val_files=225\n",
      "   * refine(10)::scale_1.1 | train_files=1049, val_files=225\n",
      "   * refine(10)::scale_1.2 | train_files=1049, val_files=225\n",
      "   * refine(10)::scale_1.3 | train_files=1049, val_files=225\n",
      "   * refine(10)::scale_1.4 | train_files=1049, val_files=225\n",
      "   *   refine(10)::side_1 | train_files=1049, val_files=225\n",
      "   *   refine(10)::side_3 | train_files=1049, val_files=225\n",
      "   *   refine(10)::side_5 | train_files=1049, val_files=225\n",
      "   *   refine(10)::side_7 | train_files=1049, val_files=225\n",
      "   *   refine(10)::side_9 | train_files=1049, val_files=225\n",
      "   * refine(50)::scale_0.6 | train_files=1049, val_files=225\n",
      "   * refine(50)::scale_0.7 | train_files=1049, val_files=225\n",
      "   * refine(50)::scale_0.8 | train_files=1049, val_files=225\n",
      "   * refine(50)::scale_0.9 | train_files=1049, val_files=225\n",
      "   * refine(50)::scale_1.1 | train_files=1049, val_files=225\n",
      "   * refine(50)::scale_1.2 | train_files=1049, val_files=225\n",
      "   * refine(50)::scale_1.3 | train_files=1049, val_files=225\n",
      "   * refine(50)::scale_1.4 | train_files=1049, val_files=225\n",
      "   *   refine(50)::side_1 | train_files=1049, val_files=225\n",
      "   *   refine(50)::side_3 | train_files=1049, val_files=225\n",
      "   *   refine(50)::side_5 | train_files=1049, val_files=225\n",
      "   *   refine(50)::side_7 | train_files=1049, val_files=225\n",
      "   *   refine(50)::side_9 | train_files=1049, val_files=225\n",
      "   * refine(sam)::scale_0.6 | train_files=1049, val_files=225\n",
      "   * refine(sam)::scale_0.7 | train_files=1049, val_files=225\n",
      "   * refine(sam)::scale_0.8 | train_files=1049, val_files=225\n",
      "   * refine(sam)::scale_0.9 | train_files=1049, val_files=225\n",
      "   * refine(sam)::scale_1.1 | train_files=1049, val_files=225\n",
      "   * refine(sam)::scale_1.2 | train_files=1049, val_files=225\n",
      "   * refine(sam)::scale_1.3 | train_files=1049, val_files=225\n",
      "   * refine(sam)::scale_1.4 | train_files=1049, val_files=225\n",
      "   *  refine(sam)::side_1 | train_files=1049, val_files=225\n",
      "   *  refine(sam)::side_3 | train_files=1049, val_files=225\n",
      "   *  refine(sam)::side_5 | train_files=1049, val_files=225\n",
      "   *  refine(sam)::side_7 | train_files=1049, val_files=225\n",
      "   *  refine(sam)::side_9 | train_files=1049, val_files=225\n",
      " - inferred classes (multiclass-based): nc=4, names=['class_0', 'class_1', 'class_2', 'class_3']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] construction-ppe\n",
      " - root        : /home/ISW/project/datasets/construction-ppe\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/construction-ppe/images/train | tag=train | n_train=1132\n",
      " - val_dir     : /home/ISW/project/datasets/construction-ppe/images/val | tag=val | n_val=143\n",
      " - test_dir    : /home/ISW/project/datasets/construction-ppe/images/test | n_test=141\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/construction-ppe/labels/train\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/construction-ppe/labels/val\n",
      " - [BASE original] train label files/boxes/groups_est : 1142 / 9191 / 9191\n",
      " - [BASE original] val   label files/boxes           : 143 / 1172\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: ['refine(10)', 'refine(50)', 'refine(sam)']\n",
      "   * refine(10) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(50) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(sam) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=1142, val_files=143\n",
      "   *            scale_0.6 | train_files=1142, val_files=143\n",
      "   *            scale_0.7 | train_files=1142, val_files=143\n",
      "   *            scale_0.8 | train_files=1142, val_files=143\n",
      "   *            scale_0.9 | train_files=1142, val_files=143\n",
      "   *            scale_1.1 | train_files=1142, val_files=143\n",
      "   *            scale_1.2 | train_files=1142, val_files=143\n",
      "   *            scale_1.3 | train_files=1142, val_files=143\n",
      "   *            scale_1.4 | train_files=1142, val_files=143\n",
      "   *               side_1 | train_files=1142, val_files=143\n",
      "   *               side_3 | train_files=1142, val_files=143\n",
      "   *               side_5 | train_files=1142, val_files=143\n",
      "   *               side_7 | train_files=1142, val_files=143\n",
      "   *               side_9 | train_files=1142, val_files=143\n",
      "   * refine(10)::scale_0.6 | train_files=1132, val_files=143\n",
      "   * refine(10)::scale_0.7 | train_files=1132, val_files=143\n",
      "   * refine(10)::scale_0.8 | train_files=1132, val_files=143\n",
      "   * refine(10)::scale_0.9 | train_files=1132, val_files=143\n",
      "   * refine(10)::scale_1.1 | train_files=1132, val_files=143\n",
      "   * refine(10)::scale_1.2 | train_files=1132, val_files=143\n",
      "   * refine(10)::scale_1.3 | train_files=1132, val_files=143\n",
      "   * refine(10)::scale_1.4 | train_files=1132, val_files=143\n",
      "   *   refine(10)::side_1 | train_files=1132, val_files=143\n",
      "   *   refine(10)::side_3 | train_files=1132, val_files=143\n",
      "   *   refine(10)::side_5 | train_files=1132, val_files=143\n",
      "   *   refine(10)::side_7 | train_files=1132, val_files=143\n",
      "   *   refine(10)::side_9 | train_files=1132, val_files=143\n",
      "   * refine(50)::scale_0.6 | train_files=1132, val_files=143\n",
      "   * refine(50)::scale_0.7 | train_files=1132, val_files=143\n",
      "   * refine(50)::scale_0.8 | train_files=1132, val_files=143\n",
      "   * refine(50)::scale_0.9 | train_files=1132, val_files=143\n",
      "   * refine(50)::scale_1.1 | train_files=1132, val_files=143\n",
      "   * refine(50)::scale_1.2 | train_files=1132, val_files=143\n",
      "   * refine(50)::scale_1.3 | train_files=1132, val_files=143\n",
      "   * refine(50)::scale_1.4 | train_files=1132, val_files=143\n",
      "   *   refine(50)::side_1 | train_files=1132, val_files=143\n",
      "   *   refine(50)::side_3 | train_files=1132, val_files=143\n",
      "   *   refine(50)::side_5 | train_files=1132, val_files=143\n",
      "   *   refine(50)::side_7 | train_files=1132, val_files=143\n",
      "   *   refine(50)::side_9 | train_files=1132, val_files=143\n",
      "   * refine(sam)::scale_0.6 | train_files=1132, val_files=143\n",
      "   * refine(sam)::scale_0.7 | train_files=1132, val_files=143\n",
      "   * refine(sam)::scale_0.8 | train_files=1132, val_files=143\n",
      "   * refine(sam)::scale_0.9 | train_files=1132, val_files=143\n",
      "   * refine(sam)::scale_1.1 | train_files=1132, val_files=143\n",
      "   * refine(sam)::scale_1.2 | train_files=1132, val_files=143\n",
      "   * refine(sam)::scale_1.3 | train_files=1132, val_files=143\n",
      "   * refine(sam)::scale_1.4 | train_files=1132, val_files=143\n",
      "   *  refine(sam)::side_1 | train_files=1132, val_files=143\n",
      "   *  refine(sam)::side_3 | train_files=1132, val_files=143\n",
      "   *  refine(sam)::side_5 | train_files=1132, val_files=143\n",
      "   *  refine(sam)::side_7 | train_files=1132, val_files=143\n",
      "   *  refine(sam)::side_9 | train_files=1132, val_files=143\n",
      " - inferred classes (multiclass-based): nc=11, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] Custom_Blood\n",
      " - root        : /home/ISW/project/datasets/Custom_Blood\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/Custom_Blood/images/train | tag=train | n_train=1105\n",
      " - val_dir     : /home/ISW/project/datasets/Custom_Blood/images/val | tag=val | n_val=122\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/Custom_Blood/labels/train\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/Custom_Blood/labels/val\n",
      " - [BASE original] train label files/boxes/groups_est : 1105 / 46487 / 46487\n",
      " - [BASE original] val   label files/boxes           : 122 / 6317\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: (none)\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=1105, val_files=122\n",
      "   *            scale_0.6 | train_files=1105, val_files=122\n",
      "   *            scale_0.7 | train_files=1105, val_files=122\n",
      "   *            scale_0.8 | train_files=1105, val_files=122\n",
      "   *            scale_0.9 | train_files=1105, val_files=122\n",
      "   *            scale_1.1 | train_files=1105, val_files=122\n",
      "   *            scale_1.2 | train_files=1105, val_files=122\n",
      "   *            scale_1.3 | train_files=1105, val_files=122\n",
      "   *            scale_1.4 | train_files=1105, val_files=122\n",
      "   *               side_1 | train_files=1105, val_files=122\n",
      "   *               side_3 | train_files=1105, val_files=122\n",
      "   *               side_5 | train_files=1105, val_files=122\n",
      "   *               side_7 | train_files=1105, val_files=122\n",
      "   *               side_9 | train_files=1105, val_files=122\n",
      " - inferred classes (multiclass-based): nc=13, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] brain-tumor\n",
      " - root        : /home/ISW/project/datasets/brain-tumor\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/brain-tumor/images/train | tag=train | n_train=893\n",
      " - val_dir     : /home/ISW/project/datasets/brain-tumor/images/val | tag=val | n_val=223\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/brain-tumor/labels/train\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/brain-tumor/labels/val\n",
      " - [BASE original] train label files/boxes/groups_est : 878 / 925 / 925\n",
      " - [BASE original] val   label files/boxes           : 223 / 241\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: ['refine(10)', 'refine(50)', 'refine(sam)']\n",
      "   * refine(10) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(50) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(sam) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=878, val_files=223\n",
      "   *            scale_0.6 | train_files=878, val_files=223\n",
      "   *            scale_0.7 | train_files=878, val_files=223\n",
      "   *            scale_0.8 | train_files=878, val_files=223\n",
      "   *            scale_0.9 | train_files=878, val_files=223\n",
      "   *            scale_1.1 | train_files=878, val_files=223\n",
      "   *            scale_1.2 | train_files=878, val_files=223\n",
      "   *            scale_1.3 | train_files=878, val_files=223\n",
      "   *            scale_1.4 | train_files=878, val_files=223\n",
      "   *               side_1 | train_files=878, val_files=223\n",
      "   *               side_3 | train_files=878, val_files=223\n",
      "   *               side_5 | train_files=878, val_files=223\n",
      "   *               side_7 | train_files=878, val_files=223\n",
      "   *               side_9 | train_files=878, val_files=223\n",
      "   * refine(10)::scale_0.6 | train_files=878, val_files=223\n",
      "   * refine(10)::scale_0.7 | train_files=878, val_files=223\n",
      "   * refine(10)::scale_0.8 | train_files=878, val_files=223\n",
      "   * refine(10)::scale_0.9 | train_files=878, val_files=223\n",
      "   * refine(10)::scale_1.1 | train_files=878, val_files=223\n",
      "   * refine(10)::scale_1.2 | train_files=878, val_files=223\n",
      "   * refine(10)::scale_1.3 | train_files=878, val_files=223\n",
      "   * refine(10)::scale_1.4 | train_files=878, val_files=223\n",
      "   *   refine(10)::side_1 | train_files=878, val_files=223\n",
      "   *   refine(10)::side_3 | train_files=878, val_files=223\n",
      "   *   refine(10)::side_5 | train_files=878, val_files=223\n",
      "   *   refine(10)::side_7 | train_files=878, val_files=223\n",
      "   *   refine(10)::side_9 | train_files=878, val_files=223\n",
      "   * refine(50)::scale_0.6 | train_files=878, val_files=223\n",
      "   * refine(50)::scale_0.7 | train_files=878, val_files=223\n",
      "   * refine(50)::scale_0.8 | train_files=878, val_files=223\n",
      "   * refine(50)::scale_0.9 | train_files=878, val_files=223\n",
      "   * refine(50)::scale_1.1 | train_files=878, val_files=223\n",
      "   * refine(50)::scale_1.2 | train_files=878, val_files=223\n",
      "   * refine(50)::scale_1.3 | train_files=878, val_files=223\n",
      "   * refine(50)::scale_1.4 | train_files=878, val_files=223\n",
      "   *   refine(50)::side_1 | train_files=878, val_files=223\n",
      "   *   refine(50)::side_3 | train_files=878, val_files=223\n",
      "   *   refine(50)::side_5 | train_files=878, val_files=223\n",
      "   *   refine(50)::side_7 | train_files=878, val_files=223\n",
      "   *   refine(50)::side_9 | train_files=878, val_files=223\n",
      "   * refine(sam)::scale_0.6 | train_files=878, val_files=223\n",
      "   * refine(sam)::scale_0.7 | train_files=878, val_files=223\n",
      "   * refine(sam)::scale_0.8 | train_files=878, val_files=223\n",
      "   * refine(sam)::scale_0.9 | train_files=878, val_files=223\n",
      "   * refine(sam)::scale_1.1 | train_files=878, val_files=223\n",
      "   * refine(sam)::scale_1.2 | train_files=878, val_files=223\n",
      "   * refine(sam)::scale_1.3 | train_files=878, val_files=223\n",
      "   * refine(sam)::scale_1.4 | train_files=878, val_files=223\n",
      "   *  refine(sam)::side_1 | train_files=878, val_files=223\n",
      "   *  refine(sam)::side_3 | train_files=878, val_files=223\n",
      "   *  refine(sam)::side_5 | train_files=878, val_files=223\n",
      "   *  refine(sam)::side_7 | train_files=878, val_files=223\n",
      "   *  refine(sam)::side_9 | train_files=878, val_files=223\n",
      " - inferred classes (multiclass-based): nc=2, names=['class_0', 'class_1']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] BCCD\n",
      " - root        : /home/ISW/project/datasets/BCCD\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/BCCD/images/train | tag=train | n_train=310\n",
      " - val_dir     : /home/ISW/project/datasets/BCCD/images/val | tag=val | n_val=54\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/BCCD/labels/train\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/BCCD/labels/val\n",
      " - [BASE original] train label files/boxes/groups_est : 310 / 4153 / 4153\n",
      " - [BASE original] val   label files/boxes           : 54 / 735\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: ['refine(10)', 'refine(50)', 'refine(sam)']\n",
      "   * refine(10) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(50) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(sam) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=310, val_files=54\n",
      "   *            scale_0.6 | train_files=310, val_files=54\n",
      "   *            scale_0.7 | train_files=310, val_files=54\n",
      "   *            scale_0.8 | train_files=310, val_files=54\n",
      "   *            scale_0.9 | train_files=310, val_files=54\n",
      "   *            scale_1.1 | train_files=310, val_files=54\n",
      "   *            scale_1.2 | train_files=310, val_files=54\n",
      "   *            scale_1.3 | train_files=310, val_files=54\n",
      "   *            scale_1.4 | train_files=310, val_files=54\n",
      "   *               side_1 | train_files=310, val_files=54\n",
      "   *               side_3 | train_files=310, val_files=54\n",
      "   *               side_5 | train_files=310, val_files=54\n",
      "   *               side_7 | train_files=310, val_files=54\n",
      "   *               side_9 | train_files=310, val_files=54\n",
      "   * refine(10)::scale_0.6 | train_files=310, val_files=54\n",
      "   * refine(10)::scale_0.7 | train_files=310, val_files=54\n",
      "   * refine(10)::scale_0.8 | train_files=310, val_files=54\n",
      "   * refine(10)::scale_0.9 | train_files=310, val_files=54\n",
      "   * refine(10)::scale_1.1 | train_files=310, val_files=54\n",
      "   * refine(10)::scale_1.2 | train_files=310, val_files=54\n",
      "   * refine(10)::scale_1.3 | train_files=310, val_files=54\n",
      "   * refine(10)::scale_1.4 | train_files=310, val_files=54\n",
      "   *   refine(10)::side_1 | train_files=310, val_files=54\n",
      "   *   refine(10)::side_3 | train_files=310, val_files=54\n",
      "   *   refine(10)::side_5 | train_files=310, val_files=54\n",
      "   *   refine(10)::side_7 | train_files=310, val_files=54\n",
      "   *   refine(10)::side_9 | train_files=310, val_files=54\n",
      "   * refine(50)::scale_0.6 | train_files=310, val_files=54\n",
      "   * refine(50)::scale_0.7 | train_files=310, val_files=54\n",
      "   * refine(50)::scale_0.8 | train_files=310, val_files=54\n",
      "   * refine(50)::scale_0.9 | train_files=310, val_files=54\n",
      "   * refine(50)::scale_1.1 | train_files=310, val_files=54\n",
      "   * refine(50)::scale_1.2 | train_files=310, val_files=54\n",
      "   * refine(50)::scale_1.3 | train_files=310, val_files=54\n",
      "   * refine(50)::scale_1.4 | train_files=310, val_files=54\n",
      "   *   refine(50)::side_1 | train_files=310, val_files=54\n",
      "   *   refine(50)::side_3 | train_files=310, val_files=54\n",
      "   *   refine(50)::side_5 | train_files=310, val_files=54\n",
      "   *   refine(50)::side_7 | train_files=310, val_files=54\n",
      "   *   refine(50)::side_9 | train_files=310, val_files=54\n",
      "   * refine(sam)::scale_0.6 | train_files=310, val_files=54\n",
      "   * refine(sam)::scale_0.7 | train_files=310, val_files=54\n",
      "   * refine(sam)::scale_0.8 | train_files=310, val_files=54\n",
      "   * refine(sam)::scale_0.9 | train_files=310, val_files=54\n",
      "   * refine(sam)::scale_1.1 | train_files=310, val_files=54\n",
      "   * refine(sam)::scale_1.2 | train_files=310, val_files=54\n",
      "   * refine(sam)::scale_1.3 | train_files=310, val_files=54\n",
      "   * refine(sam)::scale_1.4 | train_files=310, val_files=54\n",
      "   *  refine(sam)::side_1 | train_files=310, val_files=54\n",
      "   *  refine(sam)::side_3 | train_files=310, val_files=54\n",
      "   *  refine(sam)::side_5 | train_files=310, val_files=54\n",
      "   *  refine(sam)::side_7 | train_files=310, val_files=54\n",
      "   *  refine(sam)::side_9 | train_files=310, val_files=54\n",
      " - inferred classes (multiclass-based): nc=3, names=['class_0', 'class_1', 'class_2']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] signature\n",
      " - root        : /home/ISW/project/datasets/signature\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/signature/images/train | tag=train | n_train=143\n",
      " - val_dir     : /home/ISW/project/datasets/signature/images/val | tag=val | n_val=35\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/signature/labels/train\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/signature/labels/val\n",
      " - [BASE original] train label files/boxes/groups_est : 143 / 143 / 143\n",
      " - [BASE original] val   label files/boxes           : 35 / 35\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: ['refine(10)', 'refine(50)', 'refine(sam)']\n",
      "   * refine(10) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(50) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(sam) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=143, val_files=35\n",
      "   *            scale_0.6 | train_files=143, val_files=35\n",
      "   *            scale_0.7 | train_files=143, val_files=35\n",
      "   *            scale_0.8 | train_files=143, val_files=35\n",
      "   *            scale_0.9 | train_files=143, val_files=35\n",
      "   *            scale_1.1 | train_files=143, val_files=35\n",
      "   *            scale_1.2 | train_files=143, val_files=35\n",
      "   *            scale_1.3 | train_files=143, val_files=35\n",
      "   *            scale_1.4 | train_files=143, val_files=35\n",
      "   *               side_1 | train_files=143, val_files=35\n",
      "   *               side_3 | train_files=143, val_files=35\n",
      "   *               side_5 | train_files=143, val_files=35\n",
      "   *               side_7 | train_files=143, val_files=35\n",
      "   *               side_9 | train_files=143, val_files=35\n",
      "   * refine(10)::scale_0.6 | train_files=143, val_files=35\n",
      "   * refine(10)::scale_0.7 | train_files=143, val_files=35\n",
      "   * refine(10)::scale_0.8 | train_files=143, val_files=35\n",
      "   * refine(10)::scale_0.9 | train_files=143, val_files=35\n",
      "   * refine(10)::scale_1.1 | train_files=143, val_files=35\n",
      "   * refine(10)::scale_1.2 | train_files=143, val_files=35\n",
      "   * refine(10)::scale_1.3 | train_files=143, val_files=35\n",
      "   * refine(10)::scale_1.4 | train_files=143, val_files=35\n",
      "   *   refine(10)::side_1 | train_files=143, val_files=35\n",
      "   *   refine(10)::side_3 | train_files=143, val_files=35\n",
      "   *   refine(10)::side_5 | train_files=143, val_files=35\n",
      "   *   refine(10)::side_7 | train_files=143, val_files=35\n",
      "   *   refine(10)::side_9 | train_files=143, val_files=35\n",
      "   * refine(50)::scale_0.6 | train_files=143, val_files=35\n",
      "   * refine(50)::scale_0.7 | train_files=143, val_files=35\n",
      "   * refine(50)::scale_0.8 | train_files=143, val_files=35\n",
      "   * refine(50)::scale_0.9 | train_files=143, val_files=35\n",
      "   * refine(50)::scale_1.1 | train_files=143, val_files=35\n",
      "   * refine(50)::scale_1.2 | train_files=143, val_files=35\n",
      "   * refine(50)::scale_1.3 | train_files=143, val_files=35\n",
      "   * refine(50)::scale_1.4 | train_files=143, val_files=35\n",
      "   *   refine(50)::side_1 | train_files=143, val_files=35\n",
      "   *   refine(50)::side_3 | train_files=143, val_files=35\n",
      "   *   refine(50)::side_5 | train_files=143, val_files=35\n",
      "   *   refine(50)::side_7 | train_files=143, val_files=35\n",
      "   *   refine(50)::side_9 | train_files=143, val_files=35\n",
      "   * refine(sam)::scale_0.6 | train_files=143, val_files=35\n",
      "   * refine(sam)::scale_0.7 | train_files=143, val_files=35\n",
      "   * refine(sam)::scale_0.8 | train_files=143, val_files=35\n",
      "   * refine(sam)::scale_0.9 | train_files=143, val_files=35\n",
      "   * refine(sam)::scale_1.1 | train_files=143, val_files=35\n",
      "   * refine(sam)::scale_1.2 | train_files=143, val_files=35\n",
      "   * refine(sam)::scale_1.3 | train_files=143, val_files=35\n",
      "   * refine(sam)::scale_1.4 | train_files=143, val_files=35\n",
      "   *  refine(sam)::side_1 | train_files=143, val_files=35\n",
      "   *  refine(sam)::side_3 | train_files=143, val_files=35\n",
      "   *  refine(sam)::side_5 | train_files=143, val_files=35\n",
      "   *  refine(sam)::side_7 | train_files=143, val_files=35\n",
      "   *  refine(sam)::side_9 | train_files=143, val_files=35\n",
      " - inferred classes (multiclass-based): nc=1, names=['class_0']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] medical-pills\n",
      " - root        : /home/ISW/project/datasets/medical-pills\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/medical-pills/images/train | tag=train | n_train=92\n",
      " - val_dir     : /home/ISW/project/datasets/medical-pills/images/val | tag=val | n_val=23\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/medical-pills/labels/train\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/medical-pills/labels/val\n",
      " - [BASE original] train label files/boxes/groups_est : 92 / 1623 / 1623\n",
      " - [BASE original] val   label files/boxes           : 23 / 399\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: ['refine(10)', 'refine(50)', 'refine(sam)']\n",
      "   * refine(10) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(50) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(sam) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=92, val_files=23\n",
      "   *            scale_0.6 | train_files=92, val_files=23\n",
      "   *            scale_0.7 | train_files=92, val_files=23\n",
      "   *            scale_0.8 | train_files=92, val_files=23\n",
      "   *            scale_0.9 | train_files=92, val_files=23\n",
      "   *            scale_1.1 | train_files=92, val_files=23\n",
      "   *            scale_1.2 | train_files=92, val_files=23\n",
      "   *            scale_1.3 | train_files=92, val_files=23\n",
      "   *            scale_1.4 | train_files=92, val_files=23\n",
      "   *               side_1 | train_files=92, val_files=23\n",
      "   *               side_3 | train_files=92, val_files=23\n",
      "   *               side_5 | train_files=92, val_files=23\n",
      "   *               side_7 | train_files=92, val_files=23\n",
      "   *               side_9 | train_files=92, val_files=23\n",
      "   * refine(10)::scale_0.6 | train_files=92, val_files=23\n",
      "   * refine(10)::scale_0.7 | train_files=92, val_files=23\n",
      "   * refine(10)::scale_0.8 | train_files=92, val_files=23\n",
      "   * refine(10)::scale_0.9 | train_files=92, val_files=23\n",
      "   * refine(10)::scale_1.1 | train_files=92, val_files=23\n",
      "   * refine(10)::scale_1.2 | train_files=92, val_files=23\n",
      "   * refine(10)::scale_1.3 | train_files=92, val_files=23\n",
      "   * refine(10)::scale_1.4 | train_files=92, val_files=23\n",
      "   *   refine(10)::side_1 | train_files=92, val_files=23\n",
      "   *   refine(10)::side_3 | train_files=92, val_files=23\n",
      "   *   refine(10)::side_5 | train_files=92, val_files=23\n",
      "   *   refine(10)::side_7 | train_files=92, val_files=23\n",
      "   *   refine(10)::side_9 | train_files=92, val_files=23\n",
      "   * refine(50)::scale_0.6 | train_files=92, val_files=23\n",
      "   * refine(50)::scale_0.7 | train_files=92, val_files=23\n",
      "   * refine(50)::scale_0.8 | train_files=92, val_files=23\n",
      "   * refine(50)::scale_0.9 | train_files=92, val_files=23\n",
      "   * refine(50)::scale_1.1 | train_files=92, val_files=23\n",
      "   * refine(50)::scale_1.2 | train_files=92, val_files=23\n",
      "   * refine(50)::scale_1.3 | train_files=92, val_files=23\n",
      "   * refine(50)::scale_1.4 | train_files=92, val_files=23\n",
      "   *   refine(50)::side_1 | train_files=92, val_files=23\n",
      "   *   refine(50)::side_3 | train_files=92, val_files=23\n",
      "   *   refine(50)::side_5 | train_files=92, val_files=23\n",
      "   *   refine(50)::side_7 | train_files=92, val_files=23\n",
      "   *   refine(50)::side_9 | train_files=92, val_files=23\n",
      "   * refine(sam)::scale_0.6 | train_files=92, val_files=23\n",
      "   * refine(sam)::scale_0.7 | train_files=92, val_files=23\n",
      "   * refine(sam)::scale_0.8 | train_files=92, val_files=23\n",
      "   * refine(sam)::scale_0.9 | train_files=92, val_files=23\n",
      "   * refine(sam)::scale_1.1 | train_files=92, val_files=23\n",
      "   * refine(sam)::scale_1.2 | train_files=92, val_files=23\n",
      "   * refine(sam)::scale_1.3 | train_files=92, val_files=23\n",
      "   * refine(sam)::scale_1.4 | train_files=92, val_files=23\n",
      "   *  refine(sam)::side_1 | train_files=92, val_files=23\n",
      "   *  refine(sam)::side_3 | train_files=92, val_files=23\n",
      "   *  refine(sam)::side_5 | train_files=92, val_files=23\n",
      "   *  refine(sam)::side_7 | train_files=92, val_files=23\n",
      "   *  refine(sam)::side_9 | train_files=92, val_files=23\n",
      " - inferred classes (multiclass-based): nc=1, names=['class_0']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] coco\n",
      " - root        : /home/ISW/project/datasets/coco\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/coco/images/train2017 | tag=train2017 | n_train=118287\n",
      " - val_dir     : /home/ISW/project/datasets/coco/images/val2017 | tag=val2017 | n_val=5000\n",
      " - test_dir    : /home/ISW/project/datasets/coco/images/test2017 | n_test=40670\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/coco/labels/train2017\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/coco/labels/val2017\n",
      " - [BASE original] train label files/boxes/groups_est : 117266 / 849942 / 849942\n",
      " - [BASE original] val   label files/boxes           : 4952 / 36335\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: (none)\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=117266, val_files=4952\n",
      "   *            scale_0.6 | train_files=117266, val_files=4952\n",
      "   *            scale_0.7 | train_files=117266, val_files=4952\n",
      "   *            scale_0.8 | train_files=117266, val_files=4952\n",
      "   *            scale_0.9 | train_files=117266, val_files=4952\n",
      "   *            scale_1.1 | train_files=117266, val_files=4952\n",
      "   *            scale_1.2 | train_files=117266, val_files=4952\n",
      "   *            scale_1.3 | train_files=117266, val_files=4952\n",
      "   *            scale_1.4 | train_files=117266, val_files=4952\n",
      "   *               side_1 | train_files=117266, val_files=4952\n",
      "   *               side_3 | train_files=117266, val_files=4952\n",
      "   *               side_5 | train_files=117266, val_files=4952\n",
      "   *               side_7 | train_files=117266, val_files=4952\n",
      "   *               side_9 | train_files=117266, val_files=4952\n",
      " - inferred classes (multiclass-based): nc=80, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', 'class_16', 'class_17', 'class_18', 'class_19', 'class_20', 'class_21', 'class_22', 'class_23', 'class_24', 'class_25', 'class_26', 'class_27', 'class_28', 'class_29', 'class_30', 'class_31', 'class_32', 'class_33', 'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39', 'class_40', 'class_41', 'class_42', 'class_43', 'class_44', 'class_45', 'class_46', 'class_47', 'class_48', 'class_49', 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55', 'class_56', 'class_57', 'class_58', 'class_59', 'class_60', 'class_61', 'class_62', 'class_63', 'class_64', 'class_65', 'class_66', 'class_67', 'class_68', 'class_69', 'class_70', 'class_71', 'class_72', 'class_73', 'class_74', 'class_75', 'class_76', 'class_77', 'class_78', 'class_79']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] lvis\n",
      " - root        : /home/ISW/project/datasets/lvis\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/lvis/images/train2017 | tag=train2017 | n_train=118287\n",
      " - val_dir     : /home/ISW/project/datasets/lvis/images/val2017 | tag=val2017 | n_val=5000\n",
      " - test_dir    : /home/ISW/project/datasets/lvis/images/test2017 | n_test=40670\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/lvis/labels/train2017\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/lvis/labels/val2017\n",
      " - [BASE original] train label files/boxes/groups_est : 114262 / 1464174 / 1464174\n",
      " - [BASE original] val   label files/boxes           : 4752 / 50672\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: (none)\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=114262, val_files=4752\n",
      "   *            scale_0.6 | train_files=114262, val_files=4752\n",
      "   *            scale_0.7 | train_files=114262, val_files=4752\n",
      "   *            scale_0.8 | train_files=114262, val_files=4752\n",
      "   *            scale_0.9 | train_files=114262, val_files=4752\n",
      "   *            scale_1.1 | train_files=114262, val_files=4752\n",
      "   *            scale_1.2 | train_files=114262, val_files=4752\n",
      "   *            scale_1.3 | train_files=114262, val_files=4752\n",
      "   *            scale_1.4 | train_files=114262, val_files=4752\n",
      "   *               side_1 | train_files=114262, val_files=4752\n",
      "   *               side_3 | train_files=114262, val_files=4752\n",
      "   *               side_5 | train_files=114262, val_files=4752\n",
      "   *               side_7 | train_files=114262, val_files=4752\n",
      "   *               side_9 | train_files=114262, val_files=4752\n",
      " - inferred classes (multiclass-based): nc=1202, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', 'class_16', 'class_17', 'class_18', 'class_19', 'class_20', 'class_21', 'class_22', 'class_23', 'class_24', 'class_25', 'class_26', 'class_27', 'class_28', 'class_29', 'class_30', 'class_31', 'class_32', 'class_33', 'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39', 'class_40', 'class_41', 'class_42', 'class_43', 'class_44', 'class_45', 'class_46', 'class_47', 'class_48', 'class_49', 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55', 'class_56', 'class_57', 'class_58', 'class_59', 'class_60', 'class_61', 'class_62', 'class_63', 'class_64', 'class_65', 'class_66', 'class_67', 'class_68', 'class_69', 'class_70', 'class_71', 'class_72', 'class_73', 'class_74', 'class_75', 'class_76', 'class_77', 'class_78', 'class_79', 'class_80', 'class_81', 'class_82', 'class_83', 'class_84', 'class_85', 'class_86', 'class_87', 'class_88', 'class_89', 'class_90', 'class_91', 'class_92', 'class_93', 'class_94', 'class_95', 'class_96', 'class_97', 'class_98', 'class_99', 'class_100', 'class_101', 'class_102', 'class_103', 'class_104', 'class_105', 'class_106', 'class_107', 'class_108', 'class_109', 'class_110', 'class_111', 'class_112', 'class_113', 'class_114', 'class_115', 'class_116', 'class_117', 'class_118', 'class_119', 'class_120', 'class_121', 'class_122', 'class_123', 'class_124', 'class_125', 'class_126', 'class_127', 'class_128', 'class_129', 'class_130', 'class_131', 'class_132', 'class_133', 'class_134', 'class_135', 'class_136', 'class_137', 'class_138', 'class_139', 'class_140', 'class_141', 'class_142', 'class_143', 'class_144', 'class_145', 'class_146', 'class_147', 'class_148', 'class_149', 'class_150', 'class_151', 'class_152', 'class_153', 'class_154', 'class_155', 'class_156', 'class_157', 'class_158', 'class_159', 'class_160', 'class_161', 'class_162', 'class_163', 'class_164', 'class_165', 'class_166', 'class_167', 'class_168', 'class_169', 'class_170', 'class_171', 'class_172', 'class_173', 'class_174', 'class_175', 'class_176', 'class_177', 'class_178', 'class_179', 'class_180', 'class_181', 'class_182', 'class_183', 'class_184', 'class_185', 'class_186', 'class_187', 'class_188', 'class_189', 'class_190', 'class_191', 'class_192', 'class_193', 'class_194', 'class_195', 'class_196', 'class_197', 'class_198', 'class_199', 'class_200', 'class_201', 'class_202', 'class_203', 'class_204', 'class_205', 'class_206', 'class_207', 'class_208', 'class_209', 'class_210', 'class_211', 'class_212', 'class_213', 'class_214', 'class_215', 'class_216', 'class_217', 'class_218', 'class_219', 'class_220', 'class_221', 'class_222', 'class_223', 'class_224', 'class_225', 'class_226', 'class_227', 'class_228', 'class_229', 'class_230', 'class_231', 'class_232', 'class_233', 'class_234', 'class_235', 'class_236', 'class_237', 'class_238', 'class_239', 'class_240', 'class_241', 'class_242', 'class_243', 'class_244', 'class_245', 'class_246', 'class_247', 'class_248', 'class_249', 'class_250', 'class_251', 'class_252', 'class_253', 'class_254', 'class_255', 'class_256', 'class_257', 'class_258', 'class_259', 'class_260', 'class_261', 'class_262', 'class_263', 'class_264', 'class_265', 'class_266', 'class_267', 'class_268', 'class_269', 'class_270', 'class_271', 'class_272', 'class_273', 'class_274', 'class_275', 'class_276', 'class_277', 'class_278', 'class_279', 'class_280', 'class_281', 'class_282', 'class_283', 'class_284', 'class_285', 'class_286', 'class_287', 'class_288', 'class_289', 'class_290', 'class_291', 'class_292', 'class_293', 'class_294', 'class_295', 'class_296', 'class_297', 'class_298', 'class_299', 'class_300', 'class_301', 'class_302', 'class_303', 'class_304', 'class_305', 'class_306', 'class_307', 'class_308', 'class_309', 'class_310', 'class_311', 'class_312', 'class_313', 'class_314', 'class_315', 'class_316', 'class_317', 'class_318', 'class_319', 'class_320', 'class_321', 'class_322', 'class_323', 'class_324', 'class_325', 'class_326', 'class_327', 'class_328', 'class_329', 'class_330', 'class_331', 'class_332', 'class_333', 'class_334', 'class_335', 'class_336', 'class_337', 'class_338', 'class_339', 'class_340', 'class_341', 'class_342', 'class_343', 'class_344', 'class_345', 'class_346', 'class_347', 'class_348', 'class_349', 'class_350', 'class_351', 'class_352', 'class_353', 'class_354', 'class_355', 'class_356', 'class_357', 'class_358', 'class_359', 'class_360', 'class_361', 'class_362', 'class_363', 'class_364', 'class_365', 'class_366', 'class_367', 'class_368', 'class_369', 'class_370', 'class_371', 'class_372', 'class_373', 'class_374', 'class_375', 'class_376', 'class_377', 'class_378', 'class_379', 'class_380', 'class_381', 'class_382', 'class_383', 'class_384', 'class_385', 'class_386', 'class_387', 'class_388', 'class_389', 'class_390', 'class_391', 'class_392', 'class_393', 'class_394', 'class_395', 'class_396', 'class_397', 'class_398', 'class_399', 'class_400', 'class_401', 'class_402', 'class_403', 'class_404', 'class_405', 'class_406', 'class_407', 'class_408', 'class_409', 'class_410', 'class_411', 'class_412', 'class_413', 'class_414', 'class_415', 'class_416', 'class_417', 'class_418', 'class_419', 'class_420', 'class_421', 'class_422', 'class_423', 'class_424', 'class_425', 'class_426', 'class_427', 'class_428', 'class_429', 'class_430', 'class_431', 'class_432', 'class_433', 'class_434', 'class_435', 'class_436', 'class_437', 'class_438', 'class_439', 'class_440', 'class_441', 'class_442', 'class_443', 'class_444', 'class_445', 'class_446', 'class_447', 'class_448', 'class_449', 'class_450', 'class_451', 'class_452', 'class_453', 'class_454', 'class_455', 'class_456', 'class_457', 'class_458', 'class_459', 'class_460', 'class_461', 'class_462', 'class_463', 'class_464', 'class_465', 'class_466', 'class_467', 'class_468', 'class_469', 'class_470', 'class_471', 'class_472', 'class_473', 'class_474', 'class_475', 'class_476', 'class_477', 'class_478', 'class_479', 'class_480', 'class_481', 'class_482', 'class_483', 'class_484', 'class_485', 'class_486', 'class_487', 'class_488', 'class_489', 'class_490', 'class_491', 'class_492', 'class_493', 'class_494', 'class_495', 'class_496', 'class_497', 'class_498', 'class_499', 'class_500', 'class_501', 'class_502', 'class_503', 'class_504', 'class_505', 'class_506', 'class_507', 'class_508', 'class_509', 'class_510', 'class_511', 'class_512', 'class_513', 'class_514', 'class_515', 'class_516', 'class_517', 'class_518', 'class_519', 'class_520', 'class_521', 'class_522', 'class_523', 'class_524', 'class_525', 'class_526', 'class_527', 'class_528', 'class_529', 'class_530', 'class_531', 'class_532', 'class_533', 'class_534', 'class_535', 'class_536', 'class_537', 'class_538', 'class_539', 'class_540', 'class_541', 'class_542', 'class_543', 'class_544', 'class_545', 'class_546', 'class_547', 'class_548', 'class_549', 'class_550', 'class_551', 'class_552', 'class_553', 'class_554', 'class_555', 'class_556', 'class_557', 'class_558', 'class_559', 'class_560', 'class_561', 'class_562', 'class_563', 'class_564', 'class_565', 'class_566', 'class_567', 'class_568', 'class_569', 'class_570', 'class_571', 'class_572', 'class_573', 'class_574', 'class_575', 'class_576', 'class_577', 'class_578', 'class_579', 'class_580', 'class_581', 'class_582', 'class_583', 'class_584', 'class_585', 'class_586', 'class_587', 'class_588', 'class_589', 'class_590', 'class_591', 'class_592', 'class_593', 'class_594', 'class_595', 'class_596', 'class_597', 'class_598', 'class_599', 'class_600', 'class_601', 'class_602', 'class_603', 'class_604', 'class_605', 'class_606', 'class_607', 'class_608', 'class_609', 'class_610', 'class_611', 'class_612', 'class_613', 'class_614', 'class_615', 'class_616', 'class_617', 'class_618', 'class_619', 'class_620', 'class_621', 'class_622', 'class_623', 'class_624', 'class_625', 'class_626', 'class_627', 'class_628', 'class_629', 'class_630', 'class_631', 'class_632', 'class_633', 'class_634', 'class_635', 'class_636', 'class_637', 'class_638', 'class_639', 'class_640', 'class_641', 'class_642', 'class_643', 'class_644', 'class_645', 'class_646', 'class_647', 'class_648', 'class_649', 'class_650', 'class_651', 'class_652', 'class_653', 'class_654', 'class_655', 'class_656', 'class_657', 'class_658', 'class_659', 'class_660', 'class_661', 'class_662', 'class_663', 'class_664', 'class_665', 'class_666', 'class_667', 'class_668', 'class_669', 'class_670', 'class_671', 'class_672', 'class_673', 'class_674', 'class_675', 'class_676', 'class_677', 'class_678', 'class_679', 'class_680', 'class_681', 'class_682', 'class_683', 'class_684', 'class_685', 'class_686', 'class_687', 'class_688', 'class_689', 'class_690', 'class_691', 'class_692', 'class_693', 'class_694', 'class_695', 'class_696', 'class_697', 'class_698', 'class_699', 'class_700', 'class_701', 'class_702', 'class_703', 'class_704', 'class_705', 'class_706', 'class_707', 'class_708', 'class_709', 'class_710', 'class_711', 'class_712', 'class_713', 'class_714', 'class_715', 'class_716', 'class_717', 'class_718', 'class_719', 'class_720', 'class_721', 'class_722', 'class_723', 'class_724', 'class_725', 'class_726', 'class_727', 'class_728', 'class_729', 'class_730', 'class_731', 'class_732', 'class_733', 'class_734', 'class_735', 'class_736', 'class_737', 'class_738', 'class_739', 'class_740', 'class_741', 'class_742', 'class_743', 'class_744', 'class_745', 'class_746', 'class_747', 'class_748', 'class_749', 'class_750', 'class_751', 'class_752', 'class_753', 'class_754', 'class_755', 'class_756', 'class_757', 'class_758', 'class_759', 'class_760', 'class_761', 'class_762', 'class_763', 'class_764', 'class_765', 'class_766', 'class_767', 'class_768', 'class_769', 'class_770', 'class_771', 'class_772', 'class_773', 'class_774', 'class_775', 'class_776', 'class_777', 'class_778', 'class_779', 'class_780', 'class_781', 'class_782', 'class_783', 'class_784', 'class_785', 'class_786', 'class_787', 'class_788', 'class_789', 'class_790', 'class_791', 'class_792', 'class_793', 'class_794', 'class_795', 'class_796', 'class_797', 'class_798', 'class_799', 'class_800', 'class_801', 'class_802', 'class_803', 'class_804', 'class_805', 'class_806', 'class_807', 'class_808', 'class_809', 'class_810', 'class_811', 'class_812', 'class_813', 'class_814', 'class_815', 'class_816', 'class_817', 'class_818', 'class_819', 'class_820', 'class_821', 'class_822', 'class_823', 'class_824', 'class_825', 'class_826', 'class_827', 'class_828', 'class_829', 'class_830', 'class_831', 'class_832', 'class_833', 'class_834', 'class_835', 'class_836', 'class_837', 'class_838', 'class_839', 'class_840', 'class_841', 'class_842', 'class_843', 'class_844', 'class_845', 'class_846', 'class_847', 'class_848', 'class_849', 'class_850', 'class_851', 'class_852', 'class_853', 'class_854', 'class_855', 'class_856', 'class_857', 'class_858', 'class_859', 'class_860', 'class_861', 'class_862', 'class_863', 'class_864', 'class_865', 'class_866', 'class_867', 'class_868', 'class_869', 'class_870', 'class_871', 'class_872', 'class_873', 'class_874', 'class_875', 'class_876', 'class_877', 'class_878', 'class_879', 'class_880', 'class_881', 'class_882', 'class_883', 'class_884', 'class_885', 'class_886', 'class_887', 'class_888', 'class_889', 'class_890', 'class_891', 'class_892', 'class_893', 'class_894', 'class_895', 'class_896', 'class_897', 'class_898', 'class_899', 'class_900', 'class_901', 'class_902', 'class_903', 'class_904', 'class_905', 'class_906', 'class_907', 'class_908', 'class_909', 'class_910', 'class_911', 'class_912', 'class_913', 'class_914', 'class_915', 'class_916', 'class_917', 'class_918', 'class_919', 'class_920', 'class_921', 'class_922', 'class_923', 'class_924', 'class_925', 'class_926', 'class_927', 'class_928', 'class_929', 'class_930', 'class_931', 'class_932', 'class_933', 'class_934', 'class_935', 'class_936', 'class_937', 'class_938', 'class_939', 'class_940', 'class_941', 'class_942', 'class_943', 'class_944', 'class_945', 'class_946', 'class_947', 'class_948', 'class_949', 'class_950', 'class_951', 'class_952', 'class_953', 'class_954', 'class_955', 'class_956', 'class_957', 'class_958', 'class_959', 'class_960', 'class_961', 'class_962', 'class_963', 'class_964', 'class_965', 'class_966', 'class_967', 'class_968', 'class_969', 'class_970', 'class_971', 'class_972', 'class_973', 'class_974', 'class_975', 'class_976', 'class_977', 'class_978', 'class_979', 'class_980', 'class_981', 'class_982', 'class_983', 'class_984', 'class_985', 'class_986', 'class_987', 'class_988', 'class_989', 'class_990', 'class_991', 'class_992', 'class_993', 'class_994', 'class_995', 'class_996', 'class_997', 'class_998', 'class_999', 'class_1000', 'class_1001', 'class_1002', 'class_1003', 'class_1004', 'class_1005', 'class_1006', 'class_1007', 'class_1008', 'class_1009', 'class_1010', 'class_1011', 'class_1012', 'class_1013', 'class_1014', 'class_1015', 'class_1016', 'class_1017', 'class_1018', 'class_1019', 'class_1020', 'class_1021', 'class_1022', 'class_1023', 'class_1024', 'class_1025', 'class_1026', 'class_1027', 'class_1028', 'class_1029', 'class_1030', 'class_1031', 'class_1032', 'class_1033', 'class_1034', 'class_1035', 'class_1036', 'class_1037', 'class_1038', 'class_1039', 'class_1040', 'class_1041', 'class_1042', 'class_1043', 'class_1044', 'class_1045', 'class_1046', 'class_1047', 'class_1048', 'class_1049', 'class_1050', 'class_1051', 'class_1052', 'class_1053', 'class_1054', 'class_1055', 'class_1056', 'class_1057', 'class_1058', 'class_1059', 'class_1060', 'class_1061', 'class_1062', 'class_1063', 'class_1064', 'class_1065', 'class_1066', 'class_1067', 'class_1068', 'class_1069', 'class_1070', 'class_1071', 'class_1072', 'class_1073', 'class_1074', 'class_1075', 'class_1076', 'class_1077', 'class_1078', 'class_1079', 'class_1080', 'class_1081', 'class_1082', 'class_1083', 'class_1084', 'class_1085', 'class_1086', 'class_1087', 'class_1088', 'class_1089', 'class_1090', 'class_1091', 'class_1092', 'class_1093', 'class_1094', 'class_1095', 'class_1096', 'class_1097', 'class_1098', 'class_1099', 'class_1100', 'class_1101', 'class_1102', 'class_1103', 'class_1104', 'class_1105', 'class_1106', 'class_1107', 'class_1108', 'class_1109', 'class_1110', 'class_1111', 'class_1112', 'class_1113', 'class_1114', 'class_1115', 'class_1116', 'class_1117', 'class_1118', 'class_1119', 'class_1120', 'class_1121', 'class_1122', 'class_1123', 'class_1124', 'class_1125', 'class_1126', 'class_1127', 'class_1128', 'class_1129', 'class_1130', 'class_1131', 'class_1132', 'class_1133', 'class_1134', 'class_1135', 'class_1136', 'class_1137', 'class_1138', 'class_1139', 'class_1140', 'class_1141', 'class_1142', 'class_1143', 'class_1144', 'class_1145', 'class_1146', 'class_1147', 'class_1148', 'class_1149', 'class_1150', 'class_1151', 'class_1152', 'class_1153', 'class_1154', 'class_1155', 'class_1156', 'class_1157', 'class_1158', 'class_1159', 'class_1160', 'class_1161', 'class_1162', 'class_1163', 'class_1164', 'class_1165', 'class_1166', 'class_1167', 'class_1168', 'class_1169', 'class_1170', 'class_1171', 'class_1172', 'class_1173', 'class_1174', 'class_1175', 'class_1176', 'class_1177', 'class_1178', 'class_1179', 'class_1180', 'class_1181', 'class_1182', 'class_1183', 'class_1184', 'class_1185', 'class_1186', 'class_1187', 'class_1188', 'class_1189', 'class_1190', 'class_1191', 'class_1192', 'class_1193', 'class_1194', 'class_1195', 'class_1196', 'class_1197', 'class_1198', 'class_1199', 'class_1200', 'class_1201']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] VOC\n",
      " - root        : /home/ISW/project/datasets/VOC\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/VOC/images/train2012 | tag=train2012 | n_train=5717\n",
      " - val_dir     : /home/ISW/project/datasets/VOC/images/val2012 | tag=val2012 | n_val=5823\n",
      " - [BASE original] train_labels_dir : /home/ISW/project/datasets/VOC/labels/train2012\n",
      " - [BASE original] val_labels_dir   : /home/ISW/project/datasets/VOC/labels/val2012\n",
      " - [BASE original] train label files/boxes/groups_est : 5717 / 13609 / 13609\n",
      " - [BASE original] val   label files/boxes           : 5823 / 13841\n",
      " - base label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - refine variants found: ['refine(10)', 'refine(50)', 'refine(sam)']\n",
      "   * refine(10) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      "   * refine(50) cases: ['scale_0.6']\n",
      "   * refine(sam) cases: ['scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - case sanity (label files):\n",
      "   *             original | train_files=5717, val_files=5823\n",
      "   *            scale_0.6 | train_files=5717, val_files=5823\n",
      "   *            scale_0.7 | train_files=5717, val_files=5823\n",
      "   *            scale_0.8 | train_files=5717, val_files=5823\n",
      "   *            scale_0.9 | train_files=5717, val_files=5823\n",
      "   *            scale_1.1 | train_files=5717, val_files=5823\n",
      "   *            scale_1.2 | train_files=5717, val_files=5823\n",
      "   *            scale_1.3 | train_files=5717, val_files=5823\n",
      "   *            scale_1.4 | train_files=5717, val_files=5823\n",
      "   *               side_1 | train_files=5717, val_files=5823\n",
      "   *               side_3 | train_files=5717, val_files=5823\n",
      "   *               side_5 | train_files=5717, val_files=5823\n",
      "   *               side_7 | train_files=5717, val_files=5823\n",
      "   *               side_9 | train_files=5717, val_files=5823\n",
      "   * refine(10)::scale_0.6 | train_files=5717, val_files=5823\n",
      "   * refine(10)::scale_0.7 | train_files=5717, val_files=5823\n",
      "   * refine(10)::scale_0.8 | train_files=5717, val_files=5823\n",
      "   * refine(10)::scale_0.9 | train_files=5717, val_files=5823\n",
      "   * refine(10)::scale_1.1 | train_files=5717, val_files=5823\n",
      "   * refine(10)::scale_1.2 | train_files=5717, val_files=5823\n",
      "   * refine(10)::scale_1.3 | train_files=5717, val_files=5823\n",
      "   * refine(10)::scale_1.4 | train_files=5717, val_files=5823\n",
      "   *   refine(10)::side_1 | train_files=5717, val_files=5823\n",
      "   *   refine(10)::side_3 | train_files=5717, val_files=5823\n",
      "   *   refine(10)::side_5 | train_files=5717, val_files=5823\n",
      "   *   refine(10)::side_7 | train_files=5717, val_files=5823\n",
      "   *   refine(10)::side_9 | train_files=5717, val_files=5823\n",
      "   * refine(50)::scale_0.6 | train_files=1608, val_files=9061\n",
      "   * refine(sam)::scale_0.6 | train_files=5717, val_files=5823\n",
      "   * refine(sam)::scale_0.7 | train_files=5717, val_files=5823\n",
      "   * refine(sam)::scale_0.8 | train_files=5717, val_files=5823\n",
      "   * refine(sam)::scale_0.9 | train_files=5717, val_files=5823\n",
      "   * refine(sam)::scale_1.1 | train_files=5717, val_files=5823\n",
      "   * refine(sam)::scale_1.2 | train_files=5717, val_files=5823\n",
      "   * refine(sam)::scale_1.3 | train_files=5717, val_files=5823\n",
      "   * refine(sam)::scale_1.4 | train_files=5717, val_files=5823\n",
      "   *  refine(sam)::side_1 | train_files=5717, val_files=5823\n",
      "   *  refine(sam)::side_3 | train_files=5717, val_files=5823\n",
      "   *  refine(sam)::side_5 | train_files=5717, val_files=5823\n",
      "   *  refine(sam)::side_7 | train_files=5717, val_files=5823\n",
      "   *  refine(sam)::side_9 | train_files=5717, val_files=5823\n",
      " - inferred classes (multiclass-based): nc=20, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', 'class_16', 'class_17', 'class_18', 'class_19']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Cell 1 done.\n",
      "   -> dataset_summaries length = 13\n",
      "   -> roots variable is ready for Cell 2.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 1) Detection datasets discovery & inspection (FINAL+++)\n",
    "#   - How many datasets are found\n",
    "#   - train/val image count per dataset\n",
    "#   - Whether label cases (original/scale/side) exist\n",
    "#   - Output estimated class count/names (multiclass-based)\n",
    "#\n",
    "# [UPDATED+++]\n",
    "#    Reflect split structure rules per dataset name\n",
    "#    For Cell 2 acceleration\n",
    "#       - Store confirmed train/val labels dir\n",
    "#       - Calculate train/val label file count, box (line) count\n",
    "#       - Store n_train_groups_est (=box count)\n",
    "#    NEW: Also load noise label cases under refine(10) / refine(sam) / refine(*)\n",
    "#       - refine(*)/labels_uniform_scaling_{S}, refine(*)/labels_boundary_jitter_{K} (+ optional refine(*)/labels)\n",
    "#       - Confirm train/val labels dir per case + (optional) file/box statistics\n",
    "# ==========================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, sys, random, re\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 0) Register PROJECT_MODULE_DIR\n",
    "# -------------------------------------------------------------------------\n",
    "PROJECT_MODULE_DIR = Path(\"/home/ISW/project/Project_Module\")\n",
    "if str(PROJECT_MODULE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_MODULE_DIR))\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1) ultra_det_loader\n",
    "# -------------------------------------------------------------------------\n",
    "from ultra_det_loader import discover_det_datasets\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2) noisy_insection (use only scale/boundary jitter case list)\n",
    "# -------------------------------------------------------------------------\n",
    "try:\n",
    "    from noisy_insection import UNIFORM_SCALING_FACTORS, JITTER_PATTERNS\n",
    "except Exception:\n",
    "    UNIFORM_SCALING_FACTORS = [0.6, 0.7, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
    "    JITTER_PATTERNS = [1, 3, 5, 7, 9]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# User config\n",
    "# -------------------------------------------------------------------------\n",
    "LOAD_DIR = \"/home/ISW/project/datasets\"\n",
    "SEED = 42\n",
    "\n",
    "#  Refine variant folder candidates (additionally auto-detect refine(*))\n",
    "REFINE_VARIANT_NAMES = [\"refine(10)\", \"refine(sam)\"]\n",
    "\n",
    "#  Per-case box (line) count is expensive -> set True if needed\n",
    "COUNT_BOX_LINES_FOR_ALL_CASES = False   # Default: box count only for base(original), only file count for rest\n",
    "COUNT_BOX_LINES_FOR_BASE_ORIGINAL = True\n",
    "\n",
    "# Image extensions\n",
    "_IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "\n",
    "def list_images(dir_path: Optional[Path]) -> List[Path]:\n",
    "    if dir_path is None or not Path(dir_path).exists():\n",
    "        return []\n",
    "    dir_path = Path(dir_path)\n",
    "    imgs = []\n",
    "    for p in dir_path.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in _IMG_EXTS:\n",
    "            imgs.append(p)\n",
    "    return sorted(imgs)\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    n = name.strip().lower()\n",
    "    n = n.replace(\"_\", \"-\")\n",
    "    n = n.replace(\" \", \"-\")\n",
    "    return n\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Legacy heuristic (fallback)\n",
    "# -------------------------------------------------------------------------\n",
    "def _fallback_train_dir(images_root: Path) -> Path:\n",
    "    if (images_root / \"train\").is_dir():\n",
    "        return images_root / \"train\"\n",
    "    return images_root\n",
    "\n",
    "def _fallback_val_dir(images_root: Path) -> Optional[Path]:\n",
    "    if (images_root / \"val\").is_dir():\n",
    "        return images_root / \"val\"\n",
    "    if (images_root / \"valid\").is_dir():\n",
    "        return images_root / \"valid\"\n",
    "    return None\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "#  Dataset-specific split rules\n",
    "# -------------------------------------------------------------------------\n",
    "_SIMPLE_TRAIN_VAL = {\n",
    "    \"bccd\",\n",
    "    \"brain-tumor\",\n",
    "    \"custom-blood\",\n",
    "    \"homeobjects-3k\",\n",
    "    \"kitti\",\n",
    "    \"medical-pills\",\n",
    "    \"signature\",\n",
    "}\n",
    "\n",
    "_TRAIN_TEST_VAL = {\n",
    "    \"construction-ppe\",\n",
    "    \"african-wildlife\",\n",
    "}\n",
    "\n",
    "def detect_split_dirs(ds_root: Path) -> Dict[str, Optional[Path]]:\n",
    "    \"\"\"\n",
    "    Interpret images/labels split structure based on ds_root.\n",
    "    Returns:\n",
    "        {\n",
    "          \"train_img_dir\": Path|None,\n",
    "          \"val_img_dir\": Path|None,\n",
    "          \"test_img_dir\": Path|None,\n",
    "          \"split_mode\": str,  # \"explicit\" | \"sku_virtual_8_2\" | \"fallback\"\n",
    "          \"train_tag\": str,\n",
    "          \"val_tag\": str,\n",
    "        }\n",
    "    \"\"\"\n",
    "    ds_name = normalize_name(ds_root.name)\n",
    "    images_root = ds_root / \"images\"\n",
    "\n",
    "    # 1) VOC rule: use train2012/val2012 only\n",
    "    if ds_name == \"voc\":\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train2012\",\n",
    "            val_img_dir=images_root / \"val2012\",\n",
    "            test_img_dir=None,\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train2012\",\n",
    "            val_tag=\"val2012\",\n",
    "        )\n",
    "\n",
    "    # 2) COCO/LVIS rule\n",
    "    if ds_name == \"coco\" or \"coco\" in ds_name:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train2017\",\n",
    "            val_img_dir=images_root / \"val2017\",\n",
    "            test_img_dir=images_root / \"test2017\",\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train2017\",\n",
    "            val_tag=\"val2017\",\n",
    "        )\n",
    "\n",
    "    if ds_name == \"lvis\" or \"lvis\" in ds_name:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train2017\",\n",
    "            val_img_dir=images_root / \"val2017\",\n",
    "            test_img_dir=images_root / \"test2017\",\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train2017\",\n",
    "            val_tag=\"val2017\",\n",
    "        )\n",
    "\n",
    "    # 3) Explicit train/val structure\n",
    "    if ds_name in _SIMPLE_TRAIN_VAL:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train\",\n",
    "            val_img_dir=images_root / \"val\",\n",
    "            test_img_dir=None,\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train\",\n",
    "            val_tag=\"val\",\n",
    "        )\n",
    "\n",
    "    # 4) train/test/val structure\n",
    "    if ds_name in _TRAIN_TEST_VAL:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train\",\n",
    "            val_img_dir=images_root / \"val\",\n",
    "            test_img_dir=images_root / \"test\",\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train\",\n",
    "            val_tag=\"val\",\n",
    "        )\n",
    "\n",
    "    # 5) SKU-110K: no subfolders -> virtual split\n",
    "    if ds_name in {\"sku-110k\", \"sku110k\", \"sku_110k\"} or (\"sku\" in ds_name and \"110k\" in ds_name):\n",
    "        return dict(\n",
    "            train_img_dir=images_root,\n",
    "            val_img_dir=images_root,\n",
    "            test_img_dir=None,\n",
    "            split_mode=\"sku_virtual_8_2\",\n",
    "            train_tag=\"virtual_8_2\",\n",
    "            val_tag=\"virtual_8_2\",\n",
    "        )\n",
    "\n",
    "    # 6) fallback\n",
    "    tr = _fallback_train_dir(images_root)\n",
    "    va = _fallback_val_dir(images_root)\n",
    "    return dict(\n",
    "        train_img_dir=tr,\n",
    "        val_img_dir=va,\n",
    "        test_img_dir=None,\n",
    "        split_mode=\"fallback\",\n",
    "        train_tag=tr.name if tr else \"unknown\",\n",
    "        val_tag=va.name if va else \"missing\",\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Class name estimation\n",
    "# -------------------------------------------------------------------------\n",
    "def infer_class_names_from_labels(label_root: Path, max_files: int = 2000) -> List[str]:\n",
    "    if label_root is None or not label_root.exists():\n",
    "        return [\"class_0\"]\n",
    "\n",
    "    txts = list(label_root.rglob(\"*.txt\"))\n",
    "    if not txts:\n",
    "        return [\"class_0\"]\n",
    "\n",
    "    txts = txts[:max_files]\n",
    "    cls_ids = set()\n",
    "\n",
    "    for t in txts:\n",
    "        try:\n",
    "            with open(t, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) < 1:\n",
    "                        continue\n",
    "                    cid = int(float(parts[0]))\n",
    "                    cls_ids.add(cid)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not cls_ids:\n",
    "        return [\"class_0\"]\n",
    "\n",
    "    max_id = max(cls_ids)\n",
    "    return [f\"class_{i}\" for i in range(max_id + 1)]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "#  Determine label split dir (applicable to any labels_root)\n",
    "# -------------------------------------------------------------------------\n",
    "def resolve_split_label_dirs_from_root(labels_root: Path, train_tag: str, val_tag: str) -> Tuple[Path, Path]:\n",
    "    \"\"\"\n",
    "    If split subfolders exist under labels_root use them, otherwise use labels_root itself.\n",
    "    e.g.) labels_root/train, labels_root/val\n",
    "        labels_root/train2017, labels_root/val2017\n",
    "    \"\"\"\n",
    "    if labels_root is None:\n",
    "        return None, None\n",
    "    labels_root = Path(labels_root)\n",
    "\n",
    "    cand_train = labels_root / train_tag\n",
    "    cand_val   = labels_root / val_tag\n",
    "\n",
    "    train_labels_dir = cand_train if cand_train.is_dir() else labels_root\n",
    "    val_labels_dir   = cand_val   if cand_val.is_dir()   else labels_root\n",
    "    return train_labels_dir, val_labels_dir\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "#  Label statistics (quick group count estimation)\n",
    "# -------------------------------------------------------------------------\n",
    "def count_label_files_and_boxes(label_dir: Optional[Path], count_boxes: bool = True) -> Tuple[int, int]:\n",
    "    if label_dir is None or not Path(label_dir).exists():\n",
    "        return 0, 0\n",
    "    label_dir = Path(label_dir)\n",
    "    txts = sorted(label_dir.rglob(\"*.txt\"))\n",
    "    n_files = len(txts)\n",
    "\n",
    "    if not count_boxes:\n",
    "        return n_files, 0\n",
    "\n",
    "    n_boxes = 0\n",
    "    for t in txts:\n",
    "        try:\n",
    "            with open(t, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        n_boxes += 1\n",
    "        except Exception:\n",
    "            continue\n",
    "    return n_files, n_boxes\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# SKU-110K virtual split count\n",
    "# -------------------------------------------------------------------------\n",
    "def compute_sku_virtual_counts(images_root: Path, seed: int = 42, ratio: float = 0.8) -> Tuple[int, int]:\n",
    "    imgs = list_images(images_root)\n",
    "    n = len(imgs)\n",
    "    if n == 0:\n",
    "        return 0, 0\n",
    "    rnd = random.Random(seed)\n",
    "    idxs = list(range(n))\n",
    "    rnd.shuffle(idxs)\n",
    "    cut = int(n * ratio)\n",
    "    n_train = cut\n",
    "    n_val = n - cut\n",
    "    return n_train, n_val\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "#  Detect label cases under base ds_root or refine_variant_root\n",
    "#   - Assumes structure with labels / labels_uniform_scaling_* / labels_boundary_jitter_* directly under root_dir\n",
    "# -------------------------------------------------------------------------\n",
    "def list_label_cases_under_root(root_dir: Path) -> List[Tuple[str, Path]]:\n",
    "    \"\"\"\n",
    "    Returns: [(case_name, labels_root_path), ...]\n",
    "      case_name e.g.: \"original\", \"scale_0.6\", \"side_7\"\n",
    "    \"\"\"\n",
    "    cases: List[Tuple[str, Path]] = []\n",
    "    root_dir = Path(root_dir)\n",
    "\n",
    "    # original\n",
    "    if (root_dir / \"labels\").is_dir():\n",
    "        cases.append((\"original\", root_dir / \"labels\"))\n",
    "\n",
    "    # scale\n",
    "    for s in UNIFORM_SCALING_FACTORS:\n",
    "        d = root_dir / f\"labels_uniform_scaling_{s}\"\n",
    "        if d.is_dir():\n",
    "            cases.append((f\"scale_{s}\", d))\n",
    "\n",
    "    # side\n",
    "    for k in JITTER_PATTERNS:\n",
    "        d = root_dir / f\"labels_boundary_jitter_{k}\"\n",
    "        if d.is_dir():\n",
    "            cases.append((f\"side_{k}\", d))\n",
    "\n",
    "    return cases\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "#  Detect refine variant dirs: refine(10), refine(sam), + auto-include existing refine(*)\n",
    "# -------------------------------------------------------------------------\n",
    "def discover_refine_variant_dirs(ds_root: Path) -> List[Path]:\n",
    "    ds_root = Path(ds_root)\n",
    "    found: List[Path] = []\n",
    "\n",
    "    # 1) Specified names first\n",
    "    for nm in REFINE_VARIANT_NAMES:\n",
    "        p = ds_root / nm\n",
    "        if p.is_dir():\n",
    "            found.append(p)\n",
    "\n",
    "    # 2) Auto-detect refine(*) (remove duplicates)\n",
    "    for p in ds_root.iterdir():\n",
    "        if p.is_dir() and p.name.startswith(\"refine(\") and p.name.endswith(\")\"):\n",
    "            if p not in found:\n",
    "                found.append(p)\n",
    "\n",
    "    # Sort by name\n",
    "    found = sorted(found, key=lambda x: x.name)\n",
    "    return found\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Discover dataset roots\n",
    "# -------------------------------------------------------------------------\n",
    "set_seed(SEED)\n",
    "\n",
    "specs = discover_det_datasets(LOAD_DIR)\n",
    "roots: List[Path] = []\n",
    "for s in specs:\n",
    "    r = Path(s.root)\n",
    "    if r not in roots:\n",
    "        roots.append(r)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"[DISCOVERY] Found {len(roots)} unique dataset roots under: {Path(LOAD_DIR).resolve()}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Per-dataset summary\n",
    "# -------------------------------------------------------------------------\n",
    "dataset_summaries: List[Dict[str, Any]] = []\n",
    "\n",
    "for ds_root in roots:\n",
    "    ds_root = Path(ds_root)\n",
    "    images_root = ds_root / \"images\"\n",
    "    labels_root = ds_root / \"labels\"\n",
    "\n",
    "    if not images_root.is_dir() or not labels_root.is_dir():\n",
    "        print(f\"  Skip (missing images/labels): {ds_root}\")\n",
    "        continue\n",
    "\n",
    "    split_info = detect_split_dirs(ds_root)\n",
    "    train_dir = split_info[\"train_img_dir\"]\n",
    "    val_dir   = split_info[\"val_img_dir\"]\n",
    "    split_mode = split_info[\"split_mode\"]\n",
    "    train_tag  = split_info.get(\"train_tag\", \"train\")\n",
    "    val_tag    = split_info.get(\"val_tag\", \"val\")\n",
    "\n",
    "    # --- Calculate image count ---\n",
    "    if split_mode == \"sku_virtual_8_2\":\n",
    "        n_train, n_val = compute_sku_virtual_counts(images_root, seed=SEED, ratio=0.8)\n",
    "    else:\n",
    "        n_train = len(list_images(train_dir))\n",
    "        n_val   = len(list_images(val_dir)) if val_dir else 0\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    #  (A) base label cases: labels / labels_uniform_scaling_* / labels_boundary_jitter_* directly under ds_root\n",
    "    # ---------------------------------------------------------------------\n",
    "    base_cases = list_label_cases_under_root(ds_root)\n",
    "\n",
    "    # base originalfor \"Cell2 default\" path/stats as before top-level also keep (compatibility)\n",
    "    train_labels_dir_base, val_labels_dir_base = resolve_split_label_dirs_from_root(ds_root / \"labels\", train_tag, val_tag)\n",
    "\n",
    "    # base original statistics\n",
    "    n_train_label_files_base, n_train_boxes_base = count_label_files_and_boxes(\n",
    "        train_labels_dir_base,\n",
    "        count_boxes=COUNT_BOX_LINES_FOR_BASE_ORIGINAL\n",
    "    )\n",
    "    n_val_label_files_base, n_val_boxes_base = count_label_files_and_boxes(\n",
    "        val_labels_dir_base,\n",
    "        count_boxes=COUNT_BOX_LINES_FOR_BASE_ORIGINAL\n",
    "    )\n",
    "    n_train_groups_est_base = n_train_boxes_base  # group count estimate (for practical absn conversion)\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    #  (B) refine variant label cases: labels_uniform_scaling_* / labels_boundary_jitter_* under ds_root/refine(*)\n",
    "    # ---------------------------------------------------------------------\n",
    "    refine_dirs = discover_refine_variant_dirs(ds_root)\n",
    "\n",
    "    # case_details: labels_root + split dirs + stats for all cases (base + refine variants)\n",
    "    case_details: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    def _register_case(case_id: str, labels_root_case: Path, count_boxes: bool):\n",
    "        tr_ld, va_ld = resolve_split_label_dirs_from_root(labels_root_case, train_tag, val_tag)\n",
    "        n_tr_files, n_tr_boxes = count_label_files_and_boxes(tr_ld, count_boxes=count_boxes)\n",
    "        n_va_files, n_va_boxes = count_label_files_and_boxes(va_ld, count_boxes=count_boxes)\n",
    "        case_details[case_id] = dict(\n",
    "            case_id=case_id,\n",
    "            labels_root=str(labels_root_case),\n",
    "            train_labels_dir=str(tr_ld) if tr_ld else None,\n",
    "            val_labels_dir=str(va_ld) if va_ld else None,\n",
    "            n_train_label_files=n_tr_files,\n",
    "            n_val_label_files=n_va_files,\n",
    "            n_train_boxes=n_tr_boxes,\n",
    "            n_val_boxes=n_va_boxes,\n",
    "        )\n",
    "\n",
    "    # 1) Register base cases\n",
    "    for case_name, case_labels_root in base_cases:\n",
    "        # Box count only for base original (default), rest is optional\n",
    "        if case_name == \"original\":\n",
    "            _register_case(case_name, case_labels_root, count_boxes=COUNT_BOX_LINES_FOR_BASE_ORIGINAL)\n",
    "        else:\n",
    "            _register_case(case_name, case_labels_root, count_boxes=COUNT_BOX_LINES_FOR_ALL_CASES)\n",
    "\n",
    "    # 2) Register refine variants\n",
    "    refine_case_index: Dict[str, List[str]] = {}  # variant_name -> [case_ids...]\n",
    "    for rdir in refine_dirs:\n",
    "        variant = rdir.name  # e.g., refine(sam), refine(10)\n",
    "        r_cases = list_label_cases_under_root(rdir)\n",
    "        ids: List[str] = []\n",
    "        for case_name, case_labels_root in r_cases:\n",
    "            case_id = f\"{variant}::{case_name}\"\n",
    "            ids.append(case_id)\n",
    "            _register_case(case_id, case_labels_root, count_boxes=COUNT_BOX_LINES_FOR_ALL_CASES)\n",
    "        if ids:\n",
    "            refine_case_index[variant] = ids\n",
    "\n",
    "    # Multiclass estimation based on base labels_root (keep existing)\n",
    "    class_names = infer_class_names_from_labels(labels_root)\n",
    "    nc = len(class_names)\n",
    "\n",
    "    info: Dict[str, Any] = {\n",
    "        \"dataset\": ds_root.name,\n",
    "        \"root\": str(ds_root),\n",
    "        \"images_root\": str(images_root),\n",
    "        \"labels_root\": str(labels_root),\n",
    "\n",
    "        \"train_dir\": str(train_dir) if train_dir else None,\n",
    "        \"val_dir\": str(val_dir) if val_dir else None,\n",
    "\n",
    "        #  Used directly by Cell 2 (based on base original labels, keep existing keys)\n",
    "        \"train_labels_dir\": str(train_labels_dir_base) if train_labels_dir_base else None,\n",
    "        \"val_labels_dir\": str(val_labels_dir_base) if val_labels_dir_base else None,\n",
    "\n",
    "        \"n_train\": n_train,\n",
    "        \"n_val\": n_val,\n",
    "\n",
    "        #  base original label stats (keep existing keys)\n",
    "        \"n_train_label_files\": n_train_label_files_base,\n",
    "        \"n_val_label_files\": n_val_label_files_base,\n",
    "        \"n_train_boxes\": n_train_boxes_base,\n",
    "        \"n_val_boxes\": n_val_boxes_base,\n",
    "        \"n_train_groups_est\": n_train_groups_est_base,\n",
    "\n",
    "        \"split_mode\": split_mode,\n",
    "        \"train_tag\": train_tag,\n",
    "        \"val_tag\": val_tag,\n",
    "\n",
    "        # base case names\n",
    "        \"label_cases\": [c[0] for c in base_cases],\n",
    "\n",
    "        #  NEW: case index per refine(*) variant\n",
    "        \"refine_variants\": [p.name for p in refine_dirs],\n",
    "        \"refine_case_index\": refine_case_index,   # variant -> [\"refine(sam)::scale_0.6\", ...]\n",
    "\n",
    "        #  NEW: all case details (base + refine)\n",
    "        \"label_case_details\": case_details,       # case_id -> dirs/stats\n",
    "\n",
    "        \"nc_inferred\": nc,\n",
    "        \"class_names_inferred\": class_names,\n",
    "    }\n",
    "    dataset_summaries.append(info)\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Print summary\n",
    "    # ---------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(f\"[Dataset] {ds_root.name}\")\n",
    "    print(f\" - root        : {ds_root}\")\n",
    "    print(f\" - split_mode  : {split_mode}\")\n",
    "    print(f\" - train_dir   : {train_dir if train_dir else '(missing)'} | tag={train_tag} | n_train={n_train}\")\n",
    "    print(f\" - val_dir     : {val_dir if val_dir else '(missing)'} | tag={val_tag} | n_val={n_val}\")\n",
    "\n",
    "    test_dir = split_info.get(\"test_img_dir\", None)\n",
    "    if test_dir and test_dir.is_dir():\n",
    "        n_test = len(list_images(test_dir))\n",
    "        print(f\" - test_dir    : {test_dir} | n_test={n_test}\")\n",
    "\n",
    "    print(f\" - [BASE original] train_labels_dir : {train_labels_dir_base}\")\n",
    "    print(f\" - [BASE original] val_labels_dir   : {val_labels_dir_base}\")\n",
    "    print(f\" - [BASE original] train label files/boxes/groups_est : {n_train_label_files_base} / {n_train_boxes_base} / {n_train_groups_est_base}\")\n",
    "    print(f\" - [BASE original] val   label files/boxes           : {n_val_label_files_base} / {n_val_boxes_base}\")\n",
    "\n",
    "    print(f\" - base label_cases : {[c[0] for c in base_cases] if base_cases else '(none)'}\")\n",
    "\n",
    "    # refine variants summary\n",
    "    if refine_dirs:\n",
    "        print(f\" - refine variants found: {[p.name for p in refine_dirs]}\")\n",
    "        for v in [p.name for p in refine_dirs]:\n",
    "            ids = refine_case_index.get(v, [])\n",
    "            if not ids:\n",
    "                continue\n",
    "            # May get too long, show only case names briefly\n",
    "            short_names = [cid.split(\"::\", 1)[-1] for cid in ids]\n",
    "            print(f\"   * {v} cases: {short_names}\")\n",
    "    else:\n",
    "        print(\" - refine variants found: (none)\")\n",
    "\n",
    "    # Simple sanity: train/val label file count per case_id\n",
    "    # (box count is optional)\n",
    "    print(\" - case sanity (label files):\")\n",
    "    for cid, det in case_details.items():\n",
    "        print(f\"   * {cid:>20s} | train_files={det['n_train_label_files']}, val_files={det['n_val_label_files']}\")\n",
    "\n",
    "    print(f\" - inferred classes (multiclass-based): nc={nc}, names={class_names}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n Cell 1 done.\")\n",
    "print(f\"   -> dataset_summaries length = {len(dataset_summaries)}\")\n",
    "print(\"   -> roots variable is ready for Cell 2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757df97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[DISCOVERY] Found 1 selected dataset roots under: /home/ISW/project/datasets\n",
      "[FILTER] TARGET_DATASETS = ['kitti']\n",
      "================================================================================\n",
      "\n",
      "[VIS] dataset=kitti split=val(tag=val) n_sample=100\n",
      "\n",
      " Visualization done.\n",
      "   -> saved to: /home/ISW/project/(visualize)_kitti\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Visualization Runner (FINAL)\n",
    "#  - Save bbox overlay visualizations for:\n",
    "#      (1) original\n",
    "#      (2) each noise case\n",
    "#      (3) refine(50) all cases\n",
    "#      (4) refine(sam) all cases\n",
    "#  - For each dataset: sample_number=100 images ONCE (deterministic)\n",
    "#    then reuse SAME images for all cases\n",
    "#  - Output root: ./(visualize)_experiment_results\n",
    "# ==========================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, sys, random, hashlib, heapq\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict, Iterable\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# -----------------------------\n",
    "# USER CONFIG\n",
    "# -----------------------------\n",
    "LOAD_DIR = Path(\"/home/ISW/project/datasets\")\n",
    "SEED = 42\n",
    "SAMPLE_NUMBER = 100\n",
    "\n",
    "TARGET_SPLITS = [\"val\"]  # [\"train\",\"val\"] possible\n",
    "TARGET_REFINE_VARIANTS = [\"refine(50)\", \"refine(sam)\"]  # None means all\n",
    "\n",
    "#  Control datasets to visualize here (None for all discovered)\n",
    "TARGET_DATASETS: Optional[List[str]] = [\n",
    "    \"kitti\",\n",
    "    # \"homeobjects-3K\",\n",
    "    # \"african-wildlife\",\n",
    "    # \"construction-ppe\",\n",
    "    # \"Custom_Blood\",\n",
    "    # \"brain-tumor\",\n",
    "    # \"BCCD\",\n",
    "    # \"signature\",\n",
    "    # \"medical-pills\",\n",
    "    # \"VOC\",\n",
    "]\n",
    "\n",
    "OUT_ROOT = Path(\"./(visualize)_kitti\").resolve()\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# UI/Style\n",
    "BBOX_THICKNESS = 4\n",
    "TITLE_BAR_H = 18\n",
    "\n",
    "# Image extensions\n",
    "_IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "# Color palette (per class)\n",
    "_PALETTE = [\n",
    "    (255, 0, 0), (0, 255, 0), (0, 128, 255), (255, 128, 0), (255, 0, 255),\n",
    "    (0, 255, 255), (255, 255, 0), (128, 0, 255), (0, 0, 255), (0, 0, 0),\n",
    "]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 0) Register PROJECT_MODULE_DIR + ultra_det_loader\n",
    "# -------------------------------------------------------------------------\n",
    "PROJECT_MODULE_DIR = Path(\"/home/ISW/project/Project_Module\")\n",
    "if str(PROJECT_MODULE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_MODULE_DIR))\n",
    "\n",
    "from ultra_det_loader import discover_det_datasets\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1) noisy_insection (use only scale/boundary jitter case list)\n",
    "# -------------------------------------------------------------------------\n",
    "try:\n",
    "    from noisy_insection import UNIFORM_SCALING_FACTORS, JITTER_PATTERNS\n",
    "except Exception:\n",
    "    UNIFORM_SCALING_FACTORS = [0.6, 0.7, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
    "    JITTER_PATTERNS = [1, 3, 5, 7, 9]\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Helpers\n",
    "# -------------------------------------------------------------------------\n",
    "def normalize_name(name: str) -> str:\n",
    "    n = name.strip().lower()\n",
    "    n = n.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "    return n\n",
    "\n",
    "def _fallback_train_dir(images_root: Path) -> Path:\n",
    "    return (images_root / \"train\") if (images_root / \"train\").is_dir() else images_root\n",
    "\n",
    "def _fallback_val_dir(images_root: Path) -> Optional[Path]:\n",
    "    if (images_root / \"val\").is_dir():\n",
    "        return images_root / \"val\"\n",
    "    if (images_root / \"valid\").is_dir():\n",
    "        return images_root / \"valid\"\n",
    "    return None\n",
    "\n",
    "_SIMPLE_TRAIN_VAL = {\n",
    "    \"bccd\",\"brain-tumor\",\"custom-blood\",\"homeobjects-3k\",\"medical-pills\",\"signature\",\n",
    "    \"kitti\",\n",
    "}\n",
    "_TRAIN_TEST_VAL = {\n",
    "    \"construction-ppe\",\"african-wildlife\"\n",
    "}\n",
    "\n",
    "def detect_split_dirs(ds_root: Path) -> Dict[str, Optional[Path]]:\n",
    "    ds_name = normalize_name(ds_root.name)\n",
    "    images_root = ds_root / \"images\"\n",
    "\n",
    "    if ds_name == \"voc\":\n",
    "        return dict(train_img_dir=images_root / \"train2012\", val_img_dir=images_root / \"val2012\",\n",
    "                    test_img_dir=None, split_mode=\"explicit\", train_tag=\"train2012\", val_tag=\"val2012\")\n",
    "\n",
    "    if ds_name == \"coco\" or \"coco\" in ds_name:\n",
    "        return dict(train_img_dir=images_root / \"train2017\", val_img_dir=images_root / \"val2017\",\n",
    "                    test_img_dir=images_root / \"test2017\", split_mode=\"explicit\", train_tag=\"train2017\", val_tag=\"val2017\")\n",
    "\n",
    "    if ds_name == \"lvis\" or \"lvis\" in ds_name:\n",
    "        return dict(train_img_dir=images_root / \"train2017\", val_img_dir=images_root / \"val2017\",\n",
    "                    test_img_dir=images_root / \"test2017\", split_mode=\"explicit\", train_tag=\"train2017\", val_tag=\"val2017\")\n",
    "\n",
    "    if ds_name in _SIMPLE_TRAIN_VAL:\n",
    "        return dict(train_img_dir=images_root / \"train\", val_img_dir=images_root / \"val\",\n",
    "                    test_img_dir=None, split_mode=\"explicit\", train_tag=\"train\", val_tag=\"val\")\n",
    "\n",
    "    if ds_name in _TRAIN_TEST_VAL:\n",
    "        return dict(train_img_dir=images_root / \"train\", val_img_dir=images_root / \"val\",\n",
    "                    test_img_dir=images_root / \"test\", split_mode=\"explicit\", train_tag=\"train\", val_tag=\"val\")\n",
    "\n",
    "    if ds_name in {\"sku-110k\", \"sku110k\", \"sku_110k\"} or (\"sku\" in ds_name and \"110k\" in ds_name):\n",
    "        # Virtual split but actual folder is flat\n",
    "        return dict(train_img_dir=images_root, val_img_dir=images_root, test_img_dir=None,\n",
    "                    split_mode=\"sku_virtual_8_2\", train_tag=\"virtual_8_2\", val_tag=\"virtual_8_2\")\n",
    "\n",
    "    tr = _fallback_train_dir(images_root)\n",
    "    va = _fallback_val_dir(images_root)\n",
    "    return dict(train_img_dir=tr, val_img_dir=va, test_img_dir=None, split_mode=\"fallback\",\n",
    "                train_tag=tr.name if tr else \"unknown\", val_tag=va.name if va else \"missing\")\n",
    "\n",
    "def resolve_split_label_dir(label_root: Path, split_tag: str) -> Path:\n",
    "    \"\"\"\n",
    "    If split folders exist under label_root use them, otherwise label_root (flat)\n",
    "    \"\"\"\n",
    "    cand = label_root / split_tag\n",
    "    return cand if cand.is_dir() else label_root\n",
    "\n",
    "def _iter_images(img_dir: Path) -> Iterable[Path]:\n",
    "    \"\"\"\n",
    "    streaming scan (prevent memory explosion)\n",
    "    \"\"\"\n",
    "    img_dir = Path(img_dir)\n",
    "    if not img_dir.exists():\n",
    "        return\n",
    "    for root, _, files in os.walk(img_dir):\n",
    "        for fn in files:\n",
    "            p = Path(root) / fn\n",
    "            if p.suffix.lower() in _IMG_EXTS:\n",
    "                yield p\n",
    "\n",
    "def _stable_int_hash(s: str) -> int:\n",
    "    h = hashlib.md5(s.encode(\"utf-8\")).hexdigest()\n",
    "    return int(h, 16)\n",
    "\n",
    "def deterministic_sample_images(\n",
    "    img_dir: Path,\n",
    "    k: int,\n",
    "    seed: int,\n",
    "    require_label_dir: Optional[Path] = None,\n",
    ") -> List[Path]:\n",
    "    \"\"\"\n",
    "    Scan entire img_dir but deterministically select k items based on relpath hash.\n",
    "    (If require_label_dir is given, only images with existing labels are candidates)\n",
    "    \"\"\"\n",
    "    img_dir = Path(img_dir)\n",
    "    require_label_dir = Path(require_label_dir) if require_label_dir else None\n",
    "\n",
    "    heap: List[Tuple[int, Path]] = []  # (-score, path)  => max-heap by score\n",
    "    for p in _iter_images(img_dir):\n",
    "        rel = p.relative_to(img_dir).as_posix()\n",
    "\n",
    "        if require_label_dir is not None:\n",
    "            lab = (require_label_dir / Path(rel)).with_suffix(\".txt\")\n",
    "            if not lab.exists():\n",
    "                continue\n",
    "\n",
    "        score = _stable_int_hash(f\"{seed}|{rel}\")\n",
    "        item = (-score, p)  # max-heap emulation (largest score => most negative -score)\n",
    "\n",
    "        if len(heap) < k:\n",
    "            heapq.heappush(heap, item)\n",
    "        else:\n",
    "            # heap[0] is current \"worst\" (largest score) because it has most negative -score\n",
    "            worst_score = -heap[0][0]\n",
    "            if score < worst_score:\n",
    "                heapq.heapreplace(heap, (-score, p))\n",
    "\n",
    "    picked = sorted(heap, key=lambda x: -x[0])  # sort by score ascending\n",
    "    return [p for _, p in picked]\n",
    "\n",
    "def parse_yolo_labels(label_path: Path, img_w: int, img_h: int) -> List[Tuple[int, Tuple[int,int,int,int]]]:\n",
    "    \"\"\"\n",
    "    Returns: [(cls_id, (x1,y1,x2,y2)), ...]\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    if label_path is None or (not label_path.exists()):\n",
    "        return out\n",
    "\n",
    "    try:\n",
    "        txt = label_path.read_text(encoding=\"utf-8\").strip().splitlines()\n",
    "    except Exception:\n",
    "        return out\n",
    "\n",
    "    for line in txt:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        try:\n",
    "            cid = int(float(parts[0]))\n",
    "            cx, cy, w, h = map(float, parts[1:5])\n",
    "            x1 = (cx - w/2.0) * img_w\n",
    "            y1 = (cy - h/2.0) * img_h\n",
    "            x2 = (cx + w/2.0) * img_w\n",
    "            y2 = (cy + h/2.0) * img_h\n",
    "            x1 = max(0, min(img_w-1, int(round(x1))))\n",
    "            y1 = max(0, min(img_h-1, int(round(y1))))\n",
    "            x2 = max(0, min(img_w-1, int(round(x2))))\n",
    "            y2 = max(0, min(img_h-1, int(round(y2))))\n",
    "            if x2 > x1 and y2 > y1:\n",
    "                out.append((cid, (x1,y1,x2,y2)))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return out\n",
    "\n",
    "def draw_overlay(img_path: Path, label_path: Optional[Path], title: str = \"\") -> Image.Image:\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    W, H = img.size\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    boxes = parse_yolo_labels(label_path, W, H)\n",
    "    for cid, (x1, y1, x2, y2) in boxes:\n",
    "        color = _PALETTE[cid % len(_PALETTE)]\n",
    "        #  bbox only (no class id/name text output)\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color, width=BBOX_THICKNESS)\n",
    "\n",
    "    if title:\n",
    "        draw.rectangle([0, 0, W, TITLE_BAR_H], fill=(0, 0, 0))\n",
    "        draw.text((3, 2), title[:120], fill=(255, 255, 255), font=font)\n",
    "\n",
    "    if label_path is None or not label_path.exists():\n",
    "        draw.text((3, TITLE_BAR_H + 2), \"LABEL MISSING\", fill=(255, 0, 0), font=font)\n",
    "\n",
    "    return img\n",
    "\n",
    "def case_to_dir_candidates(case_name: str) -> List[str]:\n",
    "    if case_name.startswith(\"scale_\"):\n",
    "        s = case_name.split(\"_\", 1)[1]\n",
    "        return [f\"labels_uniform_scaling_{s}\", case_name]\n",
    "    if case_name.startswith(\"side_\"):\n",
    "        k = case_name.split(\"_\", 1)[1]\n",
    "        return [f\"labels_boundary_jitter_{k}\", case_name]\n",
    "    if case_name == \"original\":\n",
    "        return [\"labels\", \"original\"]\n",
    "    return [case_name]\n",
    "\n",
    "def find_case_root(base_root: Path, case_name: str) -> Optional[Path]:\n",
    "    for dn in case_to_dir_candidates(case_name):\n",
    "        cand = base_root / dn\n",
    "        if cand.is_dir():\n",
    "            return cand\n",
    "    return None\n",
    "\n",
    "def list_noise_cases(ds_root: Path) -> List[str]:\n",
    "    noise = [f\"scale_{s}\" for s in UNIFORM_SCALING_FACTORS] + [f\"side_{k}\" for k in JITTER_PATTERNS]\n",
    "    out = []\n",
    "    for c in noise:\n",
    "        if find_case_root(ds_root, c) is not None:\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "def list_refine_cases(ds_root: Path, refine_variant: str, noise_cases: List[str]) -> List[str]:\n",
    "    rv = ds_root / refine_variant\n",
    "    if not rv.is_dir():\n",
    "        return []\n",
    "    out = []\n",
    "    for c in noise_cases:\n",
    "        if find_case_root(rv, c) is not None:\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "def label_path_for_image(img_path: Path, img_split_dir: Path, label_split_dir: Path) -> Path:\n",
    "    rel = img_path.relative_to(img_split_dir)\n",
    "    return (label_split_dir / rel).with_suffix(\".txt\")\n",
    "\n",
    "def _dataset_selected(ds_root: Path, target: Optional[List[str]]) -> bool:\n",
    "    if not target:\n",
    "        return True\n",
    "    ds_norm = normalize_name(ds_root.name)\n",
    "    target_norm = {normalize_name(x) for x in target}\n",
    "    return ds_norm in target_norm\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# MAIN\n",
    "# -------------------------------------------------------------------------\n",
    "random.seed(SEED)\n",
    "\n",
    "specs = discover_det_datasets(str(LOAD_DIR))\n",
    "roots: List[Path] = []\n",
    "for s in specs:\n",
    "    r = Path(s.root)\n",
    "    if r not in roots:\n",
    "        roots.append(r)\n",
    "\n",
    "#  Filter by TARGET_DATASETS\n",
    "roots = [r for r in roots if _dataset_selected(r, TARGET_DATASETS)]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"[DISCOVERY] Found {len(roots)} selected dataset roots under: {LOAD_DIR}\")\n",
    "if TARGET_DATASETS:\n",
    "    print(f\"[FILTER] TARGET_DATASETS = {TARGET_DATASETS}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# output category roots\n",
    "OUT_ORIGINAL = OUT_ROOT / \"original\"\n",
    "OUT_NOISE    = OUT_ROOT / \"noise\"\n",
    "OUT_REF50    = OUT_ROOT / \"refine(50)\"\n",
    "OUT_REFSAM   = OUT_ROOT / \"refine(sam)\"\n",
    "for p in [OUT_ORIGINAL, OUT_NOISE, OUT_REF50, OUT_REFSAM]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for ds_root in roots:\n",
    "    ds_root = Path(ds_root)\n",
    "    images_root = ds_root / \"images\"\n",
    "    labels_root = ds_root / \"labels\"\n",
    "    if not images_root.is_dir() or not labels_root.is_dir():\n",
    "        continue\n",
    "\n",
    "    split_info = detect_split_dirs(ds_root)\n",
    "    train_img_dir = split_info[\"train_img_dir\"]\n",
    "    val_img_dir   = split_info[\"val_img_dir\"]\n",
    "    train_tag = split_info.get(\"train_tag\", \"train\")\n",
    "    val_tag   = split_info.get(\"val_tag\", \"val\")\n",
    "\n",
    "    # noise/refine case list\n",
    "    noise_cases = list_noise_cases(ds_root)\n",
    "\n",
    "    # refine cases (only two requested variants)\n",
    "    refine_cases_map: Dict[str, List[str]] = {}\n",
    "    for rv in TARGET_REFINE_VARIANTS:\n",
    "        refine_cases_map[rv] = list_refine_cases(ds_root, rv, noise_cases)\n",
    "\n",
    "    for split in TARGET_SPLITS:\n",
    "        if split == \"val\":\n",
    "            img_split_dir = val_img_dir if (val_img_dir and Path(val_img_dir).is_dir()) else train_img_dir\n",
    "            split_tag = val_tag if (val_img_dir and Path(val_img_dir).is_dir()) else train_tag\n",
    "        else:\n",
    "            img_split_dir = train_img_dir\n",
    "            split_tag = train_tag\n",
    "\n",
    "        if img_split_dir is None or (not Path(img_split_dir).is_dir()):\n",
    "            continue\n",
    "        img_split_dir = Path(img_split_dir)\n",
    "\n",
    "        base_label_split_dir = resolve_split_label_dir(labels_root, split_tag)\n",
    "\n",
    "        # sample images ONCE (deterministic), prefer images that have original label file\n",
    "        sample_seed = (SEED + _stable_int_hash(ds_root.name) % 100000)\n",
    "        sample_imgs = deterministic_sample_images(\n",
    "            img_split_dir, k=SAMPLE_NUMBER, seed=sample_seed,\n",
    "            require_label_dir=base_label_split_dir\n",
    "        )\n",
    "        if len(sample_imgs) < SAMPLE_NUMBER:\n",
    "            sample_imgs = deterministic_sample_images(\n",
    "                img_split_dir, k=SAMPLE_NUMBER, seed=sample_seed,\n",
    "                require_label_dir=None\n",
    "            )\n",
    "\n",
    "        if not sample_imgs:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n[VIS] dataset={ds_root.name} split={split}(tag={split_tag}) n_sample={len(sample_imgs)}\")\n",
    "\n",
    "        # -------------------------------------------------------------\n",
    "        # (A) ORIGINAL\n",
    "        # -------------------------------------------------------------\n",
    "        out_base = OUT_ORIGINAL / ds_root.name / split_tag\n",
    "        out_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for img_path in sample_imgs:\n",
    "            lab_path = label_path_for_image(img_path, img_split_dir, base_label_split_dir)\n",
    "            title = f\"{ds_root.name} | original | {split_tag}\"\n",
    "            vis = draw_overlay(img_path, lab_path, title=title)\n",
    "\n",
    "            rel = img_path.relative_to(img_split_dir)\n",
    "            out_path = (out_base / rel).with_suffix(\".jpg\")\n",
    "            out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            vis.save(out_path, quality=95)\n",
    "\n",
    "        # -------------------------------------------------------------\n",
    "        # (B) NOISE cases\n",
    "        # -------------------------------------------------------------\n",
    "        for case in noise_cases:\n",
    "            case_root = find_case_root(ds_root, case)\n",
    "            if case_root is None:\n",
    "                continue\n",
    "            case_label_split_dir = resolve_split_label_dir(case_root, split_tag)\n",
    "\n",
    "            out_case = OUT_NOISE / ds_root.name / case / split_tag\n",
    "            out_case.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for img_path in sample_imgs:\n",
    "                lab_path = label_path_for_image(img_path, img_split_dir, case_label_split_dir)\n",
    "                title = f\"{ds_root.name} | noise:{case} | {split_tag}\"\n",
    "                vis = draw_overlay(img_path, lab_path, title=title)\n",
    "\n",
    "                rel = img_path.relative_to(img_split_dir)\n",
    "                out_path = (out_case / rel).with_suffix(\".jpg\")\n",
    "                out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                vis.save(out_path, quality=95)\n",
    "\n",
    "        # -------------------------------------------------------------\n",
    "        # (C) REFINE variants: refine(50), refine(sam)\n",
    "        # -------------------------------------------------------------\n",
    "        for rv in TARGET_REFINE_VARIANTS:\n",
    "            rv_root = ds_root / rv\n",
    "            if not rv_root.is_dir():\n",
    "                continue\n",
    "\n",
    "            rv_cases = refine_cases_map.get(rv, [])\n",
    "            if not rv_cases:\n",
    "                continue\n",
    "\n",
    "            out_rv_root = (OUT_REF50 if rv == \"refine(50)\" else OUT_REFSAM) / ds_root.name\n",
    "\n",
    "            for case in rv_cases:\n",
    "                case_root = find_case_root(rv_root, case)\n",
    "                if case_root is None:\n",
    "                    continue\n",
    "                case_label_split_dir = resolve_split_label_dir(case_root, split_tag)\n",
    "\n",
    "                out_case = out_rv_root / case / split_tag\n",
    "                out_case.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                for img_path in sample_imgs:\n",
    "                    lab_path = label_path_for_image(img_path, img_split_dir, case_label_split_dir)\n",
    "                    title = f\"{ds_root.name} | {rv}:{case} | {split_tag}\"\n",
    "                    vis = draw_overlay(img_path, lab_path, title=title)\n",
    "\n",
    "                    rel = img_path.relative_to(img_split_dir)\n",
    "                    out_path = (out_case / rel).with_suffix(\".jpg\")\n",
    "                    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    vis.save(out_path, quality=95)\n",
    "\n",
    "print(\"\\n Visualization done.\")\n",
    "print(f\"   -> saved to: {OUT_ROOT}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
