{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f215caaa",
   "metadata": {},
   "source": [
    "# Data Loading and Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd6b1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[DISCOVERY] Found 13 unique dataset roots under: /home/ISW/project/datasets\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] SKU-110K\n",
      " - root        : /home/ISW/project/datasets/SKU-110K\n",
      " - split_mode  : sku_virtual_8_2\n",
      " - train_dir   : /home/ISW/project/datasets/SKU-110K/images | tag=virtual_8_2 | n_train=9394\n",
      " - val_dir     : /home/ISW/project/datasets/SKU-110K/images | tag=virtual_8_2 | n_val=2349\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=1, names=['class_0']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] kitti\n",
      " - root        : /home/ISW/project/datasets/kitti\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/kitti/images/train | tag=train | n_train=5985\n",
      " - val_dir     : /home/ISW/project/datasets/kitti/images/val | tag=val | n_val=1496\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=8, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] homeobjects-3K\n",
      " - root        : /home/ISW/project/datasets/homeobjects-3K\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/homeobjects-3K/images/train | tag=train | n_train=2285\n",
      " - val_dir     : /home/ISW/project/datasets/homeobjects-3K/images/val | tag=val | n_val=404\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=12, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] african-wildlife\n",
      " - root        : /home/ISW/project/datasets/african-wildlife\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/african-wildlife/images/train | tag=train | n_train=1052\n",
      " - val_dir     : /home/ISW/project/datasets/african-wildlife/images/val | tag=val | n_val=225\n",
      " - test_dir    : /home/ISW/project/datasets/african-wildlife/images/test | n_test=227\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=4, names=['class_0', 'class_1', 'class_2', 'class_3']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] construction-ppe\n",
      " - root        : /home/ISW/project/datasets/construction-ppe\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/construction-ppe/images/train | tag=train | n_train=1132\n",
      " - val_dir     : /home/ISW/project/datasets/construction-ppe/images/val | tag=val | n_val=143\n",
      " - test_dir    : /home/ISW/project/datasets/construction-ppe/images/test | n_test=141\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=11, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] Custom_Blood\n",
      " - root        : /home/ISW/project/datasets/Custom_Blood\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/Custom_Blood/images/train | tag=train | n_train=1105\n",
      " - val_dir     : /home/ISW/project/datasets/Custom_Blood/images/val | tag=val | n_val=122\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=13, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] brain-tumor\n",
      " - root        : /home/ISW/project/datasets/brain-tumor\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/brain-tumor/images/train | tag=train | n_train=893\n",
      " - val_dir     : /home/ISW/project/datasets/brain-tumor/images/val | tag=val | n_val=223\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=2, names=['class_0', 'class_1']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] BCCD\n",
      " - root        : /home/ISW/project/datasets/BCCD\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/BCCD/images/train | tag=train | n_train=310\n",
      " - val_dir     : /home/ISW/project/datasets/BCCD/images/val | tag=val | n_val=54\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=3, names=['class_0', 'class_1', 'class_2']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] signature\n",
      " - root        : /home/ISW/project/datasets/signature\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/signature/images/train | tag=train | n_train=143\n",
      " - val_dir     : /home/ISW/project/datasets/signature/images/val | tag=val | n_val=35\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=1, names=['class_0']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] medical-pills\n",
      " - root        : /home/ISW/project/datasets/medical-pills\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/medical-pills/images/train | tag=train | n_train=92\n",
      " - val_dir     : /home/ISW/project/datasets/medical-pills/images/val | tag=val | n_val=23\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=1, names=['class_0']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] coco\n",
      " - root        : /home/ISW/project/datasets/coco\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/coco/images/train2017 | tag=train2017 | n_train=118287\n",
      " - val_dir     : /home/ISW/project/datasets/coco/images/val2017 | tag=val2017 | n_val=5000\n",
      " - test_dir    : /home/ISW/project/datasets/coco/images/test2017 | n_test=40670\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=80, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', 'class_16', 'class_17', 'class_18', 'class_19', 'class_20', 'class_21', 'class_22', 'class_23', 'class_24', 'class_25', 'class_26', 'class_27', 'class_28', 'class_29', 'class_30', 'class_31', 'class_32', 'class_33', 'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39', 'class_40', 'class_41', 'class_42', 'class_43', 'class_44', 'class_45', 'class_46', 'class_47', 'class_48', 'class_49', 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55', 'class_56', 'class_57', 'class_58', 'class_59', 'class_60', 'class_61', 'class_62', 'class_63', 'class_64', 'class_65', 'class_66', 'class_67', 'class_68', 'class_69', 'class_70', 'class_71', 'class_72', 'class_73', 'class_74', 'class_75', 'class_76', 'class_77', 'class_78', 'class_79']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] lvis\n",
      " - root        : /home/ISW/project/datasets/lvis\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/lvis/images/train2017 | tag=train2017 | n_train=118287\n",
      " - val_dir     : /home/ISW/project/datasets/lvis/images/val2017 | tag=val2017 | n_val=5000\n",
      " - test_dir    : /home/ISW/project/datasets/lvis/images/test2017 | n_test=40670\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=1202, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', 'class_16', 'class_17', 'class_18', 'class_19', 'class_20', 'class_21', 'class_22', 'class_23', 'class_24', 'class_25', 'class_26', 'class_27', 'class_28', 'class_29', 'class_30', 'class_31', 'class_32', 'class_33', 'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39', 'class_40', 'class_41', 'class_42', 'class_43', 'class_44', 'class_45', 'class_46', 'class_47', 'class_48', 'class_49', 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55', 'class_56', 'class_57', 'class_58', 'class_59', 'class_60', 'class_61', 'class_62', 'class_63', 'class_64', 'class_65', 'class_66', 'class_67', 'class_68', 'class_69', 'class_70', 'class_71', 'class_72', 'class_73', 'class_74', 'class_75', 'class_76', 'class_77', 'class_78', 'class_79', 'class_80', 'class_81', 'class_82', 'class_83', 'class_84', 'class_85', 'class_86', 'class_87', 'class_88', 'class_89', 'class_90', 'class_91', 'class_92', 'class_93', 'class_94', 'class_95', 'class_96', 'class_97', 'class_98', 'class_99', 'class_100', 'class_101', 'class_102', 'class_103', 'class_104', 'class_105', 'class_106', 'class_107', 'class_108', 'class_109', 'class_110', 'class_111', 'class_112', 'class_113', 'class_114', 'class_115', 'class_116', 'class_117', 'class_118', 'class_119', 'class_120', 'class_121', 'class_122', 'class_123', 'class_124', 'class_125', 'class_126', 'class_127', 'class_128', 'class_129', 'class_130', 'class_131', 'class_132', 'class_133', 'class_134', 'class_135', 'class_136', 'class_137', 'class_138', 'class_139', 'class_140', 'class_141', 'class_142', 'class_143', 'class_144', 'class_145', 'class_146', 'class_147', 'class_148', 'class_149', 'class_150', 'class_151', 'class_152', 'class_153', 'class_154', 'class_155', 'class_156', 'class_157', 'class_158', 'class_159', 'class_160', 'class_161', 'class_162', 'class_163', 'class_164', 'class_165', 'class_166', 'class_167', 'class_168', 'class_169', 'class_170', 'class_171', 'class_172', 'class_173', 'class_174', 'class_175', 'class_176', 'class_177', 'class_178', 'class_179', 'class_180', 'class_181', 'class_182', 'class_183', 'class_184', 'class_185', 'class_186', 'class_187', 'class_188', 'class_189', 'class_190', 'class_191', 'class_192', 'class_193', 'class_194', 'class_195', 'class_196', 'class_197', 'class_198', 'class_199', 'class_200', 'class_201', 'class_202', 'class_203', 'class_204', 'class_205', 'class_206', 'class_207', 'class_208', 'class_209', 'class_210', 'class_211', 'class_212', 'class_213', 'class_214', 'class_215', 'class_216', 'class_217', 'class_218', 'class_219', 'class_220', 'class_221', 'class_222', 'class_223', 'class_224', 'class_225', 'class_226', 'class_227', 'class_228', 'class_229', 'class_230', 'class_231', 'class_232', 'class_233', 'class_234', 'class_235', 'class_236', 'class_237', 'class_238', 'class_239', 'class_240', 'class_241', 'class_242', 'class_243', 'class_244', 'class_245', 'class_246', 'class_247', 'class_248', 'class_249', 'class_250', 'class_251', 'class_252', 'class_253', 'class_254', 'class_255', 'class_256', 'class_257', 'class_258', 'class_259', 'class_260', 'class_261', 'class_262', 'class_263', 'class_264', 'class_265', 'class_266', 'class_267', 'class_268', 'class_269', 'class_270', 'class_271', 'class_272', 'class_273', 'class_274', 'class_275', 'class_276', 'class_277', 'class_278', 'class_279', 'class_280', 'class_281', 'class_282', 'class_283', 'class_284', 'class_285', 'class_286', 'class_287', 'class_288', 'class_289', 'class_290', 'class_291', 'class_292', 'class_293', 'class_294', 'class_295', 'class_296', 'class_297', 'class_298', 'class_299', 'class_300', 'class_301', 'class_302', 'class_303', 'class_304', 'class_305', 'class_306', 'class_307', 'class_308', 'class_309', 'class_310', 'class_311', 'class_312', 'class_313', 'class_314', 'class_315', 'class_316', 'class_317', 'class_318', 'class_319', 'class_320', 'class_321', 'class_322', 'class_323', 'class_324', 'class_325', 'class_326', 'class_327', 'class_328', 'class_329', 'class_330', 'class_331', 'class_332', 'class_333', 'class_334', 'class_335', 'class_336', 'class_337', 'class_338', 'class_339', 'class_340', 'class_341', 'class_342', 'class_343', 'class_344', 'class_345', 'class_346', 'class_347', 'class_348', 'class_349', 'class_350', 'class_351', 'class_352', 'class_353', 'class_354', 'class_355', 'class_356', 'class_357', 'class_358', 'class_359', 'class_360', 'class_361', 'class_362', 'class_363', 'class_364', 'class_365', 'class_366', 'class_367', 'class_368', 'class_369', 'class_370', 'class_371', 'class_372', 'class_373', 'class_374', 'class_375', 'class_376', 'class_377', 'class_378', 'class_379', 'class_380', 'class_381', 'class_382', 'class_383', 'class_384', 'class_385', 'class_386', 'class_387', 'class_388', 'class_389', 'class_390', 'class_391', 'class_392', 'class_393', 'class_394', 'class_395', 'class_396', 'class_397', 'class_398', 'class_399', 'class_400', 'class_401', 'class_402', 'class_403', 'class_404', 'class_405', 'class_406', 'class_407', 'class_408', 'class_409', 'class_410', 'class_411', 'class_412', 'class_413', 'class_414', 'class_415', 'class_416', 'class_417', 'class_418', 'class_419', 'class_420', 'class_421', 'class_422', 'class_423', 'class_424', 'class_425', 'class_426', 'class_427', 'class_428', 'class_429', 'class_430', 'class_431', 'class_432', 'class_433', 'class_434', 'class_435', 'class_436', 'class_437', 'class_438', 'class_439', 'class_440', 'class_441', 'class_442', 'class_443', 'class_444', 'class_445', 'class_446', 'class_447', 'class_448', 'class_449', 'class_450', 'class_451', 'class_452', 'class_453', 'class_454', 'class_455', 'class_456', 'class_457', 'class_458', 'class_459', 'class_460', 'class_461', 'class_462', 'class_463', 'class_464', 'class_465', 'class_466', 'class_467', 'class_468', 'class_469', 'class_470', 'class_471', 'class_472', 'class_473', 'class_474', 'class_475', 'class_476', 'class_477', 'class_478', 'class_479', 'class_480', 'class_481', 'class_482', 'class_483', 'class_484', 'class_485', 'class_486', 'class_487', 'class_488', 'class_489', 'class_490', 'class_491', 'class_492', 'class_493', 'class_494', 'class_495', 'class_496', 'class_497', 'class_498', 'class_499', 'class_500', 'class_501', 'class_502', 'class_503', 'class_504', 'class_505', 'class_506', 'class_507', 'class_508', 'class_509', 'class_510', 'class_511', 'class_512', 'class_513', 'class_514', 'class_515', 'class_516', 'class_517', 'class_518', 'class_519', 'class_520', 'class_521', 'class_522', 'class_523', 'class_524', 'class_525', 'class_526', 'class_527', 'class_528', 'class_529', 'class_530', 'class_531', 'class_532', 'class_533', 'class_534', 'class_535', 'class_536', 'class_537', 'class_538', 'class_539', 'class_540', 'class_541', 'class_542', 'class_543', 'class_544', 'class_545', 'class_546', 'class_547', 'class_548', 'class_549', 'class_550', 'class_551', 'class_552', 'class_553', 'class_554', 'class_555', 'class_556', 'class_557', 'class_558', 'class_559', 'class_560', 'class_561', 'class_562', 'class_563', 'class_564', 'class_565', 'class_566', 'class_567', 'class_568', 'class_569', 'class_570', 'class_571', 'class_572', 'class_573', 'class_574', 'class_575', 'class_576', 'class_577', 'class_578', 'class_579', 'class_580', 'class_581', 'class_582', 'class_583', 'class_584', 'class_585', 'class_586', 'class_587', 'class_588', 'class_589', 'class_590', 'class_591', 'class_592', 'class_593', 'class_594', 'class_595', 'class_596', 'class_597', 'class_598', 'class_599', 'class_600', 'class_601', 'class_602', 'class_603', 'class_604', 'class_605', 'class_606', 'class_607', 'class_608', 'class_609', 'class_610', 'class_611', 'class_612', 'class_613', 'class_614', 'class_615', 'class_616', 'class_617', 'class_618', 'class_619', 'class_620', 'class_621', 'class_622', 'class_623', 'class_624', 'class_625', 'class_626', 'class_627', 'class_628', 'class_629', 'class_630', 'class_631', 'class_632', 'class_633', 'class_634', 'class_635', 'class_636', 'class_637', 'class_638', 'class_639', 'class_640', 'class_641', 'class_642', 'class_643', 'class_644', 'class_645', 'class_646', 'class_647', 'class_648', 'class_649', 'class_650', 'class_651', 'class_652', 'class_653', 'class_654', 'class_655', 'class_656', 'class_657', 'class_658', 'class_659', 'class_660', 'class_661', 'class_662', 'class_663', 'class_664', 'class_665', 'class_666', 'class_667', 'class_668', 'class_669', 'class_670', 'class_671', 'class_672', 'class_673', 'class_674', 'class_675', 'class_676', 'class_677', 'class_678', 'class_679', 'class_680', 'class_681', 'class_682', 'class_683', 'class_684', 'class_685', 'class_686', 'class_687', 'class_688', 'class_689', 'class_690', 'class_691', 'class_692', 'class_693', 'class_694', 'class_695', 'class_696', 'class_697', 'class_698', 'class_699', 'class_700', 'class_701', 'class_702', 'class_703', 'class_704', 'class_705', 'class_706', 'class_707', 'class_708', 'class_709', 'class_710', 'class_711', 'class_712', 'class_713', 'class_714', 'class_715', 'class_716', 'class_717', 'class_718', 'class_719', 'class_720', 'class_721', 'class_722', 'class_723', 'class_724', 'class_725', 'class_726', 'class_727', 'class_728', 'class_729', 'class_730', 'class_731', 'class_732', 'class_733', 'class_734', 'class_735', 'class_736', 'class_737', 'class_738', 'class_739', 'class_740', 'class_741', 'class_742', 'class_743', 'class_744', 'class_745', 'class_746', 'class_747', 'class_748', 'class_749', 'class_750', 'class_751', 'class_752', 'class_753', 'class_754', 'class_755', 'class_756', 'class_757', 'class_758', 'class_759', 'class_760', 'class_761', 'class_762', 'class_763', 'class_764', 'class_765', 'class_766', 'class_767', 'class_768', 'class_769', 'class_770', 'class_771', 'class_772', 'class_773', 'class_774', 'class_775', 'class_776', 'class_777', 'class_778', 'class_779', 'class_780', 'class_781', 'class_782', 'class_783', 'class_784', 'class_785', 'class_786', 'class_787', 'class_788', 'class_789', 'class_790', 'class_791', 'class_792', 'class_793', 'class_794', 'class_795', 'class_796', 'class_797', 'class_798', 'class_799', 'class_800', 'class_801', 'class_802', 'class_803', 'class_804', 'class_805', 'class_806', 'class_807', 'class_808', 'class_809', 'class_810', 'class_811', 'class_812', 'class_813', 'class_814', 'class_815', 'class_816', 'class_817', 'class_818', 'class_819', 'class_820', 'class_821', 'class_822', 'class_823', 'class_824', 'class_825', 'class_826', 'class_827', 'class_828', 'class_829', 'class_830', 'class_831', 'class_832', 'class_833', 'class_834', 'class_835', 'class_836', 'class_837', 'class_838', 'class_839', 'class_840', 'class_841', 'class_842', 'class_843', 'class_844', 'class_845', 'class_846', 'class_847', 'class_848', 'class_849', 'class_850', 'class_851', 'class_852', 'class_853', 'class_854', 'class_855', 'class_856', 'class_857', 'class_858', 'class_859', 'class_860', 'class_861', 'class_862', 'class_863', 'class_864', 'class_865', 'class_866', 'class_867', 'class_868', 'class_869', 'class_870', 'class_871', 'class_872', 'class_873', 'class_874', 'class_875', 'class_876', 'class_877', 'class_878', 'class_879', 'class_880', 'class_881', 'class_882', 'class_883', 'class_884', 'class_885', 'class_886', 'class_887', 'class_888', 'class_889', 'class_890', 'class_891', 'class_892', 'class_893', 'class_894', 'class_895', 'class_896', 'class_897', 'class_898', 'class_899', 'class_900', 'class_901', 'class_902', 'class_903', 'class_904', 'class_905', 'class_906', 'class_907', 'class_908', 'class_909', 'class_910', 'class_911', 'class_912', 'class_913', 'class_914', 'class_915', 'class_916', 'class_917', 'class_918', 'class_919', 'class_920', 'class_921', 'class_922', 'class_923', 'class_924', 'class_925', 'class_926', 'class_927', 'class_928', 'class_929', 'class_930', 'class_931', 'class_932', 'class_933', 'class_934', 'class_935', 'class_936', 'class_937', 'class_938', 'class_939', 'class_940', 'class_941', 'class_942', 'class_943', 'class_944', 'class_945', 'class_946', 'class_947', 'class_948', 'class_949', 'class_950', 'class_951', 'class_952', 'class_953', 'class_954', 'class_955', 'class_956', 'class_957', 'class_958', 'class_959', 'class_960', 'class_961', 'class_962', 'class_963', 'class_964', 'class_965', 'class_966', 'class_967', 'class_968', 'class_969', 'class_970', 'class_971', 'class_972', 'class_973', 'class_974', 'class_975', 'class_976', 'class_977', 'class_978', 'class_979', 'class_980', 'class_981', 'class_982', 'class_983', 'class_984', 'class_985', 'class_986', 'class_987', 'class_988', 'class_989', 'class_990', 'class_991', 'class_992', 'class_993', 'class_994', 'class_995', 'class_996', 'class_997', 'class_998', 'class_999', 'class_1000', 'class_1001', 'class_1002', 'class_1003', 'class_1004', 'class_1005', 'class_1006', 'class_1007', 'class_1008', 'class_1009', 'class_1010', 'class_1011', 'class_1012', 'class_1013', 'class_1014', 'class_1015', 'class_1016', 'class_1017', 'class_1018', 'class_1019', 'class_1020', 'class_1021', 'class_1022', 'class_1023', 'class_1024', 'class_1025', 'class_1026', 'class_1027', 'class_1028', 'class_1029', 'class_1030', 'class_1031', 'class_1032', 'class_1033', 'class_1034', 'class_1035', 'class_1036', 'class_1037', 'class_1038', 'class_1039', 'class_1040', 'class_1041', 'class_1042', 'class_1043', 'class_1044', 'class_1045', 'class_1046', 'class_1047', 'class_1048', 'class_1049', 'class_1050', 'class_1051', 'class_1052', 'class_1053', 'class_1054', 'class_1055', 'class_1056', 'class_1057', 'class_1058', 'class_1059', 'class_1060', 'class_1061', 'class_1062', 'class_1063', 'class_1064', 'class_1065', 'class_1066', 'class_1067', 'class_1068', 'class_1069', 'class_1070', 'class_1071', 'class_1072', 'class_1073', 'class_1074', 'class_1075', 'class_1076', 'class_1077', 'class_1078', 'class_1079', 'class_1080', 'class_1081', 'class_1082', 'class_1083', 'class_1084', 'class_1085', 'class_1086', 'class_1087', 'class_1088', 'class_1089', 'class_1090', 'class_1091', 'class_1092', 'class_1093', 'class_1094', 'class_1095', 'class_1096', 'class_1097', 'class_1098', 'class_1099', 'class_1100', 'class_1101', 'class_1102', 'class_1103', 'class_1104', 'class_1105', 'class_1106', 'class_1107', 'class_1108', 'class_1109', 'class_1110', 'class_1111', 'class_1112', 'class_1113', 'class_1114', 'class_1115', 'class_1116', 'class_1117', 'class_1118', 'class_1119', 'class_1120', 'class_1121', 'class_1122', 'class_1123', 'class_1124', 'class_1125', 'class_1126', 'class_1127', 'class_1128', 'class_1129', 'class_1130', 'class_1131', 'class_1132', 'class_1133', 'class_1134', 'class_1135', 'class_1136', 'class_1137', 'class_1138', 'class_1139', 'class_1140', 'class_1141', 'class_1142', 'class_1143', 'class_1144', 'class_1145', 'class_1146', 'class_1147', 'class_1148', 'class_1149', 'class_1150', 'class_1151', 'class_1152', 'class_1153', 'class_1154', 'class_1155', 'class_1156', 'class_1157', 'class_1158', 'class_1159', 'class_1160', 'class_1161', 'class_1162', 'class_1163', 'class_1164', 'class_1165', 'class_1166', 'class_1167', 'class_1168', 'class_1169', 'class_1170', 'class_1171', 'class_1172', 'class_1173', 'class_1174', 'class_1175', 'class_1176', 'class_1177', 'class_1178', 'class_1179', 'class_1180', 'class_1181', 'class_1182', 'class_1183', 'class_1184', 'class_1185', 'class_1186', 'class_1187', 'class_1188', 'class_1189', 'class_1190', 'class_1191', 'class_1192', 'class_1193', 'class_1194', 'class_1195', 'class_1196', 'class_1197', 'class_1198', 'class_1199', 'class_1200', 'class_1201']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] VOC\n",
      " - root        : /home/ISW/project/datasets/VOC\n",
      " - split_mode  : explicit\n",
      " - train_dir   : /home/ISW/project/datasets/VOC/images/train2012 | tag=train2012 | n_train=5717\n",
      " - val_dir     : /home/ISW/project/datasets/VOC/images/val2012 | tag=val2012 | n_val=5823\n",
      " - label_cases : ['original', 'scale_0.6', 'scale_0.7', 'scale_0.8', 'scale_0.9', 'scale_1.1', 'scale_1.2', 'scale_1.3', 'scale_1.4', 'side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - inferred classes (multiclass-based): nc=20, names=['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', 'class_16', 'class_17', 'class_18', 'class_19']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ Cell 1 done.\n",
      "   -> dataset_summaries length = 13\n",
      "   -> roots variable is ready for Cell 2.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 1) Detection datasets discovery & inspection (FINAL)\n",
    "#   - How many datasets are found\n",
    "#   - train/val image count per dataset\n",
    "#   - Whether label cases (original/scale/side) exist\n",
    "#   - Output estimated class count/names (multiclass-based)\n",
    "#\n",
    "# [UPDATED]\n",
    "#   ‚úÖ Reflect split structure rules per dataset name\n",
    "#     * BCCD, brain-tumor, Custom_Blood, homeobjects-3K, kitti, medical-pills, signature\n",
    "#         images/labels -> train, val\n",
    "#     * coco\n",
    "#         images/labels -> train2017, val2017, test2017\n",
    "#     * construction-ppe, african-wildlife\n",
    "#         images/labels -> train, val, test\n",
    "#     * lvis\n",
    "#         images/labels -> train2017, val2017, test2017\n",
    "#     * SKU-110K\n",
    "#         images/labels -> no subfolders\n",
    "#         -> seed-based 8:2 virtual split\n",
    "#     * VOC\n",
    "#         images/labels -> test2007, train2007, train2012, val2007, val2012\n",
    "#         -> use train2012 / val2012 only\n",
    "# ==========================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, sys, random, shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 0) Register PROJECT_MODULE_DIR\n",
    "# -------------------------------------------------------------------------\n",
    "PROJECT_MODULE_DIR = Path(\"/home/ISW/project/Project_Module\")\n",
    "if str(PROJECT_MODULE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_MODULE_DIR))\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1) ultra_det_loader\n",
    "# -------------------------------------------------------------------------\n",
    "from ultra_det_loader import discover_det_datasets\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2) noisy_insection (use only scale/boundary jitter case list)\n",
    "# -------------------------------------------------------------------------\n",
    "try:\n",
    "    from noisy_insection import UNIFORM_SCALING_FACTORS, JITTER_PATTERNS\n",
    "except Exception:\n",
    "    UNIFORM_SCALING_FACTORS = [0.6, 0.8, 1.2, 1.4]\n",
    "    JITTER_PATTERNS = [3, 5, 7]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# User config\n",
    "# -------------------------------------------------------------------------\n",
    "LOAD_DIR = \"/home/ISW/project/datasets\"\n",
    "SEED = 42\n",
    "\n",
    "# Image extensions\n",
    "_IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "\n",
    "def list_images(dir_path: Optional[Path]) -> List[Path]:\n",
    "    if dir_path is None or not Path(dir_path).exists():\n",
    "        return []\n",
    "    dir_path = Path(dir_path)\n",
    "    imgs = []\n",
    "    for p in dir_path.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in _IMG_EXTS:\n",
    "            imgs.append(p)\n",
    "    return sorted(imgs)\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    # Simple normalization to absorb case/separator differences\n",
    "    n = name.strip().lower()\n",
    "    n = n.replace(\"_\", \"-\")\n",
    "    n = n.replace(\" \", \"-\")\n",
    "    return n\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Legacy heuristic (fallback)\n",
    "# -------------------------------------------------------------------------\n",
    "def _fallback_train_dir(images_root: Path) -> Path:\n",
    "    if (images_root / \"train\").is_dir():\n",
    "        return images_root / \"train\"\n",
    "    return images_root\n",
    "\n",
    "def _fallback_val_dir(images_root: Path) -> Optional[Path]:\n",
    "    if (images_root / \"val\").is_dir():\n",
    "        return images_root / \"val\"\n",
    "    if (images_root / \"valid\").is_dir():\n",
    "        return images_root / \"valid\"\n",
    "    return None\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ Dataset-specific split rules\n",
    "# -------------------------------------------------------------------------\n",
    "_SIMPLE_TRAIN_VAL = {\n",
    "    \"bccd\",\n",
    "    \"brain-tumor\",\n",
    "    \"custom-blood\",\n",
    "    \"homeobjects-3k\",\n",
    "    \"kitti\",\n",
    "    \"medical-pills\",\n",
    "    \"signature\",\n",
    "}\n",
    "\n",
    "_TRAIN_TEST_VAL = {\n",
    "    \"construction-ppe\",\n",
    "    \"african-wildlife\",\n",
    "}\n",
    "\n",
    "def detect_split_dirs(ds_root: Path) -> Dict[str, Optional[Path]]:\n",
    "    \"\"\"\n",
    "    Interpret images/labels split structure based on ds_root.\n",
    "    Returns:\n",
    "        {\n",
    "          \"train_img_dir\": Path|None,\n",
    "          \"val_img_dir\": Path|None,\n",
    "          \"test_img_dir\": Path|None,\n",
    "          \"split_mode\": str,  # \"explicit\" | \"sku_virtual_8_2\" | \"fallback\"\n",
    "          \"train_tag\": str,\n",
    "          \"val_tag\": str,\n",
    "        }\n",
    "    \"\"\"\n",
    "    ds_name = normalize_name(ds_root.name)\n",
    "    images_root = ds_root / \"images\"\n",
    "\n",
    "    # 1) VOC rule: use train2012/val2012 only\n",
    "    if ds_name == \"voc\":\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train2012\",\n",
    "            val_img_dir=images_root / \"val2012\",\n",
    "            test_img_dir=None,\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train2012\",\n",
    "            val_tag=\"val2012\",\n",
    "        )\n",
    "\n",
    "    # 2) COCO/LVIS rule\n",
    "    #    - Handle exact coco/lvis names or potential inclusion\n",
    "    if ds_name == \"coco\" or \"coco\" in ds_name:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train2017\",\n",
    "            val_img_dir=images_root / \"val2017\",\n",
    "            test_img_dir=images_root / \"test2017\",\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train2017\",\n",
    "            val_tag=\"val2017\",\n",
    "        )\n",
    "\n",
    "    if ds_name == \"lvis\" or \"lvis\" in ds_name:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train2017\",\n",
    "            val_img_dir=images_root / \"val2017\",\n",
    "            test_img_dir=images_root / \"test2017\",\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train2017\",\n",
    "            val_tag=\"val2017\",\n",
    "        )\n",
    "\n",
    "    # 3) Explicit train/val structure\n",
    "    if ds_name in _SIMPLE_TRAIN_VAL:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train\",\n",
    "            val_img_dir=images_root / \"val\",\n",
    "            test_img_dir=None,\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train\",\n",
    "            val_tag=\"val\",\n",
    "        )\n",
    "\n",
    "    # 4) train/test/val structure (only train/val used for summary)\n",
    "    if ds_name in _TRAIN_TEST_VAL:\n",
    "        return dict(\n",
    "            train_img_dir=images_root / \"train\",\n",
    "            val_img_dir=images_root / \"val\",\n",
    "            test_img_dir=images_root / \"test\",\n",
    "            split_mode=\"explicit\",\n",
    "            train_tag=\"train\",\n",
    "            val_tag=\"val\",\n",
    "        )\n",
    "\n",
    "    # 5) SKU-110K: no subfolders -> virtual split\n",
    "    #    - Handle name variations\n",
    "    if ds_name in {\"sku-110k\", \"sku110k\", \"sku_110k\"} or \"sku\" in ds_name and \"110k\" in ds_name:\n",
    "        return dict(\n",
    "            train_img_dir=images_root,  # Same physical folder since virtual split\n",
    "            val_img_dir=images_root,\n",
    "            test_img_dir=None,\n",
    "            split_mode=\"sku_virtual_8_2\",\n",
    "            train_tag=\"virtual_8_2\",\n",
    "            val_tag=\"virtual_8_2\",\n",
    "        )\n",
    "\n",
    "    # 6) fallback\n",
    "    tr = _fallback_train_dir(images_root)\n",
    "    va = _fallback_val_dir(images_root)\n",
    "    return dict(\n",
    "        train_img_dir=tr,\n",
    "        val_img_dir=va,\n",
    "        test_img_dir=None,\n",
    "        split_mode=\"fallback\",\n",
    "        train_tag=tr.name if tr else \"unknown\",\n",
    "        val_tag=va.name if va else \"missing\",\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Class name estimation\n",
    "# -------------------------------------------------------------------------\n",
    "def infer_class_names_from_labels(label_root: Path, max_files: int = 2000) -> List[str]:\n",
    "    if label_root is None or not label_root.exists():\n",
    "        return [\"class_0\"]\n",
    "\n",
    "    txts = list(label_root.rglob(\"*.txt\"))\n",
    "    if not txts:\n",
    "        return [\"class_0\"]\n",
    "\n",
    "    txts = txts[:max_files]\n",
    "    cls_ids = set()\n",
    "\n",
    "    for t in txts:\n",
    "        try:\n",
    "            with open(t, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) < 5:\n",
    "                        continue\n",
    "                    cid = int(float(parts[0]))\n",
    "                    cls_ids.add(cid)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not cls_ids:\n",
    "        return [\"class_0\"]\n",
    "\n",
    "    max_id = max(cls_ids)\n",
    "    return [f\"class_{i}\" for i in range(max_id + 1)]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Label case detection\n",
    "# -------------------------------------------------------------------------\n",
    "def list_label_cases_for_dataset(ds_root: Path) -> List[Tuple[str, str]]:\n",
    "    cases: List[Tuple[str, str]] = []\n",
    "\n",
    "    if (ds_root / \"labels\").is_dir():\n",
    "        cases.append((\"original\", \"labels\"))\n",
    "\n",
    "    for s in UNIFORM_SCALING_FACTORS:\n",
    "        d = f\"labels_uniform_scaling_{s}\"\n",
    "        if (ds_root / d).is_dir():\n",
    "            cases.append((f\"scale_{s}\", d))\n",
    "\n",
    "    for k in JITTER_PATTERNS:\n",
    "        d = f\"labels_boundary_jitter_{k}\"\n",
    "        if (ds_root / d).is_dir():\n",
    "            cases.append((f\"side_{k}\", d))\n",
    "\n",
    "    return cases\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# SKU-110K virtual split count\n",
    "# -------------------------------------------------------------------------\n",
    "def compute_sku_virtual_counts(images_root: Path, seed: int = 42, ratio: float = 0.8) -> Tuple[int, int]:\n",
    "    imgs = list_images(images_root)\n",
    "    n = len(imgs)\n",
    "    if n == 0:\n",
    "        return 0, 0\n",
    "    rnd = random.Random(seed)\n",
    "    idxs = list(range(n))\n",
    "    rnd.shuffle(idxs)\n",
    "    cut = int(n * ratio)\n",
    "    n_train = cut\n",
    "    n_val = n - cut\n",
    "    return n_train, n_val\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Discover dataset roots\n",
    "# -------------------------------------------------------------------------\n",
    "set_seed(SEED)\n",
    "\n",
    "specs = discover_det_datasets(LOAD_DIR)\n",
    "roots: List[Path] = []\n",
    "for s in specs:\n",
    "    r = Path(s.root)\n",
    "    if r not in roots:\n",
    "        roots.append(r)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"[DISCOVERY] Found {len(roots)} unique dataset roots under: {Path(LOAD_DIR).resolve()}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Per-dataset summary\n",
    "# -------------------------------------------------------------------------\n",
    "dataset_summaries: List[Dict] = []\n",
    "\n",
    "for ds_root in roots:\n",
    "    ds_root = Path(ds_root)\n",
    "    images_root = ds_root / \"images\"\n",
    "    labels_root = ds_root / \"labels\"\n",
    "\n",
    "    if not images_root.is_dir() or not labels_root.is_dir():\n",
    "        print(f\"‚è≠Ô∏è  Skip (missing images/labels): {ds_root}\")\n",
    "        continue\n",
    "\n",
    "    split_info = detect_split_dirs(ds_root)\n",
    "    train_dir = split_info[\"train_img_dir\"]\n",
    "    val_dir   = split_info[\"val_img_dir\"]\n",
    "    split_mode = split_info[\"split_mode\"]\n",
    "    train_tag  = split_info.get(\"train_tag\", \"train\")\n",
    "    val_tag    = split_info.get(\"val_tag\", \"val\")\n",
    "\n",
    "    # --- Calculate image count ---\n",
    "    if split_mode == \"sku_virtual_8_2\":\n",
    "        n_train, n_val = compute_sku_virtual_counts(images_root, seed=SEED, ratio=0.8)\n",
    "    else:\n",
    "        n_train = len(list_images(train_dir))\n",
    "        n_val   = len(list_images(val_dir)) if val_dir else 0\n",
    "\n",
    "    cases = list_label_cases_for_dataset(ds_root)\n",
    "    class_names = infer_class_names_from_labels(labels_root)\n",
    "    nc = len(class_names)\n",
    "\n",
    "    info = {\n",
    "        \"dataset\": ds_root.name,\n",
    "        \"root\": str(ds_root),\n",
    "        \"images_root\": str(images_root),\n",
    "        \"labels_root\": str(labels_root),\n",
    "        \"train_dir\": str(train_dir) if train_dir else None,\n",
    "        \"val_dir\": str(val_dir) if val_dir else None,\n",
    "        \"n_train\": n_train,\n",
    "        \"n_val\": n_val,\n",
    "        \"split_mode\": split_mode,\n",
    "        \"train_tag\": train_tag,\n",
    "        \"val_tag\": val_tag,\n",
    "        \"label_cases\": [c[0] for c in cases],\n",
    "        \"nc_inferred\": nc,\n",
    "        \"class_names_inferred\": class_names,\n",
    "    }\n",
    "    dataset_summaries.append(info)\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(f\"[Dataset] {ds_root.name}\")\n",
    "    print(f\" - root        : {ds_root}\")\n",
    "    print(f\" - split_mode  : {split_mode}\")\n",
    "    print(f\" - train_dir   : {train_dir if train_dir else '(missing)'} | tag={train_tag} | n_train={n_train}\")\n",
    "    print(f\" - val_dir     : {val_dir if val_dir else '(missing)'} | tag={val_tag} | n_val={n_val}\")\n",
    "\n",
    "    # If test structure exists, just report existence (summary counts focus on train/val)\n",
    "    test_dir = split_info.get(\"test_img_dir\", None)\n",
    "    if test_dir and test_dir.is_dir():\n",
    "        n_test = len(list_images(test_dir))\n",
    "        print(f\" - test_dir    : {test_dir} | n_test={n_test}\")\n",
    "\n",
    "    print(f\" - label_cases : {[c[0] for c in cases] if cases else '(none)'}\")\n",
    "    print(f\" - inferred classes (multiclass-based): nc={nc}, names={class_names}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n‚úÖ Cell 1 done.\")\n",
    "print(f\"   -> dataset_summaries length = {len(dataset_summaries)}\")\n",
    "print(\"   -> roots variable is ready for Cell 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e3144",
   "metadata": {},
   "source": [
    "# YOLO model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4d83ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[TRAIN/EVAL] Start (Cell 1 summaries-aware + runtime path safe + object-only)\n",
      " - OUT_ROOT             : /home/ISW/project/object_detect\n",
      " - RUNTIME_VROOT_BASE   : /home/ISW/project/_runtime_dataset_views\n",
      " - TRAIN_FRACTION       : 1.0\n",
      " - NUM_WORKERS          : 8\n",
      " - CLASS_MODES          : ['multiclass', 'object_only']\n",
      " - CLEANUP_RUNTIME_VROOT: True\n",
      " - TRAIN_USE_ORIGINAL   : False\n",
      " - TRAIN_USE_UNIFORM_SCALING_NOISE: False\n",
      " - TRAIN_USE_BOUNDARY_JITTER_NOISE : True\n",
      " - TARGET_DATASETS      : ['african-wildlife', 'bccd', 'brain-tumor', 'construction-ppe', 'custom_blood', 'homeobjects-3k', 'kitti', 'medical-pills', 'signature', 'voc']\n",
      "================================================================================\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): SKU-110K\n",
      "\n",
      "[Integrity Check] kitti\n",
      "   üîç Scanning integrity of 7481 images in images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ  No corrupt images found.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] kitti\n",
      " - split_mode : explicit\n",
      " - Cases      : ['side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - CLASS_MODES: ['multiclass', 'object_only']\n",
      "--------------------------------------------------------------------------------\n",
      "  [Subset] case=side_1 | class_mode=multiclass | split_mode=explicit | train_used=5985/5985 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolov8n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolo11n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/detr__side_1__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_1 | class_mode=object_only | split_mode=explicit | train_used=5985/5985 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolov8n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolo11n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/detr__side_1__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=multiclass | split_mode=explicit | train_used=5985/5985 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolov8n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolo11n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/detr__side_3__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=object_only | split_mode=explicit | train_used=5985/5985 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolov8n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolo11n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/detr__side_3__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=multiclass | split_mode=explicit | train_used=5985/5985 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolov8n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolo11n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/detr__side_5__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=object_only | split_mode=explicit | train_used=5985/5985 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolov8n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolo11n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/detr__side_5__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=multiclass | split_mode=explicit | train_used=5985/5985 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolov8n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolo11n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/detr__side_7__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=object_only | split_mode=explicit | train_used=5985/5985 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolov8n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolo11n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/detr__side_7__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=multiclass | split_mode=explicit | train_used=5985/5985 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolov8n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolo11n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/detr__side_9__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=object_only | split_mode=explicit | train_used=5985/5985 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolov8n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/yolo11n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/kitti/detr__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "[Integrity Check] homeobjects-3K\n",
      "   üîç Scanning integrity of 2689 images in images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ  No corrupt images found.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] homeobjects-3K\n",
      " - split_mode : explicit\n",
      " - Cases      : ['side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - CLASS_MODES: ['multiclass', 'object_only']\n",
      "--------------------------------------------------------------------------------\n",
      "  [Subset] case=side_1 | class_mode=multiclass | split_mode=explicit | train_used=2285/2285 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolov8n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolo11n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/detr__side_1__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_1 | class_mode=object_only | split_mode=explicit | train_used=2285/2285 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolov8n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolo11n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/detr__side_1__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=multiclass | split_mode=explicit | train_used=2285/2285 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolov8n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolo11n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/detr__side_3__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=object_only | split_mode=explicit | train_used=2285/2285 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolov8n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolo11n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/detr__side_3__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=multiclass | split_mode=explicit | train_used=2285/2285 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolov8n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolo11n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/detr__side_5__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=object_only | split_mode=explicit | train_used=2285/2285 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolov8n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolo11n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/detr__side_5__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=multiclass | split_mode=explicit | train_used=2285/2285 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolov8n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolo11n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/detr__side_7__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=object_only | split_mode=explicit | train_used=2285/2285 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolov8n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolo11n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/detr__side_7__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=multiclass | split_mode=explicit | train_used=2285/2285 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolov8n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolo11n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/detr__side_9__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=object_only | split_mode=explicit | train_used=2285/2285 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolov8n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/yolo11n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/homeobjects-3K/detr__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "[Integrity Check] african-wildlife\n",
      "   üîç Scanning integrity of 1504 images in images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ  No corrupt images found.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] african-wildlife\n",
      " - split_mode : explicit\n",
      " - Cases      : ['side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - CLASS_MODES: ['multiclass', 'object_only']\n",
      "--------------------------------------------------------------------------------\n",
      "  [Subset] case=side_1 | class_mode=multiclass | split_mode=explicit | train_used=1052/1052 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolov8n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolo11n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/detr__side_1__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_1 | class_mode=object_only | split_mode=explicit | train_used=1052/1052 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolov8n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolo11n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/detr__side_1__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=multiclass | split_mode=explicit | train_used=1052/1052 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolov8n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolo11n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/detr__side_3__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=object_only | split_mode=explicit | train_used=1052/1052 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolov8n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolo11n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/detr__side_3__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=multiclass | split_mode=explicit | train_used=1052/1052 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolov8n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolo11n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/detr__side_5__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=object_only | split_mode=explicit | train_used=1052/1052 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolov8n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolo11n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/detr__side_5__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=multiclass | split_mode=explicit | train_used=1052/1052 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolov8n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolo11n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/detr__side_7__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=object_only | split_mode=explicit | train_used=1052/1052 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolov8n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolo11n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/detr__side_7__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=multiclass | split_mode=explicit | train_used=1052/1052 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolov8n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolo11n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/detr__side_9__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=object_only | split_mode=explicit | train_used=1052/1052 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolov8n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/yolo11n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/african-wildlife/detr__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "[Integrity Check] construction-ppe\n",
      "   üîç Scanning integrity of 1416 images in images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ  No corrupt images found.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] construction-ppe\n",
      " - split_mode : explicit\n",
      " - Cases      : ['side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - CLASS_MODES: ['multiclass', 'object_only']\n",
      "--------------------------------------------------------------------------------\n",
      "  [Subset] case=side_1 | class_mode=multiclass | split_mode=explicit | train_used=1132/1132 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolov8n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolo11n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/detr__side_1__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_1 | class_mode=object_only | split_mode=explicit | train_used=1132/1132 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolov8n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolo11n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/detr__side_1__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=multiclass | split_mode=explicit | train_used=1132/1132 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolov8n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolo11n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/detr__side_3__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=object_only | split_mode=explicit | train_used=1132/1132 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolov8n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolo11n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/detr__side_3__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=multiclass | split_mode=explicit | train_used=1132/1132 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolov8n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolo11n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/detr__side_5__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=object_only | split_mode=explicit | train_used=1132/1132 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolov8n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolo11n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/detr__side_5__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=multiclass | split_mode=explicit | train_used=1132/1132 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolov8n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolo11n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/detr__side_7__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=object_only | split_mode=explicit | train_used=1132/1132 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolov8n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolo11n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/detr__side_7__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=multiclass | split_mode=explicit | train_used=1132/1132 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolov8n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolo11n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/detr__side_9__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=object_only | split_mode=explicit | train_used=1132/1132 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolov8n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/yolo11n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/construction-ppe/detr__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "[Integrity Check] Custom_Blood\n",
      "   üîç Scanning integrity of 1227 images in images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ  No corrupt images found.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] Custom_Blood\n",
      " - split_mode : explicit\n",
      " - Cases      : ['side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - CLASS_MODES: ['multiclass', 'object_only']\n",
      "--------------------------------------------------------------------------------\n",
      "  [Subset] case=side_1 | class_mode=multiclass | split_mode=explicit | train_used=1105/1105 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolov8n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolo11n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/detr__side_1__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_1 | class_mode=object_only | split_mode=explicit | train_used=1105/1105 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolov8n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolo11n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/detr__side_1__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=multiclass | split_mode=explicit | train_used=1105/1105 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolov8n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolo11n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/detr__side_3__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=object_only | split_mode=explicit | train_used=1105/1105 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolov8n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolo11n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/detr__side_3__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=multiclass | split_mode=explicit | train_used=1105/1105 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolov8n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolo11n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/detr__side_5__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=object_only | split_mode=explicit | train_used=1105/1105 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolov8n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolo11n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/detr__side_5__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=multiclass | split_mode=explicit | train_used=1105/1105 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolov8n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolo11n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/detr__side_7__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=object_only | split_mode=explicit | train_used=1105/1105 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolov8n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolo11n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/detr__side_7__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=multiclass | split_mode=explicit | train_used=1105/1105 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolov8n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolo11n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/detr__side_9__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=object_only | split_mode=explicit | train_used=1105/1105 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolov8n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/yolo11n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/Custom_Blood/detr__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "[Integrity Check] brain-tumor\n",
      "   üîç Scanning integrity of 1116 images in images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ  No corrupt images found.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] brain-tumor\n",
      " - split_mode : explicit\n",
      " - Cases      : ['side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - CLASS_MODES: ['multiclass', 'object_only']\n",
      "--------------------------------------------------------------------------------\n",
      "  [Subset] case=side_1 | class_mode=multiclass | split_mode=explicit | train_used=893/893 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolov8n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolo11n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/detr__side_1__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_1 | class_mode=object_only | split_mode=explicit | train_used=893/893 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolov8n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolo11n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/detr__side_1__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=multiclass | split_mode=explicit | train_used=893/893 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolov8n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolo11n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/detr__side_3__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=object_only | split_mode=explicit | train_used=893/893 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolov8n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolo11n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/detr__side_3__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=multiclass | split_mode=explicit | train_used=893/893 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolov8n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolo11n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/detr__side_5__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=object_only | split_mode=explicit | train_used=893/893 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolov8n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolo11n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/detr__side_5__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=multiclass | split_mode=explicit | train_used=893/893 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolov8n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolo11n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/detr__side_7__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=object_only | split_mode=explicit | train_used=893/893 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolov8n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolo11n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/detr__side_7__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=multiclass | split_mode=explicit | train_used=893/893 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolov8n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolo11n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/detr__side_9__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=object_only | split_mode=explicit | train_used=893/893 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolov8n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/yolo11n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/brain-tumor/detr__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "[Integrity Check] BCCD\n",
      "   üîç Scanning integrity of 364 images in images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ  No corrupt images found.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] BCCD\n",
      " - split_mode : explicit\n",
      " - Cases      : ['side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - CLASS_MODES: ['multiclass', 'object_only']\n",
      "--------------------------------------------------------------------------------\n",
      "  [Subset] case=side_1 | class_mode=multiclass | split_mode=explicit | train_used=310/310 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolov8n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolo11n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/detr__side_1__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_1 | class_mode=object_only | split_mode=explicit | train_used=310/310 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolov8n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolo11n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/detr__side_1__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=multiclass | split_mode=explicit | train_used=310/310 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolov8n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolo11n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/detr__side_3__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=object_only | split_mode=explicit | train_used=310/310 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolov8n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolo11n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/detr__side_3__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=multiclass | split_mode=explicit | train_used=310/310 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolov8n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolo11n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/detr__side_5__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=object_only | split_mode=explicit | train_used=310/310 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolov8n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolo11n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/detr__side_5__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=multiclass | split_mode=explicit | train_used=310/310 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolov8n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolo11n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/detr__side_7__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=object_only | split_mode=explicit | train_used=310/310 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolov8n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolo11n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/detr__side_7__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=multiclass | split_mode=explicit | train_used=310/310 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolov8n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolo11n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/detr__side_9__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=object_only | split_mode=explicit | train_used=310/310 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolov8n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/yolo11n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/BCCD/detr__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "[Integrity Check] signature\n",
      "   üîç Scanning integrity of 178 images in images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ  No corrupt images found.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] signature\n",
      " - split_mode : explicit\n",
      " - Cases      : ['side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - CLASS_MODES: ['multiclass', 'object_only']\n",
      "--------------------------------------------------------------------------------\n",
      "  [Subset] case=side_1 | class_mode=multiclass | split_mode=explicit | train_used=143/143 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolov8n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolo11n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/detr__side_1__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_1 | class_mode=object_only | split_mode=explicit | train_used=143/143 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolov8n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolo11n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/detr__side_1__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=multiclass | split_mode=explicit | train_used=143/143 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolov8n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolo11n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/detr__side_3__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=object_only | split_mode=explicit | train_used=143/143 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolov8n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolo11n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/detr__side_3__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=multiclass | split_mode=explicit | train_used=143/143 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolov8n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolo11n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/detr__side_5__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=object_only | split_mode=explicit | train_used=143/143 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolov8n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolo11n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/detr__side_5__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=multiclass | split_mode=explicit | train_used=143/143 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolov8n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolo11n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/detr__side_7__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=object_only | split_mode=explicit | train_used=143/143 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolov8n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolo11n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/detr__side_7__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=multiclass | split_mode=explicit | train_used=143/143 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolov8n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolo11n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/detr__side_9__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=object_only | split_mode=explicit | train_used=143/143 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolov8n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/yolo11n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/signature/detr__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "[Integrity Check] medical-pills\n",
      "   üîç Scanning integrity of 115 images in images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ  No corrupt images found.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] medical-pills\n",
      " - split_mode : explicit\n",
      " - Cases      : ['side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - CLASS_MODES: ['multiclass', 'object_only']\n",
      "--------------------------------------------------------------------------------\n",
      "  [Subset] case=side_1 | class_mode=multiclass | split_mode=explicit | train_used=92/92 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolov8n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolo11n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/detr__side_1__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_1 | class_mode=object_only | split_mode=explicit | train_used=92/92 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolov8n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolo11n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/detr__side_1__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=multiclass | split_mode=explicit | train_used=92/92 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolov8n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolo11n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/detr__side_3__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=object_only | split_mode=explicit | train_used=92/92 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolov8n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolo11n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/detr__side_3__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=multiclass | split_mode=explicit | train_used=92/92 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolov8n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolo11n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/detr__side_5__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=object_only | split_mode=explicit | train_used=92/92 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolov8n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolo11n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/detr__side_5__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=multiclass | split_mode=explicit | train_used=92/92 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolov8n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolo11n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/detr__side_7__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=object_only | split_mode=explicit | train_used=92/92 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolov8n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolo11n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/detr__side_7__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=multiclass | split_mode=explicit | train_used=92/92 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolov8n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolo11n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/detr__side_9__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=object_only | split_mode=explicit | train_used=92/92 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolov8n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/yolo11n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/medical-pills/detr__side_9__object_only__tr100/metrics_eval.json\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): coco\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): lvis\n",
      "\n",
      "[Integrity Check] VOC\n",
      "   üîç Scanning integrity of 34178 images in images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ  No corrupt images found.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] VOC\n",
      " - split_mode : explicit\n",
      " - Cases      : ['side_1', 'side_3', 'side_5', 'side_7', 'side_9']\n",
      " - CLASS_MODES: ['multiclass', 'object_only']\n",
      "--------------------------------------------------------------------------------\n",
      "  [Subset] case=side_1 | class_mode=multiclass | split_mode=explicit | train_used=5717/5717 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolov8n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolo11n__side_1__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/detr__side_1__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_1 | class_mode=object_only | split_mode=explicit | train_used=5717/5717 (100.0%)\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolov8n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolo11n__side_1__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_1 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/detr__side_1__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=multiclass | split_mode=explicit | train_used=5717/5717 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolov8n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolo11n__side_3__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/detr__side_3__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_3 | class_mode=object_only | split_mode=explicit | train_used=5717/5717 (100.0%)\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolov8n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolo11n__side_3__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_3 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/detr__side_3__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=multiclass | split_mode=explicit | train_used=5717/5717 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolov8n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolo11n__side_5__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/detr__side_5__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_5 | class_mode=object_only | split_mode=explicit | train_used=5717/5717 (100.0%)\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolov8n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolo11n__side_5__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_5 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/detr__side_5__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=multiclass | split_mode=explicit | train_used=5717/5717 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolov8n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolo11n__side_7__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/detr__side_7__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_7 | class_mode=object_only | split_mode=explicit | train_used=5717/5717 (100.0%)\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolov8n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolo11n__side_7__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_7 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/detr__side_7__object_only__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=multiclass | split_mode=explicit | train_used=5717/5717 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolov8n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolo11n__side_9__multiclass__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=multiclass | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/detr__side_9__multiclass__tr100/metrics_eval.json\n",
      "  [Subset] case=side_9 | class_mode=object_only | split_mode=explicit | train_used=5717/5717 (100.0%)\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolov8n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolo11n__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=side_9 | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/detr__side_9__object_only__tr100/metrics_eval.json\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Saved summary CSV: /home/ISW/project/object_detect/summary_final_optimized.csv\n",
      "‚úÖ Total runs: 300\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Cell 2 done.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 2) Train & Validate (FAST & ROBUST) ‚Äî FINAL OPTIMIZED + OBJECT-ONLY\n",
    "#   - Supports both multi-class and object-only modes\n",
    "#   - Select only required modes from CLASS_MODES\n",
    "#   - Select datasets to use via TARGET_DATASETS\n",
    "#   - ‚úÖ NEW: Control training with original / uniform_scaling_noise / boundary_jitter_noise flags\n",
    "# ==========================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, json, shutil, random, csv, sys, time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# ‚úÖ Libraries for image integrity check\n",
    "try:\n",
    "    import cv2\n",
    "    from PIL import Image\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Required libraries are missing. Please install: pip install opencv-python pillow tqdm\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ‚úÖ OOM fragmentation mitigation\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.ERROR)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ FIXED grids (Speed Optimized)\n",
    "#   Note: These values are \"candidate labels_* folders for training\".\n",
    "#           Must match actual generated labels_boundary_jitter_K / labels_uniform_scaling_S folder names for cases to be detected.\n",
    "# -------------------------------------------------------------------------\n",
    "UNIFORM_SCALING_FACTORS = [0.6, 0.7, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
    "JITTER_PATTERNS = [1, 3, 5, 7, 9]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ NEW: Train-case control flags\n",
    "#   - Can control inclusion/exclusion of noise label folders in training\n",
    "# -------------------------------------------------------------------------\n",
    "TRAIN_USE_ORIGINAL    = False\n",
    "TRAIN_USE_UNIFORM_SCALING_NOISE = False\n",
    "TRAIN_USE_BOUNDARY_JITTER_NOISE  = True\n",
    "# e.g.) Original only: TRAIN_USE_ORIGINAL=True, TRAIN_USE_UNIFORM_SCALING_NOISE=False, TRAIN_USE_BOUNDARY_JITTER_NOISE=False\n",
    "# e.g.) Side only: TRAIN_USE_ORIGINAL=False, TRAIN_USE_UNIFORM_SCALING_NOISE=False, TRAIN_USE_BOUNDARY_JITTER_NOISE=True\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ Speed control\n",
    "# -------------------------------------------------------------------------\n",
    "TRAIN_FRACTION = 1.0\n",
    "TRAIN_MIN_IMAGES = 50\n",
    "NUM_WORKERS = min(8, os.cpu_count() or 4)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# User config\n",
    "# -------------------------------------------------------------------------\n",
    "IMG_SIZE = 640\n",
    "EPOCHS = 10\n",
    "BATCH = 32\n",
    "DEVICE = \"0\"\n",
    "SEED = 42\n",
    "\n",
    "OUT_ROOT = Path(\"/home/ISW/project/object_detect\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RUNTIME_VROOT_BASE = Path(\"/home/ISW/project/_runtime_dataset_views\")\n",
    "RUNTIME_VROOT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CORRUPT_BACKUP_DIR = Path(\"/home/ISW/project/_corrupt_files_backup\")\n",
    "CORRUPT_BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CLEANUP_RUNTIME_VROOT = True\n",
    "SILENCE_ULTRA_OUTPUT = True\n",
    "\n",
    "# ‚úÖ Select which class modes to run\n",
    "CLASS_MODES = [\"multiclass\", \"object_only\"]\n",
    "\n",
    "# ‚úÖ Select datasets to use (by folder name, case-insensitive)\n",
    "TARGET_DATASETS: Optional[List[str]] = [\n",
    "    # \"SKU-110K\",\n",
    "    \"kitti\",\n",
    "    \"homeobjects-3K\",\n",
    "    \"african-wildlife\",\n",
    "    \"construction-ppe\",\n",
    "    \"Custom_Blood\",\n",
    "    \"brain-tumor\",\n",
    "    \"BCCD\",\n",
    "    \"signature\",\n",
    "    \"medical-pills\",\n",
    "    # \"coco\",\n",
    "    # \"lvis\",\n",
    "    \"VOC\",\n",
    "]\n",
    "TARGET_DATASETS_LOWER = (\n",
    "    {name.strip().lower() for name in TARGET_DATASETS}\n",
    "    if TARGET_DATASETS is not None\n",
    "    else None\n",
    ")\n",
    "\n",
    "@contextmanager\n",
    "def suppress_output(enabled: bool = True):\n",
    "    if not enabled:\n",
    "        yield\n",
    "        return\n",
    "    devnull = open(os.devnull, \"w\")\n",
    "    old_out, old_err = sys.stdout, sys.stderr\n",
    "    try:\n",
    "        sys.stdout, sys.stderr = devnull, devnull\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout, sys.stderr = old_out, old_err\n",
    "        devnull.close()\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Model specs\n",
    "# -------------------------------------------------------------------------\n",
    "YOLOV8N_CKPT_CANDIDATES = [\"yolov8n.pt\"]\n",
    "YOLO11N_CKPT_CANDIDATES = [\"yolo11n.pt\", \"yolov11n.pt\"]\n",
    "DETR_CKPT_CANDIDATES   = [\"rtdetr-s.pt\", \"rtdetr-l.pt\"]\n",
    "\n",
    "MODEL_SPECS = [\n",
    "    (\"yolov8n\", YOLOV8N_CKPT_CANDIDATES),\n",
    "    (\"yolo11n\", YOLO11N_CKPT_CANDIDATES),\n",
    "    (\"detr\",    DETR_CKPT_CANDIDATES),\n",
    "]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Utils\n",
    "# -------------------------------------------------------------------------\n",
    "_IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def list_images(dir_path: Optional[Path]) -> List[Path]:\n",
    "    if dir_path is None or not Path(dir_path).exists():\n",
    "        return []\n",
    "    dir_path = Path(dir_path)\n",
    "    imgs = []\n",
    "    for p in dir_path.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in _IMG_EXTS:\n",
    "            imgs.append(p)\n",
    "    return sorted(imgs)\n",
    "\n",
    "def _safe_symlink(src: Path, dst: Path):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dst.exists() or dst.is_symlink():\n",
    "        return\n",
    "    os.symlink(str(src), str(dst))\n",
    "\n",
    "def _safe_copytree(src: Path, dst: Path):\n",
    "    if not src.exists():\n",
    "        return\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "\n",
    "def _link_or_copy(src: Path, dst: Path, prefer_symlink: bool = True):\n",
    "    if not src.exists():\n",
    "        return\n",
    "    try:\n",
    "        if src.is_dir():\n",
    "            _safe_copytree(src, dst)\n",
    "            return\n",
    "        if prefer_symlink:\n",
    "            _safe_symlink(src, dst)\n",
    "            return\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(src, dst)\n",
    "    except Exception:\n",
    "        try:\n",
    "            dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(src, dst)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def infer_class_names_from_labels(label_root: Path, max_files: int = 2000) -> List[str]:\n",
    "    if label_root is None or not label_root.exists():\n",
    "        return [\"class_0\"]\n",
    "    txts = list(label_root.rglob(\"*.txt\"))\n",
    "    if not txts:\n",
    "        return [\"class_0\"]\n",
    "\n",
    "    txts = txts[:max_files]\n",
    "    cls_ids = set()\n",
    "    for t in txts:\n",
    "        try:\n",
    "            with open(t, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) < 5:\n",
    "                        continue\n",
    "                    cid = int(float(parts[0]))\n",
    "                    cls_ids.add(cid)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not cls_ids:\n",
    "        return [\"class_0\"]\n",
    "    max_id = max(cls_ids)\n",
    "    return [f\"class_{i}\" for i in range(max_id + 1)]\n",
    "\n",
    "def choose_model(ckpt_candidates: List[str]) -> YOLO:\n",
    "    last_err = None\n",
    "    for ckpt in ckpt_candidates:\n",
    "        try:\n",
    "            return YOLO(ckpt)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"Failed to load model weights: {ckpt_candidates}\") from last_err\n",
    "\n",
    "def extract_metrics_dict(val_result) -> Dict:\n",
    "    if val_result is None:\n",
    "        return {}\n",
    "    if hasattr(val_result, \"results_dict\") and isinstance(val_result.results_dict, dict):\n",
    "        return dict(val_result.results_dict)\n",
    "    try:\n",
    "        d = dict(val_result.__dict__)\n",
    "        d.pop(\"plots\", None)\n",
    "        d.pop(\"speed\", None)\n",
    "        return d\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ Label rewrite utility for object-only mode\n",
    "# -------------------------------------------------------------------------\n",
    "def rewrite_label_file_to_object_only(src: Path, dst: Path):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if not src.exists():\n",
    "        try:\n",
    "            dst.write_text(\"\", encoding=\"utf-8\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        lines_out = []\n",
    "        with open(src, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 5:\n",
    "                    continue\n",
    "                parts[0] = \"0\"\n",
    "                lines_out.append(\" \".join(parts))\n",
    "        with open(dst, \"w\", encoding=\"utf-8\") as f:\n",
    "            for ln in lines_out:\n",
    "                f.write(ln + \"\\n\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            dst.write_text(\"\", encoding=\"utf-8\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ Corrupt Image Cleaner\n",
    "# -------------------------------------------------------------------------\n",
    "def scan_and_clean_images(dir_path: Path):\n",
    "    if not dir_path.exists():\n",
    "        return\n",
    "\n",
    "    images = list_images(dir_path)\n",
    "    if not images:\n",
    "        return\n",
    "\n",
    "    print(f\"   üîç Scanning integrity of {len(images)} images in {dir_path.name}...\")\n",
    "    corrupt_count = 0\n",
    "    for img_path in tqdm(images, desc=\"Checking\", leave=False):\n",
    "        is_corrupt = False\n",
    "\n",
    "        try:\n",
    "            with Image.open(img_path) as im:\n",
    "                im.verify()\n",
    "        except Exception:\n",
    "            is_corrupt = True\n",
    "\n",
    "        if not is_corrupt:\n",
    "            try:\n",
    "                img = cv2.imread(str(img_path))\n",
    "                if img is None:\n",
    "                    is_corrupt = True\n",
    "                else:\n",
    "                    _ = img.shape\n",
    "            except Exception:\n",
    "                is_corrupt = True\n",
    "\n",
    "        if is_corrupt:\n",
    "            corrupt_count += 1\n",
    "            dest = CORRUPT_BACKUP_DIR / dir_path.name / img_path.name\n",
    "            dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            label_path = img_path.parent.parent / \"labels\" / img_path.parent.name / img_path.with_suffix(\".txt\").name\n",
    "            if not label_path.exists():\n",
    "                label_path = img_path.with_suffix(\".txt\")\n",
    "\n",
    "            try:\n",
    "                shutil.move(str(img_path), str(dest))\n",
    "                if label_path.exists():\n",
    "                    shutil.move(str(label_path), str(dest.with_suffix(\".txt\")))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    if corrupt_count > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  Moved {corrupt_count} corrupt images to {CORRUPT_BACKUP_DIR}\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ  No corrupt images found.\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Split/Case helpers\n",
    "# -------------------------------------------------------------------------\n",
    "def normalize_name(name: str) -> str:\n",
    "    return name.strip().lower().replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "_ds_map: Dict[str, Dict] = {}\n",
    "try:\n",
    "    for info in dataset_summaries:\n",
    "        key = normalize_name(info.get(\"dataset\", \"\"))\n",
    "        if key:\n",
    "            _ds_map[key] = info\n",
    "except Exception:\n",
    "    _ds_map = {}\n",
    "\n",
    "def get_split_info(ds_root: Path) -> Dict[str, Optional[Path]]:\n",
    "    key = normalize_name(ds_root.name)\n",
    "    if key in _ds_map:\n",
    "        info = _ds_map[key]\n",
    "        return dict(\n",
    "            train_img_dir=Path(info[\"train_dir\"]) if info.get(\"train_dir\") else None,\n",
    "            val_img_dir=Path(info[\"val_dir\"]) if info.get(\"val_dir\") else None,\n",
    "            split_mode=info.get(\"split_mode\", \"fallback\"),\n",
    "            train_tag=info.get(\"train_tag\", \"train\"),\n",
    "            val_tag=info.get(\"val_tag\", \"val\"),\n",
    "        )\n",
    "\n",
    "    images_root = ds_root / \"images\"\n",
    "    tr = images_root / \"train\" if (images_root / \"train\").is_dir() else images_root\n",
    "    va = images_root / \"val\" if (images_root / \"val\").is_dir() else (images_root / \"valid\" if (images_root / \"valid\").is_dir() else None)\n",
    "    return dict(\n",
    "        train_img_dir=tr,\n",
    "        val_img_dir=va,\n",
    "        split_mode=\"fallback\",\n",
    "        train_tag=tr.name if tr else \"unknown\",\n",
    "        val_tag=va.name if va else \"missing\",\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ NEW: label case listing (flags reflected)\n",
    "# -------------------------------------------------------------------------\n",
    "def list_label_cases_for_dataset(ds_root: Path) -> List[Tuple[str, str]]:\n",
    "    key = normalize_name(ds_root.name)\n",
    "    existing = None\n",
    "    if key in _ds_map and isinstance(_ds_map[key].get(\"label_cases\"), list):\n",
    "        existing = set(_ds_map[key][\"label_cases\"])\n",
    "\n",
    "    cases: List[Tuple[str, str]] = []\n",
    "\n",
    "    # (1) original\n",
    "    if TRAIN_USE_ORIGINAL:\n",
    "        if (ds_root / \"labels\").is_dir() and (existing is None or \"original\" in existing):\n",
    "            cases.append((\"original\", \"labels\"))\n",
    "\n",
    "    # (2) uniform scaling noise\n",
    "    if TRAIN_USE_UNIFORM_SCALING_NOISE:\n",
    "        for s in UNIFORM_SCALING_FACTORS:\n",
    "            tag = f\"scale_{s}\"\n",
    "            dirname = f\"labels_uniform_scaling_{s}\"\n",
    "            if (ds_root / dirname).is_dir() and (existing is None or tag in existing):\n",
    "                cases.append((tag, dirname))\n",
    "\n",
    "    # (3) boundary jitter noise\n",
    "    if TRAIN_USE_BOUNDARY_JITTER_NOISE:\n",
    "        for k in JITTER_PATTERNS:\n",
    "            tag = f\"side_{k}\"\n",
    "            dirname = f\"labels_boundary_jitter_{k}\"\n",
    "            if (ds_root / dirname).is_dir() and (existing is None or tag in existing):\n",
    "                cases.append((tag, dirname))\n",
    "\n",
    "    return cases\n",
    "\n",
    "def resolve_label_base(label_root: Path, split_tag: str, is_train: bool) -> Path:\n",
    "    if label_root is None:\n",
    "        return label_root\n",
    "    tagged = label_root / split_tag\n",
    "    if split_tag and tagged.is_dir():\n",
    "        return tagged\n",
    "    if is_train:\n",
    "        tdir = label_root / \"train\"\n",
    "        if tdir.is_dir():\n",
    "            return tdir\n",
    "        return label_root\n",
    "    else:\n",
    "        vdir = label_root / \"val\"\n",
    "        if vdir.is_dir():\n",
    "            return vdir\n",
    "        vdir2 = label_root / \"valid\"\n",
    "        if vdir2.is_dir():\n",
    "            return vdir2\n",
    "        return label_root\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# SKU virtual split & Runtime View (unchanged)\n",
    "# -------------------------------------------------------------------------\n",
    "def sku_virtual_split_images(images_root: Path, seed: int = 42, ratio: float = 0.8) -> Tuple[List[Path], List[Path]]:\n",
    "    imgs = list_images(images_root)\n",
    "    n = len(imgs)\n",
    "    if n == 0:\n",
    "        return [], []\n",
    "    rnd = random.Random(seed)\n",
    "    idxs = list(range(n))\n",
    "    rnd.shuffle(idxs)\n",
    "    cut = int(n * ratio)\n",
    "    train_imgs = [imgs[i] for i in idxs[:cut]]\n",
    "    val_imgs   = [imgs[i] for i in idxs[cut:]]\n",
    "    return train_imgs, val_imgs\n",
    "\n",
    "def sample_train_images(base_train_imgs: List[Path], fraction: float, seed: int) -> Tuple[List[Path], int]:\n",
    "    n_total = len(base_train_imgs)\n",
    "    if n_total == 0:\n",
    "        return [], 0\n",
    "    if fraction >= 1.0:\n",
    "        return base_train_imgs, n_total\n",
    "    n_pick = int(n_total * fraction)\n",
    "    n_pick = max(TRAIN_MIN_IMAGES, n_pick)\n",
    "    n_pick = min(n_pick, n_total)\n",
    "    rnd = random.Random(seed)\n",
    "    chosen = rnd.sample(base_train_imgs, k=n_pick)\n",
    "    return chosen, n_total\n",
    "\n",
    "def build_runtime_view_root(\n",
    "    ds_root: Path,\n",
    "    case_labels_dirname: str,\n",
    "    train_fraction: float,\n",
    "    seed: int,\n",
    "    class_mode: str = \"multiclass\",\n",
    ") -> Tuple[Path, Path, int, int, str]:\n",
    "\n",
    "    assert class_mode in (\"multiclass\", \"object_only\")\n",
    "    images_root     = ds_root / \"images\"\n",
    "    orig_label_root = ds_root / \"labels\"\n",
    "    case_label_root = ds_root / case_labels_dirname\n",
    "\n",
    "    split_info = get_split_info(ds_root)\n",
    "    train_img_dir = split_info[\"train_img_dir\"]\n",
    "    val_img_dir   = split_info[\"val_img_dir\"]\n",
    "    split_mode    = split_info[\"split_mode\"]\n",
    "    train_tag     = split_info.get(\"train_tag\", \"train\")\n",
    "    val_tag       = split_info.get(\"val_tag\", \"val\")\n",
    "\n",
    "    vroot    = RUNTIME_VROOT_BASE / ds_root.name / f\"case__{case_labels_dirname}__{class_mode}\"\n",
    "    v_images = vroot / \"images\"\n",
    "    v_labels = vroot / \"labels\"\n",
    "\n",
    "    if vroot.exists():\n",
    "        try:\n",
    "            shutil.rmtree(vroot)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    (v_images / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "    (v_images / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "    (v_labels / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "    (v_labels / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # A) SKU virtual split\n",
    "    if split_mode == \"sku_virtual_8_2\":\n",
    "        base_train_imgs, base_val_imgs = sku_virtual_split_images(images_root, seed=seed, ratio=0.8)\n",
    "        chosen_train_imgs, n_total_train = sample_train_images(base_train_imgs, train_fraction, seed)\n",
    "\n",
    "        for img in chosen_train_imgs:\n",
    "            rel = img.relative_to(images_root)\n",
    "            dst = v_images / \"train\" / rel\n",
    "            try:\n",
    "                _safe_symlink(img, dst)\n",
    "            except Exception:\n",
    "                _link_or_copy(img, dst, prefer_symlink=False)\n",
    "\n",
    "        for img in base_val_imgs:\n",
    "            rel = img.relative_to(images_root)\n",
    "            dst = v_images / \"val\" / rel\n",
    "            try:\n",
    "                _safe_symlink(img, dst)\n",
    "            except Exception:\n",
    "                _link_or_copy(img, dst, prefer_symlink=False)\n",
    "\n",
    "        for img in chosen_train_imgs:\n",
    "            rel = img.relative_to(images_root)\n",
    "            src_lbl = case_label_root / rel.with_suffix(\".txt\")\n",
    "            dst_lbl = v_labels / \"train\" / rel.with_suffix(\".txt\")\n",
    "            if class_mode == \"multiclass\":\n",
    "                dst_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
    "                if src_lbl.exists():\n",
    "                    try:\n",
    "                        _safe_symlink(src_lbl, dst_lbl)\n",
    "                    except Exception:\n",
    "                        _link_or_copy(src_lbl, dst_lbl, prefer_symlink=False)\n",
    "                else:\n",
    "                    try:\n",
    "                        dst_lbl.write_text(\"\", encoding=\"utf-8\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            else:\n",
    "                rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "        for img in base_val_imgs:\n",
    "            rel = img.relative_to(images_root)\n",
    "            src_lbl = orig_label_root / rel.with_suffix(\".txt\")\n",
    "            dst_lbl = v_labels / \"val\" / rel.with_suffix(\".txt\")\n",
    "            if class_mode == \"multiclass\":\n",
    "                dst_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
    "                if src_lbl.exists():\n",
    "                    try:\n",
    "                        _safe_symlink(src_lbl, dst_lbl)\n",
    "                    except Exception:\n",
    "                        _link_or_copy(src_lbl, dst_lbl, prefer_symlink=False)\n",
    "                else:\n",
    "                    try:\n",
    "                        dst_lbl.write_text(\"\", encoding=\"utf-8\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            else:\n",
    "                rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "        if class_mode == \"multiclass\":\n",
    "            names = infer_class_names_from_labels(orig_label_root)\n",
    "            nc = len(names)\n",
    "        else:\n",
    "            names = [\"object\"]\n",
    "            nc = 1\n",
    "\n",
    "        data_yaml = vroot / \"data.yaml\"\n",
    "        with open(data_yaml, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\n",
    "                f\"path: {str(vroot)}\\n\"\n",
    "                f\"train: images/train\\n\"\n",
    "                f\"val: images/val\\n\"\n",
    "                f\"nc: {nc}\\n\"\n",
    "                f\"names: {names}\\n\"\n",
    "            )\n",
    "\n",
    "        rt_n_train = len(list_images(v_images / \"train\"))\n",
    "        if rt_n_train == 0:\n",
    "            raise RuntimeError(f\"Runtime train images empty (SKU mode): {v_images/'train'}\")\n",
    "\n",
    "        return vroot, data_yaml, len(chosen_train_imgs), len(base_train_imgs), split_mode\n",
    "\n",
    "    # B) Standard split\n",
    "    if train_img_dir is None or not Path(train_img_dir).is_dir():\n",
    "        raise RuntimeError(f\"No train images dir resolved for {ds_root.name}\")\n",
    "    if val_img_dir is None or not Path(val_img_dir).is_dir():\n",
    "        raise RuntimeError(f\"No val images dir resolved for {ds_root.name}\")\n",
    "\n",
    "    all_train_imgs = list_images(train_img_dir)\n",
    "    chosen_train_imgs, n_total_train = sample_train_images(all_train_imgs, train_fraction, seed)\n",
    "    if n_total_train == 0 or len(chosen_train_imgs) == 0:\n",
    "        raise RuntimeError(f\"No train images for {ds_root.name}\")\n",
    "\n",
    "    for img in chosen_train_imgs:\n",
    "        rel = img.relative_to(train_img_dir)\n",
    "        dst = v_images / \"train\" / rel\n",
    "        try:\n",
    "            _safe_symlink(img, dst)\n",
    "        except Exception:\n",
    "            _link_or_copy(img, dst, prefer_symlink=False)\n",
    "\n",
    "    _safe_copytree(Path(val_img_dir), v_images / \"val\")\n",
    "\n",
    "    case_train_lbl_base = resolve_label_base(case_label_root, train_tag, is_train=True)\n",
    "    for img in chosen_train_imgs:\n",
    "        rel = img.relative_to(train_img_dir)\n",
    "        src_lbl = case_train_lbl_base / rel.with_suffix(\".txt\")\n",
    "        dst_lbl = v_labels / \"train\" / rel.with_suffix(\".txt\")\n",
    "        if class_mode == \"multiclass\":\n",
    "            dst_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
    "            if src_lbl.exists():\n",
    "                try:\n",
    "                    _safe_symlink(src_lbl, dst_lbl)\n",
    "                except Exception:\n",
    "                    _link_or_copy(src_lbl, dst_lbl, prefer_symlink=False)\n",
    "            else:\n",
    "                try:\n",
    "                    dst_lbl.write_text(\"\", encoding=\"utf-8\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "        else:\n",
    "            rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "    orig_val_lbl_base = resolve_label_base(orig_label_root, val_tag, is_train=False)\n",
    "    if class_mode == \"multiclass\":\n",
    "        _safe_copytree(orig_val_lbl_base, v_labels / \"val\")\n",
    "    else:\n",
    "        for src_lbl in orig_val_lbl_base.rglob(\"*.txt\"):\n",
    "            rel = src_lbl.relative_to(orig_val_lbl_base)\n",
    "            dst_lbl = v_labels / \"val\" / rel\n",
    "            rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "    if class_mode == \"multiclass\":\n",
    "        names = infer_class_names_from_labels(orig_label_root)\n",
    "        nc = len(names)\n",
    "    else:\n",
    "        names = [\"object\"]\n",
    "        nc = 1\n",
    "\n",
    "    data_yaml = vroot / \"data.yaml\"\n",
    "    with open(data_yaml, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\n",
    "            f\"path: {str(vroot)}\\n\"\n",
    "            f\"train: images/train\\n\"\n",
    "            f\"val: images/val\\n\"\n",
    "            f\"nc: {nc}\\n\"\n",
    "            f\"names: {names}\\n\"\n",
    "        )\n",
    "\n",
    "    rt_n_train = len(list_images(v_images / \"train\"))\n",
    "    rt_n_val   = len(list_images(v_images / \"val\"))\n",
    "    if rt_n_train == 0:\n",
    "        raise RuntimeError(f\"Runtime train images empty: {v_images/'train'}\")\n",
    "    if rt_n_val == 0:\n",
    "        raise RuntimeError(f\"Runtime val images empty: {v_images/'val'}\")\n",
    "\n",
    "    return vroot, data_yaml, len(chosen_train_imgs), n_total_train, split_mode\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# OOM-safe train wrapper\n",
    "# -------------------------------------------------------------------------\n",
    "def train_with_auto_oom(model: YOLO, data_yaml: Path, project_dir: Path, name_dir: str, model_tag: str):\n",
    "    if model_tag == \"detr\":\n",
    "        candidates = [(4, 640), (2, 640), (2, 512), (1, 512)]\n",
    "    else:\n",
    "        candidates = [(BATCH, IMG_SIZE)]\n",
    "\n",
    "    last_err = None\n",
    "    for b, sz in candidates:\n",
    "        try:\n",
    "            with suppress_output(SILENCE_ULTRA_OUTPUT):\n",
    "                model.train(\n",
    "                    data=str(data_yaml),\n",
    "                    epochs=EPOCHS,\n",
    "                    imgsz=sz,\n",
    "                    batch=b,\n",
    "                    device=DEVICE,\n",
    "                    project=str(project_dir),\n",
    "                    name=name_dir,\n",
    "                    exist_ok=True,\n",
    "                    verbose=False,\n",
    "                    workers=NUM_WORKERS,\n",
    "                    amp=True,\n",
    "                )\n",
    "            return True, b, sz, None\n",
    "        except RuntimeError as e:\n",
    "            msg = str(e).lower()\n",
    "            last_err = e\n",
    "            if \"out of memory\" in msg or \"cuda out of memory\" in msg:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.ipc_collect()\n",
    "                continue\n",
    "            break\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            break\n",
    "    return False, None, None, last_err\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Train & validate loop\n",
    "# -------------------------------------------------------------------------\n",
    "set_seed(SEED)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"[TRAIN/EVAL] Start (Cell 1 summaries-aware + runtime path safe + object-only)\")\n",
    "print(f\" - OUT_ROOT             : {OUT_ROOT}\")\n",
    "print(f\" - RUNTIME_VROOT_BASE   : {RUNTIME_VROOT_BASE}\")\n",
    "print(f\" - TRAIN_FRACTION       : {TRAIN_FRACTION}\")\n",
    "print(f\" - NUM_WORKERS          : {NUM_WORKERS}\")\n",
    "print(f\" - CLASS_MODES          : {CLASS_MODES}\")\n",
    "print(f\" - CLEANUP_RUNTIME_VROOT: {CLEANUP_RUNTIME_VROOT}\")\n",
    "print(f\" - TRAIN_USE_ORIGINAL   : {TRAIN_USE_ORIGINAL}\")\n",
    "print(f\" - TRAIN_USE_UNIFORM_SCALING_NOISE: {TRAIN_USE_UNIFORM_SCALING_NOISE}\")\n",
    "print(f\" - TRAIN_USE_BOUNDARY_JITTER_NOISE : {TRAIN_USE_BOUNDARY_JITTER_NOISE}\")\n",
    "if TARGET_DATASETS_LOWER is None:\n",
    "    print(f\" - TARGET_DATASETS      : ALL (no filter)\")\n",
    "else:\n",
    "    print(f\" - TARGET_DATASETS      : {sorted(TARGET_DATASETS_LOWER)}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary_rows: List[Dict] = []\n",
    "\n",
    "try:\n",
    "    _ = roots\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Please run Cell 1 first to prepare the roots variable.\")\n",
    "\n",
    "for ds_root in roots:\n",
    "    ds_root = Path(ds_root)\n",
    "\n",
    "    if TARGET_DATASETS_LOWER is not None:\n",
    "        ds_name_lower = ds_root.name.strip().lower()\n",
    "        if ds_name_lower not in TARGET_DATASETS_LOWER:\n",
    "            print(f\"‚è≠Ô∏è  Skip (not in TARGET_DATASETS): {ds_root.name}\")\n",
    "            continue\n",
    "\n",
    "    images_root = ds_root / \"images\"\n",
    "    labels_root = ds_root / \"labels\"\n",
    "\n",
    "    if not images_root.is_dir() or not labels_root.is_dir():\n",
    "        print(f\"‚è≠Ô∏è  Skip (missing images/labels): {ds_root}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n[Integrity Check] {ds_root.name}\")\n",
    "    scan_and_clean_images(images_root)\n",
    "\n",
    "    cases = list_label_cases_for_dataset(ds_root)\n",
    "    if not cases:\n",
    "        print(f\"‚è≠Ô∏è  Skip (no target label cases after flags/grid filter): {ds_root.name}\")\n",
    "        continue\n",
    "\n",
    "    sp = get_split_info(ds_root)\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(f\"[Dataset] {ds_root.name}\")\n",
    "    print(f\" - split_mode : {sp.get('split_mode')}\")\n",
    "    print(f\" - Cases      : {[c[0] for c in cases]}\")\n",
    "    print(f\" - CLASS_MODES: {CLASS_MODES}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for case_tag, labels_dirname in cases:\n",
    "        for class_mode in CLASS_MODES:\n",
    "            try:\n",
    "                vroot, data_yaml, n_used, n_total, split_mode = build_runtime_view_root(\n",
    "                    ds_root=ds_root,\n",
    "                    case_labels_dirname=labels_dirname,\n",
    "                    train_fraction=TRAIN_FRACTION,\n",
    "                    seed=SEED,\n",
    "                    class_mode=class_mode,\n",
    "                )\n",
    "                pct = (n_used / max(1, n_total)) * 100.0\n",
    "                print(f\"  [Subset] case={case_tag} | class_mode={class_mode} | split_mode={split_mode} | train_used={n_used}/{n_total} ({pct:.1f}%)\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚è≠Ô∏è  Skip build failed: case={case_tag} | class_mode={class_mode} | err={e}\")\n",
    "                continue\n",
    "\n",
    "            for model_tag, ckpt_candidates in MODEL_SPECS:\n",
    "                print(f\"\\n  [Train] case={case_tag} | class_mode={class_mode} | model={model_tag}\")\n",
    "\n",
    "                try:\n",
    "                    model = choose_model(ckpt_candidates)\n",
    "                except Exception as e:\n",
    "                    print(f\"    ‚ùå Model load failed: {ckpt_candidates} | err={e}\")\n",
    "                    continue\n",
    "\n",
    "                project_dir = OUT_ROOT / ds_root.name\n",
    "                frac_tag = f\"tr{int(TRAIN_FRACTION*100)}\"\n",
    "                name_dir = f\"{model_tag}__{case_tag}__{class_mode}__{frac_tag}\"\n",
    "                project_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                ok, used_b, used_sz, err = train_with_auto_oom(model, data_yaml, project_dir, name_dir, model_tag)\n",
    "                if not ok:\n",
    "                    print(f\"    ‚ùå Train failed: {err}\")\n",
    "                    try:\n",
    "                        del model\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                        torch.cuda.ipc_collect()\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    with suppress_output(SILENCE_ULTRA_OUTPUT):\n",
    "                        val_res = model.val(\n",
    "                            data=str(data_yaml),\n",
    "                            imgsz=used_sz if used_sz else IMG_SIZE,\n",
    "                            device=DEVICE,\n",
    "                            split=\"val\",\n",
    "                            verbose=False,\n",
    "                            workers=NUM_WORKERS,\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    print(f\"    ‚ùå Val failed: {e}\")\n",
    "                    val_res = None\n",
    "\n",
    "                metrics = extract_metrics_dict(val_res)\n",
    "\n",
    "                metrics_out = project_dir / name_dir / \"metrics_eval.json\"\n",
    "                try:\n",
    "                    metrics_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    with open(metrics_out, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(\n",
    "                            {\n",
    "                                \"dataset\": ds_root.name,\n",
    "                                \"root\": str(ds_root),\n",
    "                                \"case_tag\": case_tag,\n",
    "                                \"labels_dirname\": labels_dirname,\n",
    "                                \"class_mode\": class_mode,\n",
    "                                \"model_tag\": model_tag,\n",
    "                                \"ckpt_candidates\": ckpt_candidates,\n",
    "                                \"train_fraction\": TRAIN_FRACTION,\n",
    "                                \"train_used\": n_used,\n",
    "                                \"train_total\": n_total,\n",
    "                                \"data_yaml\": str(data_yaml),\n",
    "                                \"runtime_view_root\": str(vroot),\n",
    "                                \"split_mode\": split_mode,\n",
    "                                \"effective_batch\": used_b,\n",
    "                                \"effective_imgsz\": used_sz,\n",
    "                                \"metrics\": metrics,\n",
    "                            },\n",
    "                            f,\n",
    "                            ensure_ascii=False,\n",
    "                            indent=2,\n",
    "                        )\n",
    "                    print(f\"    ‚úÖ Saved metrics: {metrics_out}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                row = {\n",
    "                    \"dataset\": ds_root.name,\n",
    "                    \"model\": model_tag,\n",
    "                    \"case\": case_tag,\n",
    "                    \"labels_dir\": labels_dirname,\n",
    "                    \"class_mode\": class_mode,\n",
    "                    \"split_mode\": split_mode,\n",
    "                    \"train_fraction\": TRAIN_FRACTION,\n",
    "                    \"train_used\": n_used,\n",
    "                    \"train_total\": n_total,\n",
    "                    \"effective_batch\": used_b,\n",
    "                    \"effective_imgsz\": used_sz,\n",
    "                }\n",
    "                for k in [\"metrics/mAP50(B)\", \"metrics/mAP50-95(B)\", \"metrics/precision(B)\", \"metrics/recall(B)\"]:\n",
    "                    if k in metrics:\n",
    "                        row[k] = metrics[k]\n",
    "\n",
    "                summary_rows.append(row)\n",
    "\n",
    "                try:\n",
    "                    del model\n",
    "                except Exception:\n",
    "                    pass\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.ipc_collect()\n",
    "\n",
    "            if CLEANUP_RUNTIME_VROOT:\n",
    "                try:\n",
    "                    shutil.rmtree(vroot)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Save summary CSV\n",
    "# -------------------------------------------------------------------------\n",
    "out_csv = OUT_ROOT / \"summary_final_optimized.csv\"\n",
    "try:\n",
    "    cols = set()\n",
    "    for r in summary_rows:\n",
    "        cols.update(r.keys())\n",
    "\n",
    "    base_cols = [\n",
    "        \"dataset\", \"model\", \"case\", \"labels_dir\",\n",
    "        \"class_mode\",\n",
    "        \"split_mode\",\n",
    "        \"train_fraction\", \"train_used\", \"train_total\",\n",
    "        \"effective_batch\", \"effective_imgsz\",\n",
    "    ]\n",
    "    extra_cols = sorted([c for c in cols if c not in set(base_cols)])\n",
    "    cols = base_cols + extra_cols\n",
    "\n",
    "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=cols)\n",
    "        w.writeheader()\n",
    "        for r in summary_rows:\n",
    "            w.writerow(r)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"‚úÖ Saved summary CSV: {out_csv}\")\n",
    "    print(f\"‚úÖ Total runs: {len(summary_rows)}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Summary CSV save failed: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 2 done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b74ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 2) Train & Validate (FAST & ROBUST) ‚Äî FINAL OPTIMIZED + OBJECT-ONLY\n",
    "#   - Supports both multi-class and object-only modes\n",
    "#   - Select only required modes from CLASS_MODES\n",
    "#   - Select datasets to use via TARGET_DATASETS\n",
    "#   - ‚úÖ NEW: Control training with original / uniform_scaling_noise / boundary_jitter_noise flags\n",
    "# ==========================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, json, shutil, random, csv, sys, time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# ‚úÖ Libraries for image integrity check\n",
    "try:\n",
    "    import cv2\n",
    "    from PIL import Image\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Required libraries are missing. Please install: pip install opencv-python pillow tqdm\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ‚úÖ OOM fragmentation mitigation\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.ERROR)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ FIXED grids (Speed Optimized)\n",
    "#   Note: These values are \"candidate labels_* folders for training\".\n",
    "#           Must match actual generated labels_boundary_jitter_K / labels_uniform_scaling_S folder names for cases to be detected.\n",
    "# -------------------------------------------------------------------------\n",
    "UNIFORM_SCALING_FACTORS = [0.6, 0.7, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
    "JITTER_PATTERNS = [1, 3, 5, 7, 9]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ NEW: Train-case control flags\n",
    "#   - Can control inclusion/exclusion of noise label folders in training\n",
    "# -------------------------------------------------------------------------\n",
    "TRAIN_USE_ORIGINAL    = False\n",
    "TRAIN_USE_UNIFORM_SCALING_NOISE = False\n",
    "TRAIN_USE_BOUNDARY_JITTER_NOISE  = True\n",
    "# e.g.) Original only: TRAIN_USE_ORIGINAL=True, TRAIN_USE_UNIFORM_SCALING_NOISE=False, TRAIN_USE_BOUNDARY_JITTER_NOISE=False\n",
    "# e.g.) Side only: TRAIN_USE_ORIGINAL=False, TRAIN_USE_UNIFORM_SCALING_NOISE=False, TRAIN_USE_BOUNDARY_JITTER_NOISE=True\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ Speed control\n",
    "# -------------------------------------------------------------------------\n",
    "TRAIN_FRACTION = 1.0\n",
    "TRAIN_MIN_IMAGES = 50\n",
    "NUM_WORKERS = min(8, os.cpu_count() or 4)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# User config\n",
    "# -------------------------------------------------------------------------\n",
    "IMG_SIZE = 640\n",
    "EPOCHS = 10\n",
    "BATCH = 32\n",
    "DEVICE = \"0\"\n",
    "SEED = 42\n",
    "\n",
    "OUT_ROOT = Path(\"/home/ISW/project/object_detect\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RUNTIME_VROOT_BASE = Path(\"/home/ISW/project/_runtime_dataset_views\")\n",
    "RUNTIME_VROOT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CORRUPT_BACKUP_DIR = Path(\"/home/ISW/project/_corrupt_files_backup\")\n",
    "CORRUPT_BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CLEANUP_RUNTIME_VROOT = True\n",
    "SILENCE_ULTRA_OUTPUT = True\n",
    "\n",
    "# ‚úÖ Select which class modes to run\n",
    "CLASS_MODES = [\"multiclass\", \"object_only\"]\n",
    "\n",
    "# ‚úÖ Select datasets to use (by folder name, case-insensitive)\n",
    "TARGET_DATASETS: Optional[List[str]] = [\n",
    "    # \"SKU-110K\",\n",
    "    # \"coco\",\n",
    "    # \"lvis\",\n",
    "    \"kitti\",\n",
    "    \"homeobjects-3K\",\n",
    "    \"african-wildlife\",\n",
    "    \"construction-ppe\",\n",
    "    \"Custom_Blood\",\n",
    "    \"brain-tumor\",\n",
    "    \"BCCD\",\n",
    "    \"signature\",\n",
    "    \"medical-pills\",\n",
    "    \"VOC\",\n",
    "]\n",
    "TARGET_DATASETS_LOWER = (\n",
    "    {name.strip().lower() for name in TARGET_DATASETS}\n",
    "    if TARGET_DATASETS is not None\n",
    "    else None\n",
    ")\n",
    "\n",
    "@contextmanager\n",
    "def suppress_output(enabled: bool = True):\n",
    "    if not enabled:\n",
    "        yield\n",
    "        return\n",
    "    devnull = open(os.devnull, \"w\")\n",
    "    old_out, old_err = sys.stdout, sys.stderr\n",
    "    try:\n",
    "        sys.stdout, sys.stderr = devnull, devnull\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout, sys.stderr = old_out, old_err\n",
    "        devnull.close()\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Model specs\n",
    "# -------------------------------------------------------------------------\n",
    "YOLOV8N_CKPT_CANDIDATES = [\"yolov8n.pt\"]\n",
    "YOLO11N_CKPT_CANDIDATES = [\"yolo11n.pt\", \"yolov11n.pt\"]\n",
    "DETR_CKPT_CANDIDATES   = [\"rtdetr-s.pt\", \"rtdetr-l.pt\"]\n",
    "\n",
    "MODEL_SPECS = [\n",
    "    (\"yolov8n\", YOLOV8N_CKPT_CANDIDATES),\n",
    "    (\"yolo11n\", YOLO11N_CKPT_CANDIDATES),\n",
    "    (\"detr\",    DETR_CKPT_CANDIDATES),\n",
    "]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Utils\n",
    "# -------------------------------------------------------------------------\n",
    "_IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def list_images(dir_path: Optional[Path]) -> List[Path]:\n",
    "    if dir_path is None or not Path(dir_path).exists():\n",
    "        return []\n",
    "    dir_path = Path(dir_path)\n",
    "    imgs = []\n",
    "    for p in dir_path.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in _IMG_EXTS:\n",
    "            imgs.append(p)\n",
    "    return sorted(imgs)\n",
    "\n",
    "def _safe_symlink(src: Path, dst: Path):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dst.exists() or dst.is_symlink():\n",
    "        return\n",
    "    os.symlink(str(src), str(dst))\n",
    "\n",
    "def _safe_copytree(src: Path, dst: Path):\n",
    "    if not src.exists():\n",
    "        return\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "\n",
    "def _link_or_copy(src: Path, dst: Path, prefer_symlink: bool = True):\n",
    "    if not src.exists():\n",
    "        return\n",
    "    try:\n",
    "        if src.is_dir():\n",
    "            _safe_copytree(src, dst)\n",
    "            return\n",
    "        if prefer_symlink:\n",
    "            _safe_symlink(src, dst)\n",
    "            return\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(src, dst)\n",
    "    except Exception:\n",
    "        try:\n",
    "            dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(src, dst)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def infer_class_names_from_labels(label_root: Path, max_files: int = 2000) -> List[str]:\n",
    "    if label_root is None or not label_root.exists():\n",
    "        return [\"class_0\"]\n",
    "    txts = list(label_root.rglob(\"*.txt\"))\n",
    "    if not txts:\n",
    "        return [\"class_0\"]\n",
    "\n",
    "    txts = txts[:max_files]\n",
    "    cls_ids = set()\n",
    "    for t in txts:\n",
    "        try:\n",
    "            with open(t, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) < 5:\n",
    "                        continue\n",
    "                    cid = int(float(parts[0]))\n",
    "                    cls_ids.add(cid)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not cls_ids:\n",
    "        return [\"class_0\"]\n",
    "    max_id = max(cls_ids)\n",
    "    return [f\"class_{i}\" for i in range(max_id + 1)]\n",
    "\n",
    "def choose_model(ckpt_candidates: List[str]) -> YOLO:\n",
    "    last_err = None\n",
    "    for ckpt in ckpt_candidates:\n",
    "        try:\n",
    "            return YOLO(ckpt)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"Failed to load model weights: {ckpt_candidates}\") from last_err\n",
    "\n",
    "def extract_metrics_dict(val_result) -> Dict:\n",
    "    if val_result is None:\n",
    "        return {}\n",
    "    if hasattr(val_result, \"results_dict\") and isinstance(val_result.results_dict, dict):\n",
    "        return dict(val_result.results_dict)\n",
    "    try:\n",
    "        d = dict(val_result.__dict__)\n",
    "        d.pop(\"plots\", None)\n",
    "        d.pop(\"speed\", None)\n",
    "        return d\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ Label rewrite utility for object-only mode\n",
    "# -------------------------------------------------------------------------\n",
    "def rewrite_label_file_to_object_only(src: Path, dst: Path):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if not src.exists():\n",
    "        try:\n",
    "            dst.write_text(\"\", encoding=\"utf-8\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        lines_out = []\n",
    "        with open(src, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 5:\n",
    "                    continue\n",
    "                parts[0] = \"0\"\n",
    "                lines_out.append(\" \".join(parts))\n",
    "        with open(dst, \"w\", encoding=\"utf-8\") as f:\n",
    "            for ln in lines_out:\n",
    "                f.write(ln + \"\\n\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            dst.write_text(\"\", encoding=\"utf-8\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ Corrupt Image Cleaner\n",
    "# -------------------------------------------------------------------------\n",
    "def scan_and_clean_images(dir_path: Path):\n",
    "    if not dir_path.exists():\n",
    "        return\n",
    "\n",
    "    images = list_images(dir_path)\n",
    "    if not images:\n",
    "        return\n",
    "\n",
    "    print(f\"   üîç Scanning integrity of {len(images)} images in {dir_path.name}...\")\n",
    "    corrupt_count = 0\n",
    "    for img_path in tqdm(images, desc=\"Checking\", leave=False):\n",
    "        is_corrupt = False\n",
    "\n",
    "        try:\n",
    "            with Image.open(img_path) as im:\n",
    "                im.verify()\n",
    "        except Exception:\n",
    "            is_corrupt = True\n",
    "\n",
    "        if not is_corrupt:\n",
    "            try:\n",
    "                img = cv2.imread(str(img_path))\n",
    "                if img is None:\n",
    "                    is_corrupt = True\n",
    "                else:\n",
    "                    _ = img.shape\n",
    "            except Exception:\n",
    "                is_corrupt = True\n",
    "\n",
    "        if is_corrupt:\n",
    "            corrupt_count += 1\n",
    "            dest = CORRUPT_BACKUP_DIR / dir_path.name / img_path.name\n",
    "            dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            label_path = img_path.parent.parent / \"labels\" / img_path.parent.name / img_path.with_suffix(\".txt\").name\n",
    "            if not label_path.exists():\n",
    "                label_path = img_path.with_suffix(\".txt\")\n",
    "\n",
    "            try:\n",
    "                shutil.move(str(img_path), str(dest))\n",
    "                if label_path.exists():\n",
    "                    shutil.move(str(label_path), str(dest.with_suffix(\".txt\")))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    if corrupt_count > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  Moved {corrupt_count} corrupt images to {CORRUPT_BACKUP_DIR}\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ  No corrupt images found.\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Split/Case helpers\n",
    "# -------------------------------------------------------------------------\n",
    "def normalize_name(name: str) -> str:\n",
    "    return name.strip().lower().replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "_ds_map: Dict[str, Dict] = {}\n",
    "try:\n",
    "    for info in dataset_summaries:\n",
    "        key = normalize_name(info.get(\"dataset\", \"\"))\n",
    "        if key:\n",
    "            _ds_map[key] = info\n",
    "except Exception:\n",
    "    _ds_map = {}\n",
    "\n",
    "def get_split_info(ds_root: Path) -> Dict[str, Optional[Path]]:\n",
    "    key = normalize_name(ds_root.name)\n",
    "    if key in _ds_map:\n",
    "        info = _ds_map[key]\n",
    "        return dict(\n",
    "            train_img_dir=Path(info[\"train_dir\"]) if info.get(\"train_dir\") else None,\n",
    "            val_img_dir=Path(info[\"val_dir\"]) if info.get(\"val_dir\") else None,\n",
    "            split_mode=info.get(\"split_mode\", \"fallback\"),\n",
    "            train_tag=info.get(\"train_tag\", \"train\"),\n",
    "            val_tag=info.get(\"val_tag\", \"val\"),\n",
    "        )\n",
    "\n",
    "    images_root = ds_root / \"images\"\n",
    "    tr = images_root / \"train\" if (images_root / \"train\").is_dir() else images_root\n",
    "    va = images_root / \"val\" if (images_root / \"val\").is_dir() else (images_root / \"valid\" if (images_root / \"valid\").is_dir() else None)\n",
    "    return dict(\n",
    "        train_img_dir=tr,\n",
    "        val_img_dir=va,\n",
    "        split_mode=\"fallback\",\n",
    "        train_tag=tr.name if tr else \"unknown\",\n",
    "        val_tag=va.name if va else \"missing\",\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ‚úÖ NEW: label case listing (flags reflected)\n",
    "# -------------------------------------------------------------------------\n",
    "def list_label_cases_for_dataset(ds_root: Path) -> List[Tuple[str, str]]:\n",
    "    key = normalize_name(ds_root.name)\n",
    "    existing = None\n",
    "    if key in _ds_map and isinstance(_ds_map[key].get(\"label_cases\"), list):\n",
    "        existing = set(_ds_map[key][\"label_cases\"])\n",
    "\n",
    "    cases: List[Tuple[str, str]] = []\n",
    "\n",
    "    # (1) original\n",
    "    if TRAIN_USE_ORIGINAL:\n",
    "        if (ds_root / \"labels\").is_dir() and (existing is None or \"original\" in existing):\n",
    "            cases.append((\"original\", \"labels\"))\n",
    "\n",
    "    # (2) uniform scaling noise\n",
    "    if TRAIN_USE_UNIFORM_SCALING_NOISE:\n",
    "        for s in UNIFORM_SCALING_FACTORS:\n",
    "            tag = f\"scale_{s}\"\n",
    "            dirname = f\"labels_uniform_scaling_{s}\"\n",
    "            if (ds_root / dirname).is_dir() and (existing is None or tag in existing):\n",
    "                cases.append((tag, dirname))\n",
    "\n",
    "    # (3) boundary jitter noise\n",
    "    if TRAIN_USE_BOUNDARY_JITTER_NOISE:\n",
    "        for k in JITTER_PATTERNS:\n",
    "            tag = f\"side_{k}\"\n",
    "            dirname = f\"labels_boundary_jitter_{k}\"\n",
    "            if (ds_root / dirname).is_dir() and (existing is None or tag in existing):\n",
    "                cases.append((tag, dirname))\n",
    "\n",
    "    return cases\n",
    "\n",
    "def resolve_label_base(label_root: Path, split_tag: str, is_train: bool) -> Path:\n",
    "    if label_root is None:\n",
    "        return label_root\n",
    "    tagged = label_root / split_tag\n",
    "    if split_tag and tagged.is_dir():\n",
    "        return tagged\n",
    "    if is_train:\n",
    "        tdir = label_root / \"train\"\n",
    "        if tdir.is_dir():\n",
    "            return tdir\n",
    "        return label_root\n",
    "    else:\n",
    "        vdir = label_root / \"val\"\n",
    "        if vdir.is_dir():\n",
    "            return vdir\n",
    "        vdir2 = label_root / \"valid\"\n",
    "        if vdir2.is_dir():\n",
    "            return vdir2\n",
    "        return label_root\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# SKU virtual split & Runtime View (unchanged)\n",
    "# -------------------------------------------------------------------------\n",
    "def sku_virtual_split_images(images_root: Path, seed: int = 42, ratio: float = 0.8) -> Tuple[List[Path], List[Path]]:\n",
    "    imgs = list_images(images_root)\n",
    "    n = len(imgs)\n",
    "    if n == 0:\n",
    "        return [], []\n",
    "    rnd = random.Random(seed)\n",
    "    idxs = list(range(n))\n",
    "    rnd.shuffle(idxs)\n",
    "    cut = int(n * ratio)\n",
    "    train_imgs = [imgs[i] for i in idxs[:cut]]\n",
    "    val_imgs   = [imgs[i] for i in idxs[cut:]]\n",
    "    return train_imgs, val_imgs\n",
    "\n",
    "def sample_train_images(base_train_imgs: List[Path], fraction: float, seed: int) -> Tuple[List[Path], int]:\n",
    "    n_total = len(base_train_imgs)\n",
    "    if n_total == 0:\n",
    "        return [], 0\n",
    "    if fraction >= 1.0:\n",
    "        return base_train_imgs, n_total\n",
    "    n_pick = int(n_total * fraction)\n",
    "    n_pick = max(TRAIN_MIN_IMAGES, n_pick)\n",
    "    n_pick = min(n_pick, n_total)\n",
    "    rnd = random.Random(seed)\n",
    "    chosen = rnd.sample(base_train_imgs, k=n_pick)\n",
    "    return chosen, n_total\n",
    "\n",
    "def build_runtime_view_root(\n",
    "    ds_root: Path,\n",
    "    case_labels_dirname: str,\n",
    "    train_fraction: float,\n",
    "    seed: int,\n",
    "    class_mode: str = \"multiclass\",\n",
    ") -> Tuple[Path, Path, int, int, str]:\n",
    "\n",
    "    assert class_mode in (\"multiclass\", \"object_only\")\n",
    "    images_root     = ds_root / \"images\"\n",
    "    orig_label_root = ds_root / \"labels\"\n",
    "    case_label_root = ds_root / case_labels_dirname\n",
    "\n",
    "    split_info = get_split_info(ds_root)\n",
    "    train_img_dir = split_info[\"train_img_dir\"]\n",
    "    val_img_dir   = split_info[\"val_img_dir\"]\n",
    "    split_mode    = split_info[\"split_mode\"]\n",
    "    train_tag     = split_info.get(\"train_tag\", \"train\")\n",
    "    val_tag       = split_info.get(\"val_tag\", \"val\")\n",
    "\n",
    "    vroot    = RUNTIME_VROOT_BASE / ds_root.name / f\"case__{case_labels_dirname}__{class_mode}\"\n",
    "    v_images = vroot / \"images\"\n",
    "    v_labels = vroot / \"labels\"\n",
    "\n",
    "    if vroot.exists():\n",
    "        try:\n",
    "            shutil.rmtree(vroot)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    (v_images / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "    (v_images / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "    (v_labels / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "    (v_labels / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # A) SKU virtual split\n",
    "    if split_mode == \"sku_virtual_8_2\":\n",
    "        base_train_imgs, base_val_imgs = sku_virtual_split_images(images_root, seed=seed, ratio=0.8)\n",
    "        chosen_train_imgs, n_total_train = sample_train_images(base_train_imgs, train_fraction, seed)\n",
    "\n",
    "        for img in chosen_train_imgs:\n",
    "            rel = img.relative_to(images_root)\n",
    "            dst = v_images / \"train\" / rel\n",
    "            try:\n",
    "                _safe_symlink(img, dst)\n",
    "            except Exception:\n",
    "                _link_or_copy(img, dst, prefer_symlink=False)\n",
    "\n",
    "        for img in base_val_imgs:\n",
    "            rel = img.relative_to(images_root)\n",
    "            dst = v_images / \"val\" / rel\n",
    "            try:\n",
    "                _safe_symlink(img, dst)\n",
    "            except Exception:\n",
    "                _link_or_copy(img, dst, prefer_symlink=False)\n",
    "\n",
    "        for img in chosen_train_imgs:\n",
    "            rel = img.relative_to(images_root)\n",
    "            src_lbl = case_label_root / rel.with_suffix(\".txt\")\n",
    "            dst_lbl = v_labels / \"train\" / rel.with_suffix(\".txt\")\n",
    "            if class_mode == \"multiclass\":\n",
    "                dst_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
    "                if src_lbl.exists():\n",
    "                    try:\n",
    "                        _safe_symlink(src_lbl, dst_lbl)\n",
    "                    except Exception:\n",
    "                        _link_or_copy(src_lbl, dst_lbl, prefer_symlink=False)\n",
    "                else:\n",
    "                    try:\n",
    "                        dst_lbl.write_text(\"\", encoding=\"utf-8\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            else:\n",
    "                rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "        for img in base_val_imgs:\n",
    "            rel = img.relative_to(images_root)\n",
    "            src_lbl = orig_label_root / rel.with_suffix(\".txt\")\n",
    "            dst_lbl = v_labels / \"val\" / rel.with_suffix(\".txt\")\n",
    "            if class_mode == \"multiclass\":\n",
    "                dst_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
    "                if src_lbl.exists():\n",
    "                    try:\n",
    "                        _safe_symlink(src_lbl, dst_lbl)\n",
    "                    except Exception:\n",
    "                        _link_or_copy(src_lbl, dst_lbl, prefer_symlink=False)\n",
    "                else:\n",
    "                    try:\n",
    "                        dst_lbl.write_text(\"\", encoding=\"utf-8\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            else:\n",
    "                rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "        if class_mode == \"multiclass\":\n",
    "            names = infer_class_names_from_labels(orig_label_root)\n",
    "            nc = len(names)\n",
    "        else:\n",
    "            names = [\"object\"]\n",
    "            nc = 1\n",
    "\n",
    "        data_yaml = vroot / \"data.yaml\"\n",
    "        with open(data_yaml, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\n",
    "                f\"path: {str(vroot)}\\n\"\n",
    "                f\"train: images/train\\n\"\n",
    "                f\"val: images/val\\n\"\n",
    "                f\"nc: {nc}\\n\"\n",
    "                f\"names: {names}\\n\"\n",
    "            )\n",
    "\n",
    "        rt_n_train = len(list_images(v_images / \"train\"))\n",
    "        if rt_n_train == 0:\n",
    "            raise RuntimeError(f\"Runtime train images empty (SKU mode): {v_images/'train'}\")\n",
    "\n",
    "        return vroot, data_yaml, len(chosen_train_imgs), len(base_train_imgs), split_mode\n",
    "\n",
    "    # B) Standard split\n",
    "    if train_img_dir is None or not Path(train_img_dir).is_dir():\n",
    "        raise RuntimeError(f\"No train images dir resolved for {ds_root.name}\")\n",
    "    if val_img_dir is None or not Path(val_img_dir).is_dir():\n",
    "        raise RuntimeError(f\"No val images dir resolved for {ds_root.name}\")\n",
    "\n",
    "    all_train_imgs = list_images(train_img_dir)\n",
    "    chosen_train_imgs, n_total_train = sample_train_images(all_train_imgs, train_fraction, seed)\n",
    "    if n_total_train == 0 or len(chosen_train_imgs) == 0:\n",
    "        raise RuntimeError(f\"No train images for {ds_root.name}\")\n",
    "\n",
    "    for img in chosen_train_imgs:\n",
    "        rel = img.relative_to(train_img_dir)\n",
    "        dst = v_images / \"train\" / rel\n",
    "        try:\n",
    "            _safe_symlink(img, dst)\n",
    "        except Exception:\n",
    "            _link_or_copy(img, dst, prefer_symlink=False)\n",
    "\n",
    "    _safe_copytree(Path(val_img_dir), v_images / \"val\")\n",
    "\n",
    "    case_train_lbl_base = resolve_label_base(case_label_root, train_tag, is_train=True)\n",
    "    for img in chosen_train_imgs:\n",
    "        rel = img.relative_to(train_img_dir)\n",
    "        src_lbl = case_train_lbl_base / rel.with_suffix(\".txt\")\n",
    "        dst_lbl = v_labels / \"train\" / rel.with_suffix(\".txt\")\n",
    "        if class_mode == \"multiclass\":\n",
    "            dst_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
    "            if src_lbl.exists():\n",
    "                try:\n",
    "                    _safe_symlink(src_lbl, dst_lbl)\n",
    "                except Exception:\n",
    "                    _link_or_copy(src_lbl, dst_lbl, prefer_symlink=False)\n",
    "            else:\n",
    "                try:\n",
    "                    dst_lbl.write_text(\"\", encoding=\"utf-8\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "        else:\n",
    "            rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "    orig_val_lbl_base = resolve_label_base(orig_label_root, val_tag, is_train=False)\n",
    "    if class_mode == \"multiclass\":\n",
    "        _safe_copytree(orig_val_lbl_base, v_labels / \"val\")\n",
    "    else:\n",
    "        for src_lbl in orig_val_lbl_base.rglob(\"*.txt\"):\n",
    "            rel = src_lbl.relative_to(orig_val_lbl_base)\n",
    "            dst_lbl = v_labels / \"val\" / rel\n",
    "            rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "    if class_mode == \"multiclass\":\n",
    "        names = infer_class_names_from_labels(orig_label_root)\n",
    "        nc = len(names)\n",
    "    else:\n",
    "        names = [\"object\"]\n",
    "        nc = 1\n",
    "\n",
    "    data_yaml = vroot / \"data.yaml\"\n",
    "    with open(data_yaml, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\n",
    "            f\"path: {str(vroot)}\\n\"\n",
    "            f\"train: images/train\\n\"\n",
    "            f\"val: images/val\\n\"\n",
    "            f\"nc: {nc}\\n\"\n",
    "            f\"names: {names}\\n\"\n",
    "        )\n",
    "\n",
    "    rt_n_train = len(list_images(v_images / \"train\"))\n",
    "    rt_n_val   = len(list_images(v_images / \"val\"))\n",
    "    if rt_n_train == 0:\n",
    "        raise RuntimeError(f\"Runtime train images empty: {v_images/'train'}\")\n",
    "    if rt_n_val == 0:\n",
    "        raise RuntimeError(f\"Runtime val images empty: {v_images/'val'}\")\n",
    "\n",
    "    return vroot, data_yaml, len(chosen_train_imgs), n_total_train, split_mode\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# OOM-safe train wrapper\n",
    "# -------------------------------------------------------------------------\n",
    "def train_with_auto_oom(model: YOLO, data_yaml: Path, project_dir: Path, name_dir: str, model_tag: str):\n",
    "    if model_tag == \"detr\":\n",
    "        candidates = [(4, 640), (2, 640), (2, 512), (1, 512)]\n",
    "    else:\n",
    "        candidates = [(BATCH, IMG_SIZE)]\n",
    "\n",
    "    last_err = None\n",
    "    for b, sz in candidates:\n",
    "        try:\n",
    "            with suppress_output(SILENCE_ULTRA_OUTPUT):\n",
    "                model.train(\n",
    "                    data=str(data_yaml),\n",
    "                    epochs=EPOCHS,\n",
    "                    imgsz=sz,\n",
    "                    batch=b,\n",
    "                    device=DEVICE,\n",
    "                    project=str(project_dir),\n",
    "                    name=name_dir,\n",
    "                    exist_ok=True,\n",
    "                    verbose=False,\n",
    "                    workers=NUM_WORKERS,\n",
    "                    amp=True,\n",
    "                )\n",
    "            return True, b, sz, None\n",
    "        except RuntimeError as e:\n",
    "            msg = str(e).lower()\n",
    "            last_err = e\n",
    "            if \"out of memory\" in msg or \"cuda out of memory\" in msg:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.ipc_collect()\n",
    "                continue\n",
    "            break\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            break\n",
    "    return False, None, None, last_err\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Train & validate loop\n",
    "# -------------------------------------------------------------------------\n",
    "set_seed(SEED)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"[TRAIN/EVAL] Start (Cell 1 summaries-aware + runtime path safe + object-only)\")\n",
    "print(f\" - OUT_ROOT             : {OUT_ROOT}\")\n",
    "print(f\" - RUNTIME_VROOT_BASE   : {RUNTIME_VROOT_BASE}\")\n",
    "print(f\" - TRAIN_FRACTION       : {TRAIN_FRACTION}\")\n",
    "print(f\" - NUM_WORKERS          : {NUM_WORKERS}\")\n",
    "print(f\" - CLASS_MODES          : {CLASS_MODES}\")\n",
    "print(f\" - CLEANUP_RUNTIME_VROOT: {CLEANUP_RUNTIME_VROOT}\")\n",
    "print(f\" - TRAIN_USE_ORIGINAL   : {TRAIN_USE_ORIGINAL}\")\n",
    "print(f\" - TRAIN_USE_UNIFORM_SCALING_NOISE: {TRAIN_USE_UNIFORM_SCALING_NOISE}\")\n",
    "print(f\" - TRAIN_USE_BOUNDARY_JITTER_NOISE : {TRAIN_USE_BOUNDARY_JITTER_NOISE}\")\n",
    "if TARGET_DATASETS_LOWER is None:\n",
    "    print(f\" - TARGET_DATASETS      : ALL (no filter)\")\n",
    "else:\n",
    "    print(f\" - TARGET_DATASETS      : {sorted(TARGET_DATASETS_LOWER)}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary_rows: List[Dict] = []\n",
    "\n",
    "try:\n",
    "    _ = roots\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Please run Cell 1 first to prepare the roots variable.\")\n",
    "\n",
    "for ds_root in roots:\n",
    "    ds_root = Path(ds_root)\n",
    "\n",
    "    if TARGET_DATASETS_LOWER is not None:\n",
    "        ds_name_lower = ds_root.name.strip().lower()\n",
    "        if ds_name_lower not in TARGET_DATASETS_LOWER:\n",
    "            print(f\"‚è≠Ô∏è  Skip (not in TARGET_DATASETS): {ds_root.name}\")\n",
    "            continue\n",
    "\n",
    "    images_root = ds_root / \"images\"\n",
    "    labels_root = ds_root / \"labels\"\n",
    "\n",
    "    if not images_root.is_dir() or not labels_root.is_dir():\n",
    "        print(f\"‚è≠Ô∏è  Skip (missing images/labels): {ds_root}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n[Integrity Check] {ds_root.name}\")\n",
    "    scan_and_clean_images(images_root)\n",
    "\n",
    "    cases = list_label_cases_for_dataset(ds_root)\n",
    "    if not cases:\n",
    "        print(f\"‚è≠Ô∏è  Skip (no target label cases after flags/grid filter): {ds_root.name}\")\n",
    "        continue\n",
    "\n",
    "    sp = get_split_info(ds_root)\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(f\"[Dataset] {ds_root.name}\")\n",
    "    print(f\" - split_mode : {sp.get('split_mode')}\")\n",
    "    print(f\" - Cases      : {[c[0] for c in cases]}\")\n",
    "    print(f\" - CLASS_MODES: {CLASS_MODES}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for case_tag, labels_dirname in cases:\n",
    "        for class_mode in CLASS_MODES:\n",
    "            try:\n",
    "                vroot, data_yaml, n_used, n_total, split_mode = build_runtime_view_root(\n",
    "                    ds_root=ds_root,\n",
    "                    case_labels_dirname=labels_dirname,\n",
    "                    train_fraction=TRAIN_FRACTION,\n",
    "                    seed=SEED,\n",
    "                    class_mode=class_mode,\n",
    "                )\n",
    "                pct = (n_used / max(1, n_total)) * 100.0\n",
    "                print(f\"  [Subset] case={case_tag} | class_mode={class_mode} | split_mode={split_mode} | train_used={n_used}/{n_total} ({pct:.1f}%)\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚è≠Ô∏è  Skip build failed: case={case_tag} | class_mode={class_mode} | err={e}\")\n",
    "                continue\n",
    "\n",
    "            for model_tag, ckpt_candidates in MODEL_SPECS:\n",
    "                print(f\"\\n  [Train] case={case_tag} | class_mode={class_mode} | model={model_tag}\")\n",
    "\n",
    "                try:\n",
    "                    model = choose_model(ckpt_candidates)\n",
    "                except Exception as e:\n",
    "                    print(f\"    ‚ùå Model load failed: {ckpt_candidates} | err={e}\")\n",
    "                    continue\n",
    "\n",
    "                project_dir = OUT_ROOT / ds_root.name\n",
    "                frac_tag = f\"tr{int(TRAIN_FRACTION*100)}\"\n",
    "                name_dir = f\"{model_tag}__{case_tag}__{class_mode}__{frac_tag}\"\n",
    "                project_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                ok, used_b, used_sz, err = train_with_auto_oom(model, data_yaml, project_dir, name_dir, model_tag)\n",
    "                if not ok:\n",
    "                    print(f\"    ‚ùå Train failed: {err}\")\n",
    "                    try:\n",
    "                        del model\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                        torch.cuda.ipc_collect()\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    with suppress_output(SILENCE_ULTRA_OUTPUT):\n",
    "                        val_res = model.val(\n",
    "                            data=str(data_yaml),\n",
    "                            imgsz=used_sz if used_sz else IMG_SIZE,\n",
    "                            device=DEVICE,\n",
    "                            split=\"val\",\n",
    "                            verbose=False,\n",
    "                            workers=NUM_WORKERS,\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    print(f\"    ‚ùå Val failed: {e}\")\n",
    "                    val_res = None\n",
    "\n",
    "                metrics = extract_metrics_dict(val_res)\n",
    "\n",
    "                metrics_out = project_dir / name_dir / \"metrics_eval.json\"\n",
    "                try:\n",
    "                    metrics_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    with open(metrics_out, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(\n",
    "                            {\n",
    "                                \"dataset\": ds_root.name,\n",
    "                                \"root\": str(ds_root),\n",
    "                                \"case_tag\": case_tag,\n",
    "                                \"labels_dirname\": labels_dirname,\n",
    "                                \"class_mode\": class_mode,\n",
    "                                \"model_tag\": model_tag,\n",
    "                                \"ckpt_candidates\": ckpt_candidates,\n",
    "                                \"train_fraction\": TRAIN_FRACTION,\n",
    "                                \"train_used\": n_used,\n",
    "                                \"train_total\": n_total,\n",
    "                                \"data_yaml\": str(data_yaml),\n",
    "                                \"runtime_view_root\": str(vroot),\n",
    "                                \"split_mode\": split_mode,\n",
    "                                \"effective_batch\": used_b,\n",
    "                                \"effective_imgsz\": used_sz,\n",
    "                                \"metrics\": metrics,\n",
    "                            },\n",
    "                            f,\n",
    "                            ensure_ascii=False,\n",
    "                            indent=2,\n",
    "                        )\n",
    "                    print(f\"    ‚úÖ Saved metrics: {metrics_out}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                row = {\n",
    "                    \"dataset\": ds_root.name,\n",
    "                    \"model\": model_tag,\n",
    "                    \"case\": case_tag,\n",
    "                    \"labels_dir\": labels_dirname,\n",
    "                    \"class_mode\": class_mode,\n",
    "                    \"split_mode\": split_mode,\n",
    "                    \"train_fraction\": TRAIN_FRACTION,\n",
    "                    \"train_used\": n_used,\n",
    "                    \"train_total\": n_total,\n",
    "                    \"effective_batch\": used_b,\n",
    "                    \"effective_imgsz\": used_sz,\n",
    "                }\n",
    "                for k in [\"metrics/mAP50(B)\", \"metrics/mAP50-95(B)\", \"metrics/precision(B)\", \"metrics/recall(B)\"]:\n",
    "                    if k in metrics:\n",
    "                        row[k] = metrics[k]\n",
    "\n",
    "                summary_rows.append(row)\n",
    "\n",
    "                try:\n",
    "                    del model\n",
    "                except Exception:\n",
    "                    pass\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.ipc_collect()\n",
    "\n",
    "            if CLEANUP_RUNTIME_VROOT:\n",
    "                try:\n",
    "                    shutil.rmtree(vroot)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Save summary CSV\n",
    "# -------------------------------------------------------------------------\n",
    "out_csv = OUT_ROOT / \"summary_final_optimized.csv\"\n",
    "try:\n",
    "    cols = set()\n",
    "    for r in summary_rows:\n",
    "        cols.update(r.keys())\n",
    "\n",
    "    base_cols = [\n",
    "        \"dataset\", \"model\", \"case\", \"labels_dir\",\n",
    "        \"class_mode\",\n",
    "        \"split_mode\",\n",
    "        \"train_fraction\", \"train_used\", \"train_total\",\n",
    "        \"effective_batch\", \"effective_imgsz\",\n",
    "    ]\n",
    "    extra_cols = sorted([c for c in cols if c not in set(base_cols)])\n",
    "    cols = base_cols + extra_cols\n",
    "\n",
    "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=cols)\n",
    "        w.writeheader()\n",
    "        for r in summary_rows:\n",
    "            w.writerow(r)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"‚úÖ Saved summary CSV: {out_csv}\")\n",
    "    print(f\"‚úÖ Total runs: {len(summary_rows)}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Summary CSV save failed: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 2 done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e6bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[TRAIN/EVAL] Start (Cell 1 summaries-aware + runtime path safe + object-only)\n",
      " - OUT_ROOT             : /home/ISW/project/object_detect\n",
      " - RUNTIME_VROOT_BASE   : /home/ISW/project/_runtime_dataset_views\n",
      " - TRAIN_FRACTION       : 1.0\n",
      " - NUM_WORKERS          : 8\n",
      " - CLASS_MODES          : ['object_only']\n",
      " - CLEANUP_RUNTIME_VROOT: True\n",
      " - TRAIN_USE_ORIGINAL   : True\n",
      " - TRAIN_USE_UNIFORM_SCALING_NOISE: False\n",
      " - TRAIN_USE_BOUNDARY_JITTER_NOISE : False\n",
      " - TARGET_DATASETS      : ['voc']\n",
      "================================================================================\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): SKU-110K\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): kitti\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): homeobjects-3K\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): african-wildlife\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): construction-ppe\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): Custom_Blood\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): brain-tumor\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): BCCD\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): signature\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): medical-pills\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): coco\n",
      "‚è≠Ô∏è  Skip (not in TARGET_DATASETS): lvis\n",
      "\n",
      "[Integrity Check] VOC\n",
      "   üîç Scanning integrity of 34178 images in images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ  No corrupt images found.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[Dataset] VOC\n",
      " - split_mode : explicit\n",
      " - Cases      : ['original']\n",
      " - CLASS_MODES: ['object_only']\n",
      "--------------------------------------------------------------------------------\n",
      "  [Subset] case=original | class_mode=object_only | split_mode=explicit | train_used=5717/5717 (100.0%)\n",
      "\n",
      "  [Train] case=original | class_mode=object_only | model=yolov8n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolov8n__original__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=original | class_mode=object_only | model=yolo11n\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/yolo11n__original__object_only__tr100/metrics_eval.json\n",
      "\n",
      "  [Train] case=original | class_mode=object_only | model=detr\n",
      "    ‚úÖ Saved metrics: /home/ISW/project/object_detect/VOC/detr__original__object_only__tr100/metrics_eval.json\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Saved summary CSV: /home/ISW/project/object_detect/summary_final_optimized_VOC_only.csv\n",
      "‚úÖ Total runs: 3\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Cell 2 done.\n"
     ]
    }
   ],
   "source": [
    "# # ==========================================\n",
    "# # Cell 2) Train & Validate (FAST & ROBUST) ‚Äî FINAL OPTIMIZED + OBJECT-ONLY\n",
    "# #   - Supports both multi-class and object-only modes\n",
    "# #   - Select only required modes from CLASS_MODES\n",
    "# #   - Select datasets to use via TARGET_DATASETS\n",
    "# #   - ‚úÖ NEW: Control training with original / uniform_scaling_noise / boundary_jitter_noise flags\n",
    "# # ==========================================\n",
    "\n",
    "# from __future__ import annotations\n",
    "\n",
    "# import os, json, shutil, random, csv, sys, time\n",
    "# from pathlib import Path\n",
    "# from typing import List, Dict, Tuple, Optional\n",
    "# from contextlib import contextmanager\n",
    "\n",
    "# # ‚úÖ Libraries for image integrity check\n",
    "# try:\n",
    "#     import cv2\n",
    "#     from PIL import Image\n",
    "#     from tqdm import tqdm\n",
    "# except ImportError:\n",
    "#     print(\"‚ö†Ô∏è Required libraries are missing. Please install: pip install opencv-python pillow tqdm\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "# # ‚úÖ OOM fragmentation mitigation\n",
    "# os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
    "\n",
    "# import torch\n",
    "# from ultralytics import YOLO\n",
    "# import logging\n",
    "# logging.getLogger(\"ultralytics\").setLevel(logging.ERROR)\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # ‚úÖ FIXED grids (Speed Optimized)\n",
    "# #   Note: These values are \"candidate labels_* folders for training\".\n",
    "# #           Must match actual generated labels_boundary_jitter_K / labels_uniform_scaling_S folder names for cases to be detected.\n",
    "# # -------------------------------------------------------------------------\n",
    "# UNIFORM_SCALING_FACTORS = [0.6, 0.7, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
    "# JITTER_PATTERNS = [1, 3, 5, 7, 9]\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # ‚úÖ NEW: Train-case control flags\n",
    "# #   - Can control inclusion/exclusion of noise label folders in training\n",
    "# # -------------------------------------------------------------------------\n",
    "# TRAIN_USE_ORIGINAL    = True\n",
    "# TRAIN_USE_UNIFORM_SCALING_NOISE = False\n",
    "# TRAIN_USE_BOUNDARY_JITTER_NOISE  = False\n",
    "# # e.g.) Original only: TRAIN_USE_ORIGINAL=True, TRAIN_USE_UNIFORM_SCALING_NOISE=False, TRAIN_USE_BOUNDARY_JITTER_NOISE=False\n",
    "# # e.g.) Side only: TRAIN_USE_ORIGINAL=False, TRAIN_USE_UNIFORM_SCALING_NOISE=False, TRAIN_USE_BOUNDARY_JITTER_NOISE=True\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # ‚úÖ Speed control\n",
    "# # -------------------------------------------------------------------------\n",
    "# TRAIN_FRACTION = 1.0\n",
    "# TRAIN_MIN_IMAGES = 50\n",
    "# NUM_WORKERS = min(8, os.cpu_count() or 4)\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # User config\n",
    "# # -------------------------------------------------------------------------\n",
    "# IMG_SIZE = 640\n",
    "# EPOCHS = 10\n",
    "# BATCH = 32\n",
    "# DEVICE = \"0\"\n",
    "# SEED = 42\n",
    "\n",
    "# OUT_ROOT = Path(\"/home/ISW/project/object_detect\")\n",
    "# OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# RUNTIME_VROOT_BASE = Path(\"/home/ISW/project/_runtime_dataset_views\")\n",
    "# RUNTIME_VROOT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CORRUPT_BACKUP_DIR = Path(\"/home/ISW/project/_corrupt_files_backup\")\n",
    "# CORRUPT_BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CLEANUP_RUNTIME_VROOT = True\n",
    "# SILENCE_ULTRA_OUTPUT = True\n",
    "\n",
    "# # ‚úÖ Select which class modes to run\n",
    "# CLASS_MODES = [\"object_only\"]\n",
    "\n",
    "# # ‚úÖ Select datasets to use (by folder name, case-insensitive)\n",
    "# TARGET_DATASETS: Optional[List[str]] = [\n",
    "#     # \"SKU-110K\",\n",
    "#     # \"kitti\",\n",
    "#     # \"homeobjects-3K\",\n",
    "#     # \"african-wildlife\",\n",
    "#     # \"construction-ppe\",\n",
    "#     # \"Custom_Blood\",\n",
    "#     # \"brain-tumor\",\n",
    "#     # \"BCCD\",\n",
    "#     # \"signature\",\n",
    "#     # \"medical-pills\",\n",
    "#     # \"coco\",\n",
    "#     # \"lvis\",\n",
    "#     \"VOC\",\n",
    "# ]\n",
    "# TARGET_DATASETS_LOWER = (\n",
    "#     {name.strip().lower() for name in TARGET_DATASETS}\n",
    "#     if TARGET_DATASETS is not None\n",
    "#     else None\n",
    "# )\n",
    "\n",
    "# @contextmanager\n",
    "# def suppress_output(enabled: bool = True):\n",
    "#     if not enabled:\n",
    "#         yield\n",
    "#         return\n",
    "#     devnull = open(os.devnull, \"w\")\n",
    "#     old_out, old_err = sys.stdout, sys.stderr\n",
    "#     try:\n",
    "#         sys.stdout, sys.stderr = devnull, devnull\n",
    "#         yield\n",
    "#     finally:\n",
    "#         sys.stdout, sys.stderr = old_out, old_err\n",
    "#         devnull.close()\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # Model specs\n",
    "# # -------------------------------------------------------------------------\n",
    "# YOLOV8N_CKPT_CANDIDATES = [\"yolov8n.pt\"]\n",
    "# YOLO11N_CKPT_CANDIDATES = [\"yolo11n.pt\", \"yolov11n.pt\"]\n",
    "# DETR_CKPT_CANDIDATES   = [\"rtdetr-s.pt\", \"rtdetr-l.pt\"]\n",
    "\n",
    "# MODEL_SPECS = [\n",
    "#     (\"yolov8n\", YOLOV8N_CKPT_CANDIDATES),\n",
    "#     (\"yolo11n\", YOLO11N_CKPT_CANDIDATES),\n",
    "#     (\"detr\",    DETR_CKPT_CANDIDATES),\n",
    "# ]\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # Utils\n",
    "# # -------------------------------------------------------------------------\n",
    "# _IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "# def set_seed(seed: int = 42):\n",
    "#     random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# def list_images(dir_path: Optional[Path]) -> List[Path]:\n",
    "#     if dir_path is None or not Path(dir_path).exists():\n",
    "#         return []\n",
    "#     dir_path = Path(dir_path)\n",
    "#     imgs = []\n",
    "#     for p in dir_path.rglob(\"*\"):\n",
    "#         if p.is_file() and p.suffix.lower() in _IMG_EXTS:\n",
    "#             imgs.append(p)\n",
    "#     return sorted(imgs)\n",
    "\n",
    "# def _safe_symlink(src: Path, dst: Path):\n",
    "#     dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "#     if dst.exists() or dst.is_symlink():\n",
    "#         return\n",
    "#     os.symlink(str(src), str(dst))\n",
    "\n",
    "# def _safe_copytree(src: Path, dst: Path):\n",
    "#     if not src.exists():\n",
    "#         return\n",
    "#     dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "#     shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "\n",
    "# def _link_or_copy(src: Path, dst: Path, prefer_symlink: bool = True):\n",
    "#     if not src.exists():\n",
    "#         return\n",
    "#     try:\n",
    "#         if src.is_dir():\n",
    "#             _safe_copytree(src, dst)\n",
    "#             return\n",
    "#         if prefer_symlink:\n",
    "#             _safe_symlink(src, dst)\n",
    "#             return\n",
    "#         dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "#         shutil.copy2(src, dst)\n",
    "#     except Exception:\n",
    "#         try:\n",
    "#             dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "#             shutil.copy2(src, dst)\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "# def infer_class_names_from_labels(label_root: Path, max_files: int = 2000) -> List[str]:\n",
    "#     if label_root is None or not label_root.exists():\n",
    "#         return [\"class_0\"]\n",
    "#     txts = list(label_root.rglob(\"*.txt\"))\n",
    "#     if not txts:\n",
    "#         return [\"class_0\"]\n",
    "\n",
    "#     txts = txts[:max_files]\n",
    "#     cls_ids = set()\n",
    "#     for t in txts:\n",
    "#         try:\n",
    "#             with open(t, \"r\", encoding=\"utf-8\") as f:\n",
    "#                 for line in f:\n",
    "#                     parts = line.strip().split()\n",
    "#                     if len(parts) < 5:\n",
    "#                         continue\n",
    "#                     cid = int(float(parts[0]))\n",
    "#                     cls_ids.add(cid)\n",
    "#         except Exception:\n",
    "#             continue\n",
    "\n",
    "#     if not cls_ids:\n",
    "#         return [\"class_0\"]\n",
    "#     max_id = max(cls_ids)\n",
    "#     return [f\"class_{i}\" for i in range(max_id + 1)]\n",
    "\n",
    "# def choose_model(ckpt_candidates: List[str]) -> YOLO:\n",
    "#     last_err = None\n",
    "#     for ckpt in ckpt_candidates:\n",
    "#         try:\n",
    "#             return YOLO(ckpt)\n",
    "#         except Exception as e:\n",
    "#             last_err = e\n",
    "#     raise RuntimeError(f\"Failed to load model weights: {ckpt_candidates}\") from last_err\n",
    "\n",
    "# def extract_metrics_dict(val_result) -> Dict:\n",
    "#     if val_result is None:\n",
    "#         return {}\n",
    "#     if hasattr(val_result, \"results_dict\") and isinstance(val_result.results_dict, dict):\n",
    "#         return dict(val_result.results_dict)\n",
    "#     try:\n",
    "#         d = dict(val_result.__dict__)\n",
    "#         d.pop(\"plots\", None)\n",
    "#         d.pop(\"speed\", None)\n",
    "#         return d\n",
    "#     except Exception:\n",
    "#         return {}\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # ‚úÖ Label rewrite utility for object-only mode\n",
    "# # -------------------------------------------------------------------------\n",
    "# def rewrite_label_file_to_object_only(src: Path, dst: Path):\n",
    "#     dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "#     if not src.exists():\n",
    "#         try:\n",
    "#             dst.write_text(\"\", encoding=\"utf-8\")\n",
    "#         except Exception:\n",
    "#             pass\n",
    "#         return\n",
    "\n",
    "#     try:\n",
    "#         lines_out = []\n",
    "#         with open(src, \"r\", encoding=\"utf-8\") as f:\n",
    "#             for line in f:\n",
    "#                 parts = line.strip().split()\n",
    "#                 if len(parts) < 5:\n",
    "#                     continue\n",
    "#                 parts[0] = \"0\"\n",
    "#                 lines_out.append(\" \".join(parts))\n",
    "#         with open(dst, \"w\", encoding=\"utf-8\") as f:\n",
    "#             for ln in lines_out:\n",
    "#                 f.write(ln + \"\\n\")\n",
    "#     except Exception:\n",
    "#         try:\n",
    "#             dst.write_text(\"\", encoding=\"utf-8\")\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # ‚úÖ Corrupt Image Cleaner\n",
    "# # -------------------------------------------------------------------------\n",
    "# def scan_and_clean_images(dir_path: Path):\n",
    "#     if not dir_path.exists():\n",
    "#         return\n",
    "\n",
    "#     images = list_images(dir_path)\n",
    "#     if not images:\n",
    "#         return\n",
    "\n",
    "#     print(f\"   üîç Scanning integrity of {len(images)} images in {dir_path.name}...\")\n",
    "#     corrupt_count = 0\n",
    "#     for img_path in tqdm(images, desc=\"Checking\", leave=False):\n",
    "#         is_corrupt = False\n",
    "\n",
    "#         try:\n",
    "#             with Image.open(img_path) as im:\n",
    "#                 im.verify()\n",
    "#         except Exception:\n",
    "#             is_corrupt = True\n",
    "\n",
    "#         if not is_corrupt:\n",
    "#             try:\n",
    "#                 img = cv2.imread(str(img_path))\n",
    "#                 if img is None:\n",
    "#                     is_corrupt = True\n",
    "#                 else:\n",
    "#                     _ = img.shape\n",
    "#             except Exception:\n",
    "#                 is_corrupt = True\n",
    "\n",
    "#         if is_corrupt:\n",
    "#             corrupt_count += 1\n",
    "#             dest = CORRUPT_BACKUP_DIR / dir_path.name / img_path.name\n",
    "#             dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#             label_path = img_path.parent.parent / \"labels\" / img_path.parent.name / img_path.with_suffix(\".txt\").name\n",
    "#             if not label_path.exists():\n",
    "#                 label_path = img_path.with_suffix(\".txt\")\n",
    "\n",
    "#             try:\n",
    "#                 shutil.move(str(img_path), str(dest))\n",
    "#                 if label_path.exists():\n",
    "#                     shutil.move(str(label_path), str(dest.with_suffix(\".txt\")))\n",
    "#             except Exception:\n",
    "#                 pass\n",
    "\n",
    "#     if corrupt_count > 0:\n",
    "#         print(f\"   ‚ö†Ô∏è  Moved {corrupt_count} corrupt images to {CORRUPT_BACKUP_DIR}\")\n",
    "#     else:\n",
    "#         print(f\"   ‚úÖ  No corrupt images found.\")\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # Split/Case helpers\n",
    "# # -------------------------------------------------------------------------\n",
    "# def normalize_name(name: str) -> str:\n",
    "#     return name.strip().lower().replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "# _ds_map: Dict[str, Dict] = {}\n",
    "# try:\n",
    "#     for info in dataset_summaries:\n",
    "#         key = normalize_name(info.get(\"dataset\", \"\"))\n",
    "#         if key:\n",
    "#             _ds_map[key] = info\n",
    "# except Exception:\n",
    "#     _ds_map = {}\n",
    "\n",
    "# def get_split_info(ds_root: Path) -> Dict[str, Optional[Path]]:\n",
    "#     key = normalize_name(ds_root.name)\n",
    "#     if key in _ds_map:\n",
    "#         info = _ds_map[key]\n",
    "#         return dict(\n",
    "#             train_img_dir=Path(info[\"train_dir\"]) if info.get(\"train_dir\") else None,\n",
    "#             val_img_dir=Path(info[\"val_dir\"]) if info.get(\"val_dir\") else None,\n",
    "#             split_mode=info.get(\"split_mode\", \"fallback\"),\n",
    "#             train_tag=info.get(\"train_tag\", \"train\"),\n",
    "#             val_tag=info.get(\"val_tag\", \"val\"),\n",
    "#         )\n",
    "\n",
    "#     images_root = ds_root / \"images\"\n",
    "#     tr = images_root / \"train\" if (images_root / \"train\").is_dir() else images_root\n",
    "#     va = images_root / \"val\" if (images_root / \"val\").is_dir() else (images_root / \"valid\" if (images_root / \"valid\").is_dir() else None)\n",
    "#     return dict(\n",
    "#         train_img_dir=tr,\n",
    "#         val_img_dir=va,\n",
    "#         split_mode=\"fallback\",\n",
    "#         train_tag=tr.name if tr else \"unknown\",\n",
    "#         val_tag=va.name if va else \"missing\",\n",
    "#     )\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # ‚úÖ NEW: label case listing (flags reflected)\n",
    "# # -------------------------------------------------------------------------\n",
    "# def list_label_cases_for_dataset(ds_root: Path) -> List[Tuple[str, str]]:\n",
    "#     key = normalize_name(ds_root.name)\n",
    "#     existing = None\n",
    "#     if key in _ds_map and isinstance(_ds_map[key].get(\"label_cases\"), list):\n",
    "#         existing = set(_ds_map[key][\"label_cases\"])\n",
    "\n",
    "#     cases: List[Tuple[str, str]] = []\n",
    "\n",
    "#     # (1) original\n",
    "#     if TRAIN_USE_ORIGINAL:\n",
    "#         if (ds_root / \"labels\").is_dir() and (existing is None or \"original\" in existing):\n",
    "#             cases.append((\"original\", \"labels\"))\n",
    "\n",
    "#     # (2) uniform scaling noise\n",
    "#     if TRAIN_USE_UNIFORM_SCALING_NOISE:\n",
    "#         for s in UNIFORM_SCALING_FACTORS:\n",
    "#             tag = f\"scale_{s}\"\n",
    "#             dirname = f\"labels_uniform_scaling_{s}\"\n",
    "#             if (ds_root / dirname).is_dir() and (existing is None or tag in existing):\n",
    "#                 cases.append((tag, dirname))\n",
    "\n",
    "#     # (3) boundary jitter noise\n",
    "#     if TRAIN_USE_BOUNDARY_JITTER_NOISE:\n",
    "#         for k in JITTER_PATTERNS:\n",
    "#             tag = f\"side_{k}\"\n",
    "#             dirname = f\"labels_boundary_jitter_{k}\"\n",
    "#             if (ds_root / dirname).is_dir() and (existing is None or tag in existing):\n",
    "#                 cases.append((tag, dirname))\n",
    "\n",
    "#     return cases\n",
    "\n",
    "# def resolve_label_base(label_root: Path, split_tag: str, is_train: bool) -> Path:\n",
    "#     if label_root is None:\n",
    "#         return label_root\n",
    "#     tagged = label_root / split_tag\n",
    "#     if split_tag and tagged.is_dir():\n",
    "#         return tagged\n",
    "#     if is_train:\n",
    "#         tdir = label_root / \"train\"\n",
    "#         if tdir.is_dir():\n",
    "#             return tdir\n",
    "#         return label_root\n",
    "#     else:\n",
    "#         vdir = label_root / \"val\"\n",
    "#         if vdir.is_dir():\n",
    "#             return vdir\n",
    "#         vdir2 = label_root / \"valid\"\n",
    "#         if vdir2.is_dir():\n",
    "#             return vdir2\n",
    "#         return label_root\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # SKU virtual split & Runtime View (unchanged)\n",
    "# # -------------------------------------------------------------------------\n",
    "# def sku_virtual_split_images(images_root: Path, seed: int = 42, ratio: float = 0.8) -> Tuple[List[Path], List[Path]]:\n",
    "#     imgs = list_images(images_root)\n",
    "#     n = len(imgs)\n",
    "#     if n == 0:\n",
    "#         return [], []\n",
    "#     rnd = random.Random(seed)\n",
    "#     idxs = list(range(n))\n",
    "#     rnd.shuffle(idxs)\n",
    "#     cut = int(n * ratio)\n",
    "#     train_imgs = [imgs[i] for i in idxs[:cut]]\n",
    "#     val_imgs   = [imgs[i] for i in idxs[cut:]]\n",
    "#     return train_imgs, val_imgs\n",
    "\n",
    "# def sample_train_images(base_train_imgs: List[Path], fraction: float, seed: int) -> Tuple[List[Path], int]:\n",
    "#     n_total = len(base_train_imgs)\n",
    "#     if n_total == 0:\n",
    "#         return [], 0\n",
    "#     if fraction >= 1.0:\n",
    "#         return base_train_imgs, n_total\n",
    "#     n_pick = int(n_total * fraction)\n",
    "#     n_pick = max(TRAIN_MIN_IMAGES, n_pick)\n",
    "#     n_pick = min(n_pick, n_total)\n",
    "#     rnd = random.Random(seed)\n",
    "#     chosen = rnd.sample(base_train_imgs, k=n_pick)\n",
    "#     return chosen, n_total\n",
    "\n",
    "# def build_runtime_view_root(\n",
    "#     ds_root: Path,\n",
    "#     case_labels_dirname: str,\n",
    "#     train_fraction: float,\n",
    "#     seed: int,\n",
    "#     class_mode: str = \"multiclass\",\n",
    "# ) -> Tuple[Path, Path, int, int, str]:\n",
    "\n",
    "#     assert class_mode in (\"multiclass\", \"object_only\")\n",
    "#     images_root     = ds_root / \"images\"\n",
    "#     orig_label_root = ds_root / \"labels\"\n",
    "#     case_label_root = ds_root / case_labels_dirname\n",
    "\n",
    "#     split_info = get_split_info(ds_root)\n",
    "#     train_img_dir = split_info[\"train_img_dir\"]\n",
    "#     val_img_dir   = split_info[\"val_img_dir\"]\n",
    "#     split_mode    = split_info[\"split_mode\"]\n",
    "#     train_tag     = split_info.get(\"train_tag\", \"train\")\n",
    "#     val_tag       = split_info.get(\"val_tag\", \"val\")\n",
    "\n",
    "#     vroot    = RUNTIME_VROOT_BASE / ds_root.name / f\"case__{case_labels_dirname}__{class_mode}\"\n",
    "#     v_images = vroot / \"images\"\n",
    "#     v_labels = vroot / \"labels\"\n",
    "\n",
    "#     if vroot.exists():\n",
    "#         try:\n",
    "#             shutil.rmtree(vroot)\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "#     (v_images / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "#     (v_images / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "#     (v_labels / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "#     (v_labels / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # A) SKU virtual split\n",
    "#     if split_mode == \"sku_virtual_8_2\":\n",
    "#         base_train_imgs, base_val_imgs = sku_virtual_split_images(images_root, seed=seed, ratio=0.8)\n",
    "#         chosen_train_imgs, n_total_train = sample_train_images(base_train_imgs, train_fraction, seed)\n",
    "\n",
    "#         for img in chosen_train_imgs:\n",
    "#             rel = img.relative_to(images_root)\n",
    "#             dst = v_images / \"train\" / rel\n",
    "#             try:\n",
    "#                 _safe_symlink(img, dst)\n",
    "#             except Exception:\n",
    "#                 _link_or_copy(img, dst, prefer_symlink=False)\n",
    "\n",
    "#         for img in base_val_imgs:\n",
    "#             rel = img.relative_to(images_root)\n",
    "#             dst = v_images / \"val\" / rel\n",
    "#             try:\n",
    "#                 _safe_symlink(img, dst)\n",
    "#             except Exception:\n",
    "#                 _link_or_copy(img, dst, prefer_symlink=False)\n",
    "\n",
    "#         for img in chosen_train_imgs:\n",
    "#             rel = img.relative_to(images_root)\n",
    "#             src_lbl = case_label_root / rel.with_suffix(\".txt\")\n",
    "#             dst_lbl = v_labels / \"train\" / rel.with_suffix(\".txt\")\n",
    "#             if class_mode == \"multiclass\":\n",
    "#                 dst_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
    "#                 if src_lbl.exists():\n",
    "#                     try:\n",
    "#                         _safe_symlink(src_lbl, dst_lbl)\n",
    "#                     except Exception:\n",
    "#                         _link_or_copy(src_lbl, dst_lbl, prefer_symlink=False)\n",
    "#                 else:\n",
    "#                     try:\n",
    "#                         dst_lbl.write_text(\"\", encoding=\"utf-8\")\n",
    "#                     except Exception:\n",
    "#                         pass\n",
    "#             else:\n",
    "#                 rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "#         for img in base_val_imgs:\n",
    "#             rel = img.relative_to(images_root)\n",
    "#             src_lbl = orig_label_root / rel.with_suffix(\".txt\")\n",
    "#             dst_lbl = v_labels / \"val\" / rel.with_suffix(\".txt\")\n",
    "#             if class_mode == \"multiclass\":\n",
    "#                 dst_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
    "#                 if src_lbl.exists():\n",
    "#                     try:\n",
    "#                         _safe_symlink(src_lbl, dst_lbl)\n",
    "#                     except Exception:\n",
    "#                         _link_or_copy(src_lbl, dst_lbl, prefer_symlink=False)\n",
    "#                 else:\n",
    "#                     try:\n",
    "#                         dst_lbl.write_text(\"\", encoding=\"utf-8\")\n",
    "#                     except Exception:\n",
    "#                         pass\n",
    "#             else:\n",
    "#                 rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "#         if class_mode == \"multiclass\":\n",
    "#             names = infer_class_names_from_labels(orig_label_root)\n",
    "#             nc = len(names)\n",
    "#         else:\n",
    "#             names = [\"object\"]\n",
    "#             nc = 1\n",
    "\n",
    "#         data_yaml = vroot / \"data.yaml\"\n",
    "#         with open(data_yaml, \"w\", encoding=\"utf-8\") as f:\n",
    "#             f.write(\n",
    "#                 f\"path: {str(vroot)}\\n\"\n",
    "#                 f\"train: images/train\\n\"\n",
    "#                 f\"val: images/val\\n\"\n",
    "#                 f\"nc: {nc}\\n\"\n",
    "#                 f\"names: {names}\\n\"\n",
    "#             )\n",
    "\n",
    "#         rt_n_train = len(list_images(v_images / \"train\"))\n",
    "#         if rt_n_train == 0:\n",
    "#             raise RuntimeError(f\"Runtime train images empty (SKU mode): {v_images/'train'}\")\n",
    "\n",
    "#         return vroot, data_yaml, len(chosen_train_imgs), len(base_train_imgs), split_mode\n",
    "\n",
    "#     # B) Standard split\n",
    "#     if train_img_dir is None or not Path(train_img_dir).is_dir():\n",
    "#         raise RuntimeError(f\"No train images dir resolved for {ds_root.name}\")\n",
    "#     if val_img_dir is None or not Path(val_img_dir).is_dir():\n",
    "#         raise RuntimeError(f\"No val images dir resolved for {ds_root.name}\")\n",
    "\n",
    "#     all_train_imgs = list_images(train_img_dir)\n",
    "#     chosen_train_imgs, n_total_train = sample_train_images(all_train_imgs, train_fraction, seed)\n",
    "#     if n_total_train == 0 or len(chosen_train_imgs) == 0:\n",
    "#         raise RuntimeError(f\"No train images for {ds_root.name}\")\n",
    "\n",
    "#     for img in chosen_train_imgs:\n",
    "#         rel = img.relative_to(train_img_dir)\n",
    "#         dst = v_images / \"train\" / rel\n",
    "#         try:\n",
    "#             _safe_symlink(img, dst)\n",
    "#         except Exception:\n",
    "#             _link_or_copy(img, dst, prefer_symlink=False)\n",
    "\n",
    "#     _safe_copytree(Path(val_img_dir), v_images / \"val\")\n",
    "\n",
    "#     case_train_lbl_base = resolve_label_base(case_label_root, train_tag, is_train=True)\n",
    "#     for img in chosen_train_imgs:\n",
    "#         rel = img.relative_to(train_img_dir)\n",
    "#         src_lbl = case_train_lbl_base / rel.with_suffix(\".txt\")\n",
    "#         dst_lbl = v_labels / \"train\" / rel.with_suffix(\".txt\")\n",
    "#         if class_mode == \"multiclass\":\n",
    "#             dst_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
    "#             if src_lbl.exists():\n",
    "#                 try:\n",
    "#                     _safe_symlink(src_lbl, dst_lbl)\n",
    "#                 except Exception:\n",
    "#                     _link_or_copy(src_lbl, dst_lbl, prefer_symlink=False)\n",
    "#             else:\n",
    "#                 try:\n",
    "#                     dst_lbl.write_text(\"\", encoding=\"utf-8\")\n",
    "#                 except Exception:\n",
    "#                     pass\n",
    "#         else:\n",
    "#             rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "#     orig_val_lbl_base = resolve_label_base(orig_label_root, val_tag, is_train=False)\n",
    "#     if class_mode == \"multiclass\":\n",
    "#         _safe_copytree(orig_val_lbl_base, v_labels / \"val\")\n",
    "#     else:\n",
    "#         for src_lbl in orig_val_lbl_base.rglob(\"*.txt\"):\n",
    "#             rel = src_lbl.relative_to(orig_val_lbl_base)\n",
    "#             dst_lbl = v_labels / \"val\" / rel\n",
    "#             rewrite_label_file_to_object_only(src_lbl, dst_lbl)\n",
    "\n",
    "#     if class_mode == \"multiclass\":\n",
    "#         names = infer_class_names_from_labels(orig_label_root)\n",
    "#         nc = len(names)\n",
    "#     else:\n",
    "#         names = [\"object\"]\n",
    "#         nc = 1\n",
    "\n",
    "#     data_yaml = vroot / \"data.yaml\"\n",
    "#     with open(data_yaml, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(\n",
    "#             f\"path: {str(vroot)}\\n\"\n",
    "#             f\"train: images/train\\n\"\n",
    "#             f\"val: images/val\\n\"\n",
    "#             f\"nc: {nc}\\n\"\n",
    "#             f\"names: {names}\\n\"\n",
    "#         )\n",
    "\n",
    "#     rt_n_train = len(list_images(v_images / \"train\"))\n",
    "#     rt_n_val   = len(list_images(v_images / \"val\"))\n",
    "#     if rt_n_train == 0:\n",
    "#         raise RuntimeError(f\"Runtime train images empty: {v_images/'train'}\")\n",
    "#     if rt_n_val == 0:\n",
    "#         raise RuntimeError(f\"Runtime val images empty: {v_images/'val'}\")\n",
    "\n",
    "#     return vroot, data_yaml, len(chosen_train_imgs), n_total_train, split_mode\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # OOM-safe train wrapper\n",
    "# # -------------------------------------------------------------------------\n",
    "# def train_with_auto_oom(model: YOLO, data_yaml: Path, project_dir: Path, name_dir: str, model_tag: str):\n",
    "#     if model_tag == \"detr\":\n",
    "#         candidates = [(4, 640), (2, 640), (2, 512), (1, 512)]\n",
    "#     else:\n",
    "#         candidates = [(BATCH, IMG_SIZE)]\n",
    "\n",
    "#     last_err = None\n",
    "#     for b, sz in candidates:\n",
    "#         try:\n",
    "#             with suppress_output(SILENCE_ULTRA_OUTPUT):\n",
    "#                 model.train(\n",
    "#                     data=str(data_yaml),\n",
    "#                     epochs=EPOCHS,\n",
    "#                     imgsz=sz,\n",
    "#                     batch=b,\n",
    "#                     device=DEVICE,\n",
    "#                     project=str(project_dir),\n",
    "#                     name=name_dir,\n",
    "#                     exist_ok=True,\n",
    "#                     verbose=False,\n",
    "#                     workers=NUM_WORKERS,\n",
    "#                     amp=True,\n",
    "#                 )\n",
    "#             return True, b, sz, None\n",
    "#         except RuntimeError as e:\n",
    "#             msg = str(e).lower()\n",
    "#             last_err = e\n",
    "#             if \"out of memory\" in msg or \"cuda out of memory\" in msg:\n",
    "#                 if torch.cuda.is_available():\n",
    "#                     torch.cuda.empty_cache()\n",
    "#                     torch.cuda.ipc_collect()\n",
    "#                 continue\n",
    "#             break\n",
    "#         except Exception as e:\n",
    "#             last_err = e\n",
    "#             break\n",
    "#     return False, None, None, last_err\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # Train & validate loop\n",
    "# # -------------------------------------------------------------------------\n",
    "# set_seed(SEED)\n",
    "\n",
    "# print(\"=\" * 80)\n",
    "# print(\"[TRAIN/EVAL] Start (Cell 1 summaries-aware + runtime path safe + object-only)\")\n",
    "# print(f\" - OUT_ROOT             : {OUT_ROOT}\")\n",
    "# print(f\" - RUNTIME_VROOT_BASE   : {RUNTIME_VROOT_BASE}\")\n",
    "# print(f\" - TRAIN_FRACTION       : {TRAIN_FRACTION}\")\n",
    "# print(f\" - NUM_WORKERS          : {NUM_WORKERS}\")\n",
    "# print(f\" - CLASS_MODES          : {CLASS_MODES}\")\n",
    "# print(f\" - CLEANUP_RUNTIME_VROOT: {CLEANUP_RUNTIME_VROOT}\")\n",
    "# print(f\" - TRAIN_USE_ORIGINAL   : {TRAIN_USE_ORIGINAL}\")\n",
    "# print(f\" - TRAIN_USE_UNIFORM_SCALING_NOISE: {TRAIN_USE_UNIFORM_SCALING_NOISE}\")\n",
    "# print(f\" - TRAIN_USE_BOUNDARY_JITTER_NOISE : {TRAIN_USE_BOUNDARY_JITTER_NOISE}\")\n",
    "# if TARGET_DATASETS_LOWER is None:\n",
    "#     print(f\" - TARGET_DATASETS      : ALL (no filter)\")\n",
    "# else:\n",
    "#     print(f\" - TARGET_DATASETS      : {sorted(TARGET_DATASETS_LOWER)}\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "# summary_rows: List[Dict] = []\n",
    "\n",
    "# try:\n",
    "#     _ = roots\n",
    "# except NameError:\n",
    "#     raise RuntimeError(\"Please run Cell 1 first to prepare the roots variable.\")\n",
    "\n",
    "# for ds_root in roots:\n",
    "#     ds_root = Path(ds_root)\n",
    "\n",
    "#     if TARGET_DATASETS_LOWER is not None:\n",
    "#         ds_name_lower = ds_root.name.strip().lower()\n",
    "#         if ds_name_lower not in TARGET_DATASETS_LOWER:\n",
    "#             print(f\"‚è≠Ô∏è  Skip (not in TARGET_DATASETS): {ds_root.name}\")\n",
    "#             continue\n",
    "\n",
    "#     images_root = ds_root / \"images\"\n",
    "#     labels_root = ds_root / \"labels\"\n",
    "\n",
    "#     if not images_root.is_dir() or not labels_root.is_dir():\n",
    "#         print(f\"‚è≠Ô∏è  Skip (missing images/labels): {ds_root}\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"\\n[Integrity Check] {ds_root.name}\")\n",
    "#     scan_and_clean_images(images_root)\n",
    "\n",
    "#     cases = list_label_cases_for_dataset(ds_root)\n",
    "#     if not cases:\n",
    "#         print(f\"‚è≠Ô∏è  Skip (no target label cases after flags/grid filter): {ds_root.name}\")\n",
    "#         continue\n",
    "\n",
    "#     sp = get_split_info(ds_root)\n",
    "#     print(\"\\n\" + \"-\" * 80)\n",
    "#     print(f\"[Dataset] {ds_root.name}\")\n",
    "#     print(f\" - split_mode : {sp.get('split_mode')}\")\n",
    "#     print(f\" - Cases      : {[c[0] for c in cases]}\")\n",
    "#     print(f\" - CLASS_MODES: {CLASS_MODES}\")\n",
    "#     print(\"-\" * 80)\n",
    "\n",
    "#     for case_tag, labels_dirname in cases:\n",
    "#         for class_mode in CLASS_MODES:\n",
    "#             try:\n",
    "#                 vroot, data_yaml, n_used, n_total, split_mode = build_runtime_view_root(\n",
    "#                     ds_root=ds_root,\n",
    "#                     case_labels_dirname=labels_dirname,\n",
    "#                     train_fraction=TRAIN_FRACTION,\n",
    "#                     seed=SEED,\n",
    "#                     class_mode=class_mode,\n",
    "#                 )\n",
    "#                 pct = (n_used / max(1, n_total)) * 100.0\n",
    "#                 print(f\"  [Subset] case={case_tag} | class_mode={class_mode} | split_mode={split_mode} | train_used={n_used}/{n_total} ({pct:.1f}%)\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"  ‚è≠Ô∏è  Skip build failed: case={case_tag} | class_mode={class_mode} | err={e}\")\n",
    "#                 continue\n",
    "\n",
    "#             for model_tag, ckpt_candidates in MODEL_SPECS:\n",
    "#                 print(f\"\\n  [Train] case={case_tag} | class_mode={class_mode} | model={model_tag}\")\n",
    "\n",
    "#                 try:\n",
    "#                     model = choose_model(ckpt_candidates)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"    ‚ùå Model load failed: {ckpt_candidates} | err={e}\")\n",
    "#                     continue\n",
    "\n",
    "#                 project_dir = OUT_ROOT / ds_root.name\n",
    "#                 frac_tag = f\"tr{int(TRAIN_FRACTION*100)}\"\n",
    "#                 name_dir = f\"{model_tag}__{case_tag}__{class_mode}__{frac_tag}\"\n",
    "#                 project_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#                 ok, used_b, used_sz, err = train_with_auto_oom(model, data_yaml, project_dir, name_dir, model_tag)\n",
    "#                 if not ok:\n",
    "#                     print(f\"    ‚ùå Train failed: {err}\")\n",
    "#                     try:\n",
    "#                         del model\n",
    "#                     except Exception:\n",
    "#                         pass\n",
    "#                     if torch.cuda.is_available():\n",
    "#                         torch.cuda.empty_cache()\n",
    "#                         torch.cuda.ipc_collect()\n",
    "#                     continue\n",
    "\n",
    "#                 try:\n",
    "#                     with suppress_output(SILENCE_ULTRA_OUTPUT):\n",
    "#                         val_res = model.val(\n",
    "#                             data=str(data_yaml),\n",
    "#                             imgsz=used_sz if used_sz else IMG_SIZE,\n",
    "#                             device=DEVICE,\n",
    "#                             split=\"val\",\n",
    "#                             verbose=False,\n",
    "#                             workers=NUM_WORKERS,\n",
    "#                         )\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"    ‚ùå Val failed: {e}\")\n",
    "#                     val_res = None\n",
    "\n",
    "#                 metrics = extract_metrics_dict(val_res)\n",
    "\n",
    "#                 metrics_out = project_dir / name_dir / \"metrics_eval.json\"\n",
    "#                 try:\n",
    "#                     metrics_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "#                     with open(metrics_out, \"w\", encoding=\"utf-8\") as f:\n",
    "#                         json.dump(\n",
    "#                             {\n",
    "#                                 \"dataset\": ds_root.name,\n",
    "#                                 \"root\": str(ds_root),\n",
    "#                                 \"case_tag\": case_tag,\n",
    "#                                 \"labels_dirname\": labels_dirname,\n",
    "#                                 \"class_mode\": class_mode,\n",
    "#                                 \"model_tag\": model_tag,\n",
    "#                                 \"ckpt_candidates\": ckpt_candidates,\n",
    "#                                 \"train_fraction\": TRAIN_FRACTION,\n",
    "#                                 \"train_used\": n_used,\n",
    "#                                 \"train_total\": n_total,\n",
    "#                                 \"data_yaml\": str(data_yaml),\n",
    "#                                 \"runtime_view_root\": str(vroot),\n",
    "#                                 \"split_mode\": split_mode,\n",
    "#                                 \"effective_batch\": used_b,\n",
    "#                                 \"effective_imgsz\": used_sz,\n",
    "#                                 \"metrics\": metrics,\n",
    "#                             },\n",
    "#                             f,\n",
    "#                             ensure_ascii=False,\n",
    "#                             indent=2,\n",
    "#                         )\n",
    "#                     print(f\"    ‚úÖ Saved metrics: {metrics_out}\")\n",
    "#                 except Exception:\n",
    "#                     pass\n",
    "\n",
    "#                 row = {\n",
    "#                     \"dataset\": ds_root.name,\n",
    "#                     \"model\": model_tag,\n",
    "#                     \"case\": case_tag,\n",
    "#                     \"labels_dir\": labels_dirname,\n",
    "#                     \"class_mode\": class_mode,\n",
    "#                     \"split_mode\": split_mode,\n",
    "#                     \"train_fraction\": TRAIN_FRACTION,\n",
    "#                     \"train_used\": n_used,\n",
    "#                     \"train_total\": n_total,\n",
    "#                     \"effective_batch\": used_b,\n",
    "#                     \"effective_imgsz\": used_sz,\n",
    "#                 }\n",
    "#                 for k in [\"metrics/mAP50(B)\", \"metrics/mAP50-95(B)\", \"metrics/precision(B)\", \"metrics/recall(B)\"]:\n",
    "#                     if k in metrics:\n",
    "#                         row[k] = metrics[k]\n",
    "\n",
    "#                 summary_rows.append(row)\n",
    "\n",
    "#                 try:\n",
    "#                     del model\n",
    "#                 except Exception:\n",
    "#                     pass\n",
    "#                 if torch.cuda.is_available():\n",
    "#                     torch.cuda.empty_cache()\n",
    "#                     torch.cuda.ipc_collect()\n",
    "\n",
    "#             if CLEANUP_RUNTIME_VROOT:\n",
    "#                 try:\n",
    "#                     shutil.rmtree(vroot)\n",
    "#                 except Exception:\n",
    "#                     pass\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # Save summary CSV\n",
    "# # -------------------------------------------------------------------------\n",
    "# out_csv = OUT_ROOT / \"summary_final_optimized_VOC_only.csv\"\n",
    "# try:\n",
    "#     cols = set()\n",
    "#     for r in summary_rows:\n",
    "#         cols.update(r.keys())\n",
    "\n",
    "#     base_cols = [\n",
    "#         \"dataset\", \"model\", \"case\", \"labels_dir\",\n",
    "#         \"class_mode\",\n",
    "#         \"split_mode\",\n",
    "#         \"train_fraction\", \"train_used\", \"train_total\",\n",
    "#         \"effective_batch\", \"effective_imgsz\",\n",
    "#     ]\n",
    "#     extra_cols = sorted([c for c in cols if c not in set(base_cols)])\n",
    "#     cols = base_cols + extra_cols\n",
    "\n",
    "#     with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#         w = csv.DictWriter(f, fieldnames=cols)\n",
    "#         w.writeheader()\n",
    "#         for r in summary_rows:\n",
    "#             w.writerow(r)\n",
    "\n",
    "#     print(\"\\n\" + \"=\" * 80)\n",
    "#     print(f\"‚úÖ Saved summary CSV: {out_csv}\")\n",
    "#     print(f\"‚úÖ Total runs: {len(summary_rows)}\")\n",
    "#     print(\"=\" * 80)\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ö†Ô∏è  Summary CSV save failed: {e}\")\n",
    "\n",
    "# print(\"\\n‚úÖ Cell 2 done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
